

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Datasets &mdash; dstc7-noesis 0.0.1 documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Evaluations" href="evaluations.html" />
    <link rel="prev" title="Noetic End-to-End Response Selection Challenge" href="index.html" /> 

  
  <script src="_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="index.html" class="icon icon-home"> dstc7-noesis
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Datasets</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#ubuntu">Ubuntu</a></li>
<li class="toctree-l2"><a class="reference internal" href="#advising">Advising</a></li>
<li class="toctree-l2"><a class="reference internal" href="#sub-tasks">Sub-Tasks</a></li>
<li class="toctree-l2"><a class="reference internal" href="#data-format">Data Format</a></li>
<li class="toctree-l2"><a class="reference internal" href="#external-data">External Data</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="evaluations.html">Evaluations</a></li>
<li class="toctree-l1"><a class="reference internal" href="faq.html">FAQs</a></li>
<li class="toctree-l1"><a class="reference internal" href="submission.html">Submission</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">dstc7-noesis</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li>Datasets</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/dataset.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="datasets">
<h1>Datasets<a class="headerlink" href="#datasets" title="Permalink to this headline">¶</a></h1>
<p>The datasets will be available to the contestants upon <a class="reference external" href="https://ibm.biz/BdZ6E3">registration</a> and selecting <strong>Sentence Selection</strong> as an interested track.</p>
<div class="section" id="ubuntu">
<h2>Ubuntu<a class="headerlink" href="#ubuntu" title="Permalink to this headline">¶</a></h2>
<p>A new set of disentangled Ubuntu IRC dialogs representing two party conversations extracted from the Ubuntu IRC channel.
A typical dialog starts with a question that was asked by <em>participant_1</em>, and then someone else, <em>participant_2</em>, responds with either an answer or follow-up questions that then lead to a back-and-forth conversation.
In this challenge, the context of each dialog contains more than 3 turns which occurred between the two participants and the next turn of <em>participant_2</em> should be selected from the given set of candidate utterances.
We focus on <em>participant_2</em> to set the task up as creating a bot that could help provide answers.
Relevant external information of the form of Linux manual pages is also provided.</p>
</div>
<div class="section" id="advising">
<h2>Advising<a class="headerlink" href="#advising" title="Permalink to this headline">¶</a></h2>
<p>A two party dialogs dataset that simulate a discussion between a <em>student</em> and an academic <em>advisor</em>.
The purpose of the dialogs is to guide the student to pick courses that fit not only their curriculum, but also personal preferences about time, difficulty, areas of interest, etc.
These conversations were collected by having students at the University of Michigan act as the two roles using provided personas.
Structured information in the form of a database of course information will be provided, as well as the personas (though at test time only information available to the advisor will be provided, i.e. not the explicit student preferences).
The data also includes paraphrases of the sentences and of the target responses.</p>
</div>
<div class="section" id="sub-tasks">
<h2>Sub-Tasks<a class="headerlink" href="#sub-tasks" title="Permalink to this headline">¶</a></h2>
<p>We are considered several tasks that have similar structure, but vary in the output space and available context. In the table below, [x] indicates that the task is evaluated on the marked dataset.</p>
<blockquote>
<div><table border="1" class="docutils">
<colgroup>
<col width="7%" />
<col width="79%" />
<col width="6%" />
<col width="7%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">Sub-Task</th>
<th class="head">Description</th>
<th class="head">Ubuntu</th>
<th class="head">Advising</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>1</td>
<td>Select the next utterance from a candidate pool of 100 sentences</td>
<td>[x]</td>
<td>[x]</td>
</tr>
<tr class="row-odd"><td>2</td>
<td>Select the next utterance from a candidate pool of 120000</td>
<td>[x]</td>
<td>&#160;</td>
</tr>
<tr class="row-even"><td>3</td>
<td>Select the next utterance and its paraphrases from candidate pool of 100</td>
<td>&#160;</td>
<td>[x]</td>
</tr>
<tr class="row-odd"><td>4</td>
<td>Select the next utterance from a candidate pool of 100 which might not contain the correct next utterance</td>
<td>[x]</td>
<td>[x]</td>
</tr>
<tr class="row-even"><td>5</td>
<td>Select the next utterance from a candidate pool of 100 incorporating the provided external knowledge</td>
<td>[x]</td>
<td>[x]</td>
</tr>
</tbody>
</table>
</div></blockquote>
<p>In <strong>sub-task 1</strong>, for each partial dialog and a candidate pool of 100 is given and the contestants are expected to select the best next utterance from the given pool.</p>
<p>In <strong>sub-task 2</strong>, one large candidate pool of 120000 utterances is shared by training and validation datasets. The next best utterance should be selected from this large pool of candidate utterances.</p>
<p>For <strong>sub-task 3</strong>, in addition to the training and validation dialog datasets, and extra dataset which includes paraphrases for utterances is provided. The contestants are required to use the paraphrase information to select the next utterance as well as its paraphrases from the given set of 100 candidates.</p>
<p>The candidate sets that are provided for some dialogs in <strong>sub-task 4</strong> does not include the correct next utterance. The contestants are expected to train their models in a way that during testing they can identify such cases.</p>
<p>In <strong>sub-task 5</strong>, additional external information which will be important for dialog modeling will be provided. For Ubuntu dataset, this external information comes in the form of Linux manual pages and for Advising dataset, extra information about courses will be given. The same training, validation and test data files in task 1 will be reused for this task. The contestants can use the provided knowledge sources as is, or transform them to appropriate representations (e.g. knowledge graphs, continuous embeddings, etc.) that can be integrated with end-to-end dialog systems to improve accuracy.</p>
</div>
<div class="section" id="data-format">
<h2>Data Format<a class="headerlink" href="#data-format" title="Permalink to this headline">¶</a></h2>
<p>Each dialog contains in training, validation and test datasets follows the JSON format which is similar to the below example.</p>
<div class="highlight-json"><div class="highlight"><pre><span></span>{
    &quot;data-split&quot;: &quot;train&quot;,
    &quot;example-id&quot;: 1100001,
    &quot;messages-so-far&quot;: [
        {
            &quot;speaker&quot;: &quot;participant_1&quot;,
            &quot;utterance&quot;: &quot;hey guys, does your livecd have chroot installed? and bash?&quot;
        },
        {
            &quot;speaker&quot;: &quot;participant_2&quot;,
            &quot;utterance&quot;: &quot;sure&quot;
        },
        ...
    ],
    &quot;options-for-correct-answers&quot;: [
        {
            &quot;candidate-id&quot;: &quot;TLSHF16Y4J4L&quot;,
            &quot;utterance&quot;: &quot;what are you missing in apt ?&quot;
        }
    ],
    &quot;options-for-next&quot;: [
        {
            &quot;candidate-id&quot;: &quot;YWOA49156J9P&quot;,
            &quot;utterance&quot;: &quot;issues with msn?. I&#39;m experiencing them on windows atm, current msn version&quot;
        },
        {
            &quot;candidate-id&quot;: &quot;RYBI7QRD9QZN&quot;,
            &quot;utterance&quot;: &quot;&lt;&gt; AmaroqWolf: alias=&#39;sudo admincommand&#39;.  &lt;AmaroqWolf&gt;  aw, can&#39;t make myself type sudo? I like it better that way.&quot;
        },
        ...
    ],
    &quot;scenario&quot;: 1
}
</pre></div>
</div>
<p>The field <cite>messages-so-far</cite> contains the context of the dialog and <cite>options-for-next</cite> contains the candidates to select the next utterance from. The correct next utterance is given in the field <cite>options-for-correct-answers</cite>. The field <cite>scenario</cite> refers to the subtask.</p>
<p>For each dialog in <cite>Advising</cite> dataset, we provide a profile that contains information used during the creation of the dialog. It has the following fields:</p>
<ul class="simple">
<li><cite>Aggregated</cite> - contains student preferences, with each field matching up with a field in the <cite>course-info.json</cite> file.</li>
<li><cite>Courses</cite> - contains two lists, first is a list of courses this student has taken (“Prior”) and second is a list of suggestions that the advisor had access to (“Suggested”).</li>
<li><cite>Term</cite> - specifies the simulated year and semester for the conversation</li>
<li><cite>Standing</cite> - specifies how far through their degree the student is.</li>
</ul>
</div>
<div class="section" id="external-data">
<h2>External Data<a class="headerlink" href="#external-data" title="Permalink to this headline">¶</a></h2>
<p>Each course offering record found in the external dataset provided for Advising domain contains the following fields.</p>
<blockquote>
<div><table border="1" class="docutils">
<colgroup>
<col width="18%" />
<col width="82%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">Field</th>
<th class="head">Description</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>Area</td>
<td>Six general areas in computer science (otherwise NA)</td>
</tr>
<tr class="row-odd"><td>Category</td>
<td>Five general types of classes in computer science (otherwise NA)</td>
</tr>
<tr class="row-even"><td>ClarityRating</td>
<td>A number in [1.0, 5.0] indicating course clarity, or NA (78% of cases)</td>
</tr>
<tr class="row-odd"><td>ClassSize</td>
<td>A number in [1.0, 250.0] indicating average class size, or NA (71% of cases)</td>
</tr>
<tr class="row-even"><td>Course</td>
<td>Course ID, a series of letters and numbers</td>
</tr>
<tr class="row-odd"><td>CourseTitle</td>
<td>Complete course name</td>
</tr>
<tr class="row-even"><td>Credits</td>
<td>A number or a range (for example, indicated as 1 - 3)</td>
</tr>
<tr class="row-odd"><td>Description</td>
<td>Free text description of the class topic</td>
</tr>
<tr class="row-even"><td>EasinessRating</td>
<td>A number in [1.0, 5.0] indicating course difficulty level, or NA (78% of cases)</td>
</tr>
<tr class="row-odd"><td>HasDiscussion</td>
<td>Whether the course has a discussion section (Y, N or null)</td>
</tr>
<tr class="row-even"><td>HasLab</td>
<td>Whether the course has a lab (Y, N, null)</td>
</tr>
<tr class="row-odd"><td>HelpfulnessRating</td>
<td>A number in [1.0, 5.0] indicating how helpful course staff were, or NA (78% of cases)</td>
</tr>
<tr class="row-even"><td>Semester</td>
<td>Which semester the class was held in (Fall, Winter, Spring, Summer, or Spring-Summer)</td>
</tr>
<tr class="row-odd"><td>Workload</td>
<td>One of {1, 2, 3, 4, null, NA}, where higher numbers indicate higher workload</td>
</tr>
<tr class="row-even"><td>Year</td>
<td>A four digit number</td>
</tr>
<tr class="row-odd"><td>Section</td>
<td>Information about available sections. The key for each is the instructor name, or ‘NA”</td>
</tr>
<tr class="row-even"><td>DaysOfClass</td>
<td>One per section, lists weekdays, or for unknown it has “” or []</td>
</tr>
<tr class="row-odd"><td>StartTime / EndTime</td>
<td>When the class is held as a 24-hour time, or NA (2%) or 0:00:00 (71%) when unknown</td>
</tr>
</tbody>
</table>
</div></blockquote>
<p><strong>*All the datasets will be publicly available after the competition.*</strong></p>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="evaluations.html" class="btn btn-neutral float-right" title="Evaluations" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="index.html" class="btn btn-neutral" title="Noetic End-to-End Response Selection Challenge" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2018, International Business Machines Corp.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'./',
            VERSION:'0.0.1',
            LANGUAGE:'None',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="_static/jquery.js"></script>
      <script type="text/javascript" src="_static/underscore.js"></script>
      <script type="text/javascript" src="_static/doctools.js"></script>
      <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  <script type="text/javascript" src="_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>
