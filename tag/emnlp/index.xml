<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>emnlp | Jonathan K. Kummerfeld</title>
    <link>https://www.jkk.name/tag/emnlp/</link>
      <atom:link href="https://www.jkk.name/tag/emnlp/index.xml" rel="self" type="application/rss+xml" />
    <description>emnlp</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>Â© 2021 Jonathan K. Kummerfeld</copyright><lastBuildDate>Tue, 12 Dec 2017 20:25:40 -0500</lastBuildDate>
    <image>
      <url>https://www.jkk.name/images/icon_hua0d6326cebee282657b97e45398e76a5_17367_512x512_fill_lanczos_center_2.png</url>
      <title>emnlp</title>
      <link>https://www.jkk.name/tag/emnlp/</link>
    </image>
    
    <item>
      <title>A Simple Regularization-based Algorithm for Learning Cross-Domain Word Embeddings (Yang et al., 2017)</title>
      <link>https://www.jkk.name/post/2017-12-12_multidomainwordvector/</link>
      <pubDate>Tue, 12 Dec 2017 20:25:40 -0500</pubDate>
      <guid>https://www.jkk.name/post/2017-12-12_multidomainwordvector/</guid>
      <description>&lt;p&gt;To construct word vectors from multi-domain data, use a separate vector for each domain and add a loss term to encourage them to agree.
Here the loss is an l2 norm, weighted by a factor that depends on the frequency of the words in the two domains.
The factor is the harmonic mean of the normalised frequency in each domain (so the lower frequency dominates the factor, pulling it lower).
Across a range of tasks this consistently performs better than other approaches.&lt;/p&gt;
&lt;h2 id=&#34;citation&#34;&gt;Citation&lt;/h2&gt;
&lt;p&gt;
&lt;a href=&#34;https://aclanthology.org/D17-1312&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Paper&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bibtex&#34;&gt;@InProceedings{yang-lu-zheng:2017:EMNLP2017,
  author    = {Yang, Wei  and  Lu, Wei  and  Zheng, Vincent},
  title     = {A Simple Regularization-based Algorithm for Learning Cross-Domain Word Embeddings},
  booktitle = {Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing},
  month     = {September},
  year      = {2017},
  address   = {Copenhagen, Denmark},
  publisher = {Association for Computational Linguistics},
  pages     = {2898--2904},
  url       = {https://aclanthology.org/D17-1312}
}
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>The strange geometry of skip-gram with negative sampling (Mimno et al., 2017)</title>
      <link>https://www.jkk.name/post/2017-12-12_wordvectorgeometry/</link>
      <pubDate>Tue, 12 Dec 2017 20:15:34 -0500</pubDate>
      <guid>https://www.jkk.name/post/2017-12-12_wordvectorgeometry/</guid>
      <description>&lt;p&gt;It turns out that if the vectors learned by word2vec are projected into a plane they all point in the same direction.
Also, the context vectors (which are part of the algorithm, but not retained afterwards) point the other way.
When visualising with t-SNE this effect is not visible because of the way the space is warped to optimise the t-SNE objective.&lt;/p&gt;
&lt;p&gt;This is surprising, and may seem problematic since it doesn&amp;rsquo;t fit our goals for what these vectors should be capturing.
However, it doesn&amp;rsquo;t seem to impact downstream tasks, for example, GloVe does not have this property, and doesn&amp;rsquo;t seem to derive a great benefit from it.&lt;/p&gt;
&lt;h2 id=&#34;citation&#34;&gt;Citation&lt;/h2&gt;
&lt;p&gt;
&lt;a href=&#34;https://aclanthology.org/D17-1308&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Paper&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bibtex&#34;&gt;@InProceedings{mimno-thompson:2017:EMNLP2017,
  author    = {Mimno, David  and  Thompson, Laure},
  title     = {The strange geometry of skip-gram with negative sampling},
  booktitle = {Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing},
  month     = {September},
  year      = {2017},
  address   = {Copenhagen, Denmark},
  publisher = {Association for Computational Linguistics},
  pages     = {2873--2878},
  url       = {https://aclanthology.org/D17-1308}
}
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Sequence Effects in Crowdsourced Annotations (Mathur et al., 2017)</title>
      <link>https://www.jkk.name/post/2017-12-08_crowdbias/</link>
      <pubDate>Fri, 08 Dec 2017 19:49:09 -0500</pubDate>
      <guid>https://www.jkk.name/post/2017-12-08_crowdbias/</guid>
      <description>&lt;p&gt;Getting high quality annotations from crowdsourcing requires careful design.
This paper looks at how one annotation a worker does can influence their next annotation, for example:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;When scoring translations, a good example may make the next one look worse in comparison&lt;/li&gt;
&lt;li&gt;For labeling tasks, we may expect a long sequence of the same label to be rare (the gambler&amp;rsquo;s fallacy)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;To investigate this they fit a linear model with inputs (previous label, gold label, random noise) and see what the coefficients are.
Across multiple tasks, there is a non-zero correlation with the previous label.
Interestingly, there also seems to be a learning effect for good workers, where over time they become calibrated and show less sequence bias.
Fortunately, there is a simple solution - for each worker, give every annotator their documents in a different random order!
With that change, averaging over annotations should avoid this bias.&lt;/p&gt;
&lt;h2 id=&#34;citation&#34;&gt;Citation&lt;/h2&gt;
&lt;p&gt;
&lt;a href=&#34;https://aclanthology.org/D17-1306&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Paper&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bibtex&#34;&gt;@InProceedings{mathur-baldwin-cohn:2017:EMNLP2017,
  author    = {Mathur, Nitika  and  Baldwin, Timothy  and  Cohn, Trevor},
  title     = {Sequence Effects in Crowdsourced Annotations},
  booktitle = {Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing},
  month     = {September},
  year      = {2017},
  address   = {Copenhagen, Denmark},
  publisher = {Association for Computational Linguistics},
  pages     = {2860--2865},
  url       = {https://aclanthology.org/D17-1306}
}
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>High-risk learning: acquiring new word vectors from tiny data (Herbelot et al., 2017)</title>
      <link>https://www.jkk.name/post/2017-12-07_rarewordvectors/</link>
      <pubDate>Thu, 07 Dec 2017 20:45:39 -0500</pubDate>
      <guid>https://www.jkk.name/post/2017-12-07_rarewordvectors/</guid>
      <description>&lt;p&gt;Word vectors are great for common words, but what about rare words?
People can have a fairly good understanding of a word given only a few instances, but it&amp;rsquo;s fairly standard to turn all words with a frequency of less than 5 into UNK when learning word vectors.&lt;/p&gt;
&lt;p&gt;One simple approach is to add up word vectors from the context of the rare word and use that as the representation.
This paper proposes using a tweaked version of word2vec: keep vectors for frequent words fixed, increase the learning rate, use a fixed width context window, initialise with the additive approach, and only subsample by discarding frequent words.
All of those make sense, though I am curious whether it would be better to just decrease subsampling or disable it entirely.&lt;/p&gt;
&lt;p&gt;The results are mixed, with the improvement over the additive approach data dependent.
That might partly reflect the tasks though - something downstream like POS tagging would have been interesting, particularly since the LSTM may already be capturing contextual information that covers what the additive approach has, but not what this adds.
Ultimately this is not a solution to this problem, but it&amp;rsquo;s an idea to keep in mind.&lt;/p&gt;
&lt;h2 id=&#34;citation&#34;&gt;Citation&lt;/h2&gt;
&lt;p&gt;
&lt;a href=&#34;https://aclanthology.org/D17-1030&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Paper&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bibtex&#34;&gt;@InProceedings{herbelot-baroni:2017:EMNLP2017,
  author    = {Herbelot, Aur\&#39;{e}lie  and  Baroni, Marco},
  title     = {High-risk learning: acquiring new word vectors from tiny data},
  booktitle = {Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing},
  month     = {September},
  year      = {2017},
  address   = {Copenhagen, Denmark},
  publisher = {Association for Computational Linguistics},
  pages     = {304--309},
  url       = {https://aclanthology.org/D17-1030}
}
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Revisiting Selectional Preferences for Coreference Resolution (Heinzerling et al., 2017)</title>
      <link>https://www.jkk.name/post/2017-12-06_coreferencearguments/</link>
      <pubDate>Wed, 06 Dec 2017 19:05:20 -0500</pubDate>
      <guid>https://www.jkk.name/post/2017-12-06_coreferencearguments/</guid>
      <description>&lt;p&gt;Selectional preferences in this context are about how some verbs are more likely to take certain types of arguments (e.g. people laugh, computers do not).
Many papers have added features or structures to coreference systems aiming to get at this kind of information.
This paper presents another way of doing it and experiments that probe how useful it is (punchline: not very).&lt;/p&gt;
&lt;p&gt;Their approach is to parse a large amount of text, producing noun-verb pairs.
They learn vector representations of the relations and try to create a single space containing both entities and relations (e.g. Michigan gets a vector, as does attended@dobj).
The goal is that entities end up in locations similar to the locations of relations they are selected for.&lt;/p&gt;
&lt;p&gt;For results, first it seems like these vector similarities do not correlate particularly strongly with being coreferent.
It could be that the feature on its own isn&amp;rsquo;t enough, or this representation might not be capturing it effectively.
Adding this to the Stanford coreference system they are able to get slight gains, though the improvement might not be statistically significant.&lt;/p&gt;
&lt;p&gt;I&amp;rsquo;m not sure exactly how to do this, but it would be neat if a vector at some point of the model could be modified to remove any correlation with these features, and see what that does to performance.
If performance remains high, then this actually is an uninformative feature, but if it drops that suggests the model is already learning it.&lt;/p&gt;
&lt;h2 id=&#34;citation&#34;&gt;Citation&lt;/h2&gt;
&lt;p&gt;
&lt;a href=&#34;https://aclanthology.org/D17-1138&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Paper&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bibtex&#34;&gt;@InProceedings{heinzerling-moosavi-strube:2017:EMNLP2017,
  author    = {Heinzerling, Benjamin  and  Moosavi, Nafise Sadat  and  Strube, Michael},
  title     = {Revisiting Selectional Preferences for Coreference Resolution},
  booktitle = {Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing},
  month     = {September},
  year      = {2017},
  address   = {Copenhagen, Denmark},
  publisher = {Association for Computational Linguistics},
  pages     = {1332--1339},
  url       = {https://aclanthology.org/D17-1138}
}
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>A causal framework for explaining the predictions of black-box sequence-to-sequence models (Alvarez-Melis et al., 2017)</title>
      <link>https://www.jkk.name/post/2017-12-05_explainingpredictions/</link>
      <pubDate>Tue, 05 Dec 2017 15:40:45 -0500</pubDate>
      <guid>https://www.jkk.name/post/2017-12-05_explainingpredictions/</guid>
      <description>&lt;p&gt;Interpreting the behaviour of statistical models in NLP has been hard for a long time, but it has gotten even harder with nonlinear models.
The simplest method so far in NLP has been to look at the attention distributions in sequence to sequence models, but that doesn&amp;rsquo;t provide everything we need and obviously only applies when the model has attention.
For looking at the dynamics of the hidden state in an LSTM the Harvard NLP group built a cool 
&lt;a href=&#34;http://lstm.seas.harvard.edu/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;visualisation&lt;/a&gt;, but what about structured outputs?&lt;/p&gt;
&lt;p&gt;This paper considers sequence to sequence models and determines which parts of the input were most important for determining each part of the output.
The steps are:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Use a variational autoencoder to get perturbed versions of the input&lt;/li&gt;
&lt;li&gt;Use logistic regression to get scores for every output symbol indicating how sensitive it is to variations in parts of the input&lt;/li&gt;
&lt;li&gt;Create a bipartite graph between inputs and outputs, then find high weight components in the graph&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;These components serve as the representation of which parts of the input determine which parts of the output.
Experiments show results that match with past observations and intuitions, which is good for supporting the effectiveness of the method, but it&amp;rsquo;s a shame this didn&amp;rsquo;t uncover any exciting new patterns.&lt;/p&gt;
&lt;h2 id=&#34;citation&#34;&gt;Citation&lt;/h2&gt;
&lt;p&gt;
&lt;a href=&#34;https://aclanthology.org/D17-1042&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Paper&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bibtex&#34;&gt;@InProceedings{alvarezmelis-jaakkola:2017:EMNLP2017,
  author    = {Alvarez-Melis, David  and  Jaakkola, Tommi},
  title     = {A causal framework for explaining the predictions of black-box sequence-to-sequence models},
  booktitle = {Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing},
  month     = {September},
  year      = {2017},
  address   = {Copenhagen, Denmark},
  publisher = {Association for Computational Linguistics},
  pages     = {412--421},
  url       = {https://aclanthology.org/D17-1042}
}
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Natural Language Does Not Emerge &#39;Naturally&#39; in Multi-Agent Dialog (Kottur et al., 2017)</title>
      <link>https://www.jkk.name/post/2017-11-13_languagegame/</link>
      <pubDate>Mon, 13 Nov 2017 09:47:08 -0500</pubDate>
      <guid>https://www.jkk.name/post/2017-11-13_languagegame/</guid>
      <description>&lt;p&gt;In reference games, two players communicate in a shared world with the goal of one learning what the other is referring to.
Their small scale and clear success criteria make them a convenient testbed for dialogue agents, going back decades, with recent work focusing on neural approaches.
This paper considers a simple game and constrains models in various ways to improve performance and see how their communication varies, a line of work also appearing in recent papers by Jacob Andreas (
&lt;a href=&#34;https://aclanthology.org/P17-1022.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ACL 2017&lt;/a&gt;, 
&lt;a href=&#34;https://aclanthology.org/D17-1311.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;EMNLP 2017&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;The game in this case is to find out two properties of an object, where there are three possible properties, each with four possible values.
Given enough flexibility, models will explicitly encode every possible structure of the world as a separate symbol, which does not generalise well.
Limiting the vocabulary to one symbol per property and one per value helps, but in this particular game there are only 3 possible questions, and over two turns of dialogue the 12 value words are sufficient to encode the space.
Limiting even further, to 4 words for values and providing each turn in isolation to the answerer does lead to some compositionality, but clearly not full compositionality as they still make errors on unseen combinations of the inputs.&lt;/p&gt;
&lt;p&gt;It&amp;rsquo;s a short paper, so they can only do so much, but some experiments I am curious about are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Decrease the questioner vocabulary to 2. This avoids the problem that the questioner can express the task in one step by saying what is not needed. It&amp;rsquo;s still doable, by defining an order for questions, e.g. ask about attribute A vs. B first, then in the second step ask about either C or the other option from the first step. This is a little weird as symbols need to mean different things at different time steps, but would be interesting.&lt;/li&gt;
&lt;li&gt;Increase the number of attributes to 4. This also avoids the task expression problem, by forcing there to be compositionality on the questioner side (watching the video of the talk, someone asked this in the question time, and they didn&amp;rsquo;t know).&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;citation&#34;&gt;Citation&lt;/h2&gt;
&lt;p&gt;
&lt;a href=&#34;https://aclanthology.org/D17-1320&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Paper&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bibtex&#34;&gt;@InProceedings{kottur-EtAl:2017:EMNLP2017,
  author    = {Kottur, Satwik  and  Moura, Jos\&#39;{e}  and  Lee, Stefan  and  Batra, Dhruv},
  title     = {Natural Language Does Not Emerge &#39;Naturally&#39; in Multi-Agent Dialog},
  booktitle = {Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing},
  month     = {September},
  year      = {2017},
  address   = {Copenhagen, Denmark},
  publisher = {Association for Computational Linguistics},
  pages     = {2952--2957},
  url       = {https://aclanthology.org/D17-1320}
}
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Mr. Bennet, his coachman, and the Archbishop walk into a bar but only one of them gets recognized: On The Difficulty of Detecting Characters in Literary Texts (Vala et al., 2015)</title>
      <link>https://www.jkk.name/post/2017-11-06_literarycharacters/</link>
      <pubDate>Mon, 06 Nov 2017 20:16:28 -0500</pubDate>
      <guid>https://www.jkk.name/post/2017-11-06_literarycharacters/</guid>
      <description>&lt;p&gt;NLP tools seem like a natural fit for literary analysis, but the domain shift from news text is large enough to degrade performance to the point where tools are not useful.
Here the specific question is how many characters are there in novels?
NER + coreference would seem to be enough, but an off-the-shelf system fares poorly (and I doubt improvements in the last few years would change that story).&lt;/p&gt;
&lt;p&gt;The solution is to craft a kind of coreference system focused on getting all of the characters, but not necessarily every mention.
The most interesting new piece is how they identify rare characters: identify arguments of verbs that usually take people.
With this tool in hand they analyse patterns of character use over time to test hypotheses from literary analysis.&lt;/p&gt;
&lt;p&gt;Another key piece of this work was a tool to annotate a collection of books with character occurrences.
CHARLES, their tool, is built on top of 
&lt;a href=&#34;http://brat.nlplab.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;brat&lt;/a&gt;, adding features to help multiple annotators coordinate labels (specifically handling the case of new character identification, which modifies the set of linkable entities).&lt;/p&gt;
&lt;p&gt;Finally, they released the character lists identified for the novels considered (
&lt;a href=&#34;https://aclanthology.org/attachments/D/D15/D15-1088.Attachment.zip&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;).
It would be interesting to modify a coreference resolution system to process these books, taking advantage of that information!&lt;/p&gt;
&lt;h2 id=&#34;citation&#34;&gt;Citation&lt;/h2&gt;
&lt;p&gt;
&lt;a href=&#34;https://aclanthology.org/D15-1088&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Paper&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;
&lt;a href=&#34;http://www.lrec-conf.org/proceedings/lrec2016/pdf/1130_Paper.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Annotation Tool Paper&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bibtex&#34;&gt;@InProceedings{vala-EtAl:2015:EMNLP,
  author    = {Vala, Hardik  and  Jurgens, David  and  Piper, Andrew  and  Ruths, Derek},
  title     = {Mr. Bennet, his coachman, and the Archbishop walk into a bar but only one of them gets recognized: On The Difficulty of Detecting Characters in Literary Texts},
  booktitle = {Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing},
  month     = {September},
  year      = {2015},
  address   = {Lisbon, Portugal},
  publisher = {Association for Computational Linguistics},
  pages     = {769--774},
  url       = {https://aclanthology.org/D15-1088}
}
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>A Factored Neural Network Model for Characterizing Online Discussions in Vector Space (Cheng et al., EMNLP 2017)</title>
      <link>https://www.jkk.name/post/2017-10-16_forumrnn/</link>
      <pubDate>Mon, 16 Oct 2017 20:55:07 -0400</pubDate>
      <guid>https://www.jkk.name/post/2017-10-16_forumrnn/</guid>
      <description>&lt;p&gt;Attention - a weighted average over a set of vectors representing context - has consistently produced positive results.
Here we see an example of how it can be applied in the case of modeling a threaded discussion.&lt;/p&gt;
&lt;p&gt;Attention is applied in two ways.
First, over a fixed set of vectors.
This is intended to provide a mechanism to choose between several different sub-models contained within a single model.
Put differently, the vectors provide a set of latent representations that capture each of the different types of posts in the subreddit.
Second, attention over the current utterance is used in the process of predicting responses (at training time only).
This provides an additional source of input to the model, by forcing it to explain the response utterances using the same representations as a source of information.&lt;/p&gt;
&lt;p&gt;The application is a new task, using values assigned to posts = upvotes - downvotes (i.e. Reddit karma).
Predicting the specific value is hard, so the task is split into 7 binary decisions about whether a post has a score higher or lower than some value.
On this task the new approach provides consistent gains, though overall performance remains low (53 - 56%).
Confusingly though, one of the figures (number 4) seems to suggest that it was a single multi-way decision, not a set of binary decisions.
I&amp;rsquo;m also curious about the data, in particular what the distribution of scores is.
The paper mentions it is Zipfian, but surely it would be something double-sided with a massive peak at 0 and a rapid drop in either direction?&lt;/p&gt;
&lt;p&gt;Overall, this is further evidence of the versatility of the idea of attention!&lt;/p&gt;
&lt;h2 id=&#34;citation&#34;&gt;Citation&lt;/h2&gt;
&lt;p&gt;
&lt;a href=&#34;https://aclanthology.org/D17-1242.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Paper&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bibtex&#34;&gt;@InProceedings{cheng-fang-ostendorf:2017:EMNLP2017,
  author    = {Cheng, Hao  and  Fang, Hao  and  Ostendorf, Mari},
  title     = {A Factored Neural Network Model for Characterizing Online Discussions in Vector Space},
  booktitle = {Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing},
  month     = {September},
  year      = {2017},
  address   = {Copenhagen, Denmark},
  publisher = {Association for Computational Linguistics},
  pages     = {2286--2296},
  url       = {https://aclanthology.org/D17-1242}
}
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Getting the Most out of AMR Parsing (Wang and Xue, EMNLP 2017)</title>
      <link>https://www.jkk.name/post/2017-10-12_amralignment/</link>
      <pubDate>Thu, 12 Oct 2017 19:52:34 -0400</pubDate>
      <guid>https://www.jkk.name/post/2017-10-12_amralignment/</guid>
      <description>&lt;p&gt;Abstract Meaning Representation (AMR) structures represent sentence meaning with labeled nodes (concepts) that are related to the words in the sentence, but not explicitly linked to them.
This is a problem for most parsing algorithms, which need a way to efficiently decompose the structure in order to learn how to generate it.
In dependency parsing there are no abstract nodes to generate, in constituency parsing there is a very small set of node types, and for CCG, TAG, etc the labels come from a constrained space.
The solution for many AMR parsers is to have a process for generating the concepts as a first step towards parsing, and to automatically align the training data to guide this concept generation stage.&lt;/p&gt;
&lt;p&gt;The first idea in this paper is about the set of AMR concepts.
Some concepts are easy to link, as the concept clearly maps to a single word in the sentence.
Around a quarter of concepts have a more complex relation, where a set of concepts link to a set of words, for example, named entities.
The idea for these is to identify common subgraphs by abstracting some lexical items.
For example, a teacher and a worker both get mapped to a person concept that is the ARG0 of the lexical item (teach, or work in this case).
This can allow for the generation of entirely novel concepts (e.g. &amp;ldquo;concept&amp;rdquo;-er), giving a 0.6 boost to recall for CAMR simply by making these additional concepts available.
Using a bidirectional LSTM with a character CNN to generate features on likely concepts, there is a gain of 1.0 F1 for the parser.&lt;/p&gt;
&lt;p&gt;The second idea is to improve the alignments used to train concept generation by taking into consideration the graph structure.
To use an aligner developed for machine translation the graph needs to be turned into a linear sequence, but that can lead to strange jumps.
The idea here is to take that into consideration by modifying the calculation of the cost of distortion (i.e. jumping) to be reshaped based on the graph structure.
For optimal alignment quality they consider aligning in either direction, directly changing the distance metric in the English-AMR direction, and just rescaling it to be less sensitive when appropriate for AMR-English.
This is definitely higher precision than prior approaches, but lower recall.
It&amp;rsquo;s hard to tell whether this helps, since the evaluation doesn&amp;rsquo;t separate it out from the first idea (results in section 5.3 are not on the same dataset as 5.1).&lt;/p&gt;
&lt;p&gt;Given how separate this is from CAMR, it would be interesting to see if it helps other systems similarly.
With concept identification at 83 F there is still plenty of scope for improvement, though there is no analysis of which types of concepts remain the most problematic.&lt;/p&gt;
&lt;h2 id=&#34;citation&#34;&gt;Citation&lt;/h2&gt;
&lt;p&gt;
&lt;a href=&#34;https://aclanthology.org/D/D17/D17-1130.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Paper&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bibtex&#34;&gt;@InProceedings{wang-xue:2017:EMNLP2017,
  author    = {Wang, Chuan  and  Xue, Nianwen},
  title     = {Getting the Most out of AMR Parsing},
  booktitle = {Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing},
  month     = {September},
  year      = {2017},
  address   = {Copenhagen, Denmark},
  publisher = {Association for Computational Linguistics},
  pages     = {1268--1279},
  url       = {https://aclanthology.org/D17-1130},
}
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title> Semantic Parsing with Semi-Supervised Sequential Autoencoders (Kocisky et al., EMNLP 2016)</title>
      <link>https://www.jkk.name/post/2017-10-09_parsing-autoencoder/</link>
      <pubDate>Mon, 09 Oct 2017 14:31:24 -0400</pubDate>
      <guid>https://www.jkk.name/post/2017-10-09_parsing-autoencoder/</guid>
      <description>&lt;p&gt;Semantic parsing datasets are small because they are expensive to produce (logical forms don&amp;rsquo;t occur naturally and writing them down takes time).
The idea here is to do semi-supervised learning by implementing both a parser and a generator, which are trained together as a form of autoencoder where the intermediate representation is natural language.&lt;/p&gt;
&lt;p&gt;The architecture has four LSTMs:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Bidirectional LSTM over a logical form.&lt;/li&gt;
&lt;li&gt;One directional LSTM attending to the first LSTM&amp;rsquo;s hidden states, generating a sentence.&lt;/li&gt;
&lt;li&gt;Bidirectional LSTM over the sentence generated by the second LSTM.&lt;/li&gt;
&lt;li&gt;One directional LSTM attending to the third LSTM&amp;rsquo;s hidden states, generating a logical form.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Usually a component like the second LSTM would choose the max word at each position (or use beam search), but here they want this whole thing to be differentiable, so the distribution over words is used.
At evaluation time only the second half (3+4) is used, with the test sentence as input.&lt;/p&gt;
&lt;p&gt;With this structure, a loss function is defined that compares the input to (1) and the output of (4), which in both cases is a logical form.
As a result, they don&amp;rsquo;t need (logical form, sentence) pairs to train, they can use automatically generated logical forms.
Of course, with only logical forms it would do something random with the intermediate representation, so some supervised examples are also needed (in which case the two halves are trained independently).&lt;/p&gt;
&lt;p&gt;The results are not state-of-the-art, but good on all three tasks (Geoquery, NLmaps, SAIL), and on two they show am improvement over training (3+4) with only supervised data.
Varying the amount of training data gives a less clear picture.
On Geoquery with 5-25% of the data, this approach clearly helps, particularly if the queries are real rather than generated (which is a realistic scenario), but then there is no improvement for 50% or 75%, and at 100% the improvement is small.
On NLmaps there was no generator, and the differences at different data %s seem like noise.
SAIL has the most clear benefit, though it&amp;rsquo;s a particularly small dataset, consisting of paths in just four maps.&lt;/p&gt;
&lt;p&gt;This is a cool idea that seems effective in certain situations.
The generator is key, and it&amp;rsquo;s possible that performance on GeoQuery would be higher with a more sophisticated one (e.g. a tree structured generator, rather than the ngram model used here).
One idea mentioned in the conclusion is to try reversing the setup (3-4-1-2) and training with natural language examples that have no logical form.
How to tradeoff the different data scenarios seems like an interesting challenge!&lt;/p&gt;
&lt;h2 id=&#34;citation&#34;&gt;Citation&lt;/h2&gt;
&lt;p&gt;
&lt;a href=&#34;https://aclanthology.org/D16-1116&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Paper&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bibtex&#34;&gt;@InProceedings{kovcisky-EtAl:2016:EMNLP2016,
  author    = {Ko\v{c}isk\&#39;{y}, Tom\&#39;{a}\v{s}  and  Melis, G\&#39;{a}bor  and  Grefenstette, Edward  and  Dyer, Chris  and  Ling, Wang  and  Blunsom, Phil  and  Hermann, Karl Moritz},
  title     = {Semantic Parsing with Semi-Supervised Sequential Autoencoders},
  booktitle = {Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing},
  month     = {November},
  year      = {2016},
  address   = {Austin, Texas},
  publisher = {Association for Computational Linguistics},
  pages     = {1078--1087},
  url       = {https://aclanthology.org/D16-1116}
}
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Filling the Blanks (hint: plural noun) for Mad Libs Humor (Hossain et al., EMNLP 2017)</title>
      <link>https://www.jkk.name/post/2017-10-06-madlibs/</link>
      <pubDate>Fri, 06 Oct 2017 13:31:43 -0400</pubDate>
      <guid>https://www.jkk.name/post/2017-10-06-madlibs/</guid>
      <description>&lt;p&gt;Humor is an incredibly difficult problem, as this paper makes clear in its background section.
Most work has considered very specific types of jokes (e.g. &amp;ldquo;that&amp;rsquo;s what she said&amp;rdquo;, or pairs of words that sound similar to form riddles).
This work contributes (1) a new task, (2) an evaluation method, and (3) an example system.&lt;/p&gt;
&lt;p&gt;The task is Mad Libs, where a story has some words removed and people choose new words to make the story funny.
If you are familiar with the normal version, one key difference is that here people have access to the complete story when they are choosing their words.
A set of 40 &amp;lsquo;stories&amp;rsquo; were written based on Simple Wikipedia articles, and workers on Mechanical Turk wrote words to fill them, with filtering based on judging by other workers.&lt;/p&gt;
&lt;p&gt;The evaluation method involved recruiting a set of judges on Mechanical Turk and asking a series of questions to measure humour for a given response.
As well as judging the overall story, they were asked to select which words contributed the most.
By aggregating these selections as votes, each word was scored as funny or not.&lt;/p&gt;
&lt;p&gt;The system is a linear classifier with a range of features, including scores from a language model.
On its own, it performs very poorly, but using it as a filter to restrict the space of words a person can choose from actually leads to better performance than people on their own.
Of course, it&amp;rsquo;s difficult to analyse the source of improvement;
The authors theorise that it is because it prevents people from selecting words that only they would see is funny.
Another interpretation is that the constraint gives them a smaller space to think about and so they can find more interesting plays on words.&lt;/p&gt;
&lt;p&gt;Finally, as a non-expert in this area, this paper had some nice discussion of the tradeoffs between different ways of generating humour (incongruous vs. coherent content strategies).&lt;/p&gt;
&lt;h2 id=&#34;citation&#34;&gt;Citation&lt;/h2&gt;
&lt;p&gt;
&lt;a href=&#34;https://aclanthology.org/D17-1068&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Paper&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bibtex&#34;&gt;@InProceedings{hossain-EtAl:2017:EMNLP2017,
  author    = {Hossain, Nabil  and  Krumm, John  and  Vanderwende, Lucy  and  Horvitz, Eric  and  Kautz, Henry},
  title     = {Filling the Blanks (hint: plural noun) for Mad Libs Humor},
  booktitle = {Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing},
  month     = {September},
  year      = {2017},
  address   = {Copenhagen, Denmark},
  publisher = {Association for Computational Linguistics},
  pages     = {649--658},
  url       = {https://aclanthology.org/D17-1068},
}
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
  </channel>
</rss>
