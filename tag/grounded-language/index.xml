<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>grounded-language | Jonathan K. Kummerfeld</title>
    <link>http://www.jkk.name/tag/grounded-language/</link>
      <atom:link href="http://www.jkk.name/tag/grounded-language/index.xml" rel="self" type="application/rss+xml" />
    <description>grounded-language</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>Â© 2020 Jonathan K. Kummerfeld</copyright><lastBuildDate>Mon, 13 Nov 2017 09:47:08 -0500</lastBuildDate>
    <image>
      <url>http://www.jkk.name/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_2.png</url>
      <title>grounded-language</title>
      <link>http://www.jkk.name/tag/grounded-language/</link>
    </image>
    
    <item>
      <title>Natural Language Does Not Emerge &#39;Naturally&#39; in Multi-Agent Dialog (Kottur et al., 2017)</title>
      <link>http://www.jkk.name/post/2017-11-13_languagegame/</link>
      <pubDate>Mon, 13 Nov 2017 09:47:08 -0500</pubDate>
      <guid>http://www.jkk.name/post/2017-11-13_languagegame/</guid>
      <description>&lt;p&gt;In reference games, two players communicate in a shared world with the goal of one learning what the other is referring to.
Their small scale and clear success criteria make them a convenient testbed for dialogue agents, going back decades, with recent work focusing on neural approaches.
This paper considers a simple game and constrains models in various ways to improve performance and see how their communication varies, a line of work also appearing in recent papers by Jacob Andreas (
&lt;a href=&#34;https://www.aclweb.org/anthology/P17-1022.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ACL 2017&lt;/a&gt;, 
&lt;a href=&#34;https://www.aclweb.org/anthology/D17-1311.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;EMNLP 2017&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;The game in this case is to find out two properties of an object, where there are three possible properties, each with four possible values.
Given enough flexibility, models will explicitly encode every possible structure of the world as a separate symbol, which does not generalise well.
Limiting the vocabulary to one symbol per property and one per value helps, but in this particular game there are only 3 possible questions, and over two turns of dialogue the 12 value words are sufficient to encode the space.
Limiting even further, to 4 words for values and providing each turn in isolation to the answerer does lead to some compositionality, but clearly not full compositionality as they still make errors on unseen combinations of the inputs.&lt;/p&gt;
&lt;p&gt;It&amp;rsquo;s a short paper, so they can only do so much, but some experiments I am curious about are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Decrease the questioner vocabulary to 2. This avoids the problem that the questioner can express the task in one step by saying what is not needed. It&amp;rsquo;s still doable, by defining an order for questions, e.g. ask about attribute A vs. B first, then in the second step ask about either C or the other option from the first step. This is a little weird as symbols need to mean different things at different time steps, but would be interesting.&lt;/li&gt;
&lt;li&gt;Increase the number of attributes to 4. This also avoids the task expression problem, by forcing there to be compositionality on the questioner side (watching the video of the talk, someone asked this in the question time, and they didn&amp;rsquo;t know).&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;citation&#34;&gt;Citation&lt;/h2&gt;
&lt;p&gt;
&lt;a href=&#34;https://www.aclweb.org/anthology/D17-1320&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Paper&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bibtex&#34;&gt;@InProceedings{kottur-EtAl:2017:EMNLP2017,
  author    = {Kottur, Satwik  and  Moura, Jos\&#39;{e}  and  Lee, Stefan  and  Batra, Dhruv},
  title     = {Natural Language Does Not Emerge &#39;Naturally&#39; in Multi-Agent Dialog},
  booktitle = {Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing},
  month     = {September},
  year      = {2017},
  address   = {Copenhagen, Denmark},
  publisher = {Association for Computational Linguistics},
  pages     = {2952--2957},
  url       = {https://www.aclweb.org/anthology/D17-1320}
}
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
  </channel>
</rss>
