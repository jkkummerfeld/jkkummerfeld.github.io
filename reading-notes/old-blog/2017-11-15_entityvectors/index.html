<!doctype html>
<html lang="en" class="no-js">
  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="generator" content="Hugo 0.74.3" /><META NAME="ROBOTS" CONTENT="INDEX, FOLLOW">


<link rel="shortcut icon" href="/favicons/favicon.ico" >
<link rel="apple-touch-icon" href="/favicons/apple-touch-icon-180x180.png" sizes="180x180">
<link rel="icon" type="image/png" href="/favicons/favicon-16x16.png" sizes="16x16">
<link rel="icon" type="image/png" href="/favicons/favicon-32x32.png" sizes="32x32">
<link rel="icon" type="image/png" href="/favicons/android-36x36.png" sizes="36x36">
<link rel="icon" type="image/png" href="/favicons/android-48x48.png" sizes="48x48">
<link rel="icon" type="image/png" href="/favicons/android-72x72.png" sizes="72x72">
<link rel="icon" type="image/png" href="/favicons/android-96x96.png" sizes="96x96">
<link rel="icon" type="image/png" href="/favicons/android-144x144.png" sizes="144x144">
<link rel="icon" type="image/png" href="/favicons/android-192x192.png" sizes="192x192">

<title>Learning Distributed Representations of Texts and Entities from Knowledge Base (Yamada et al., 2017) | Jonathan K. Kummerfeld</title>


  <meta name="description" content="Vectors for words and entities can be learned by trying to model the text written about the entities. This leads to word vectors that score well on similarity tasks and entity vectors that produce excellent results on entity linking and question answering.">
<meta property="og:title" content="Learning Distributed Representations of Texts and Entities from Knowledge Base (Yamada et al., 2017)" />
<meta property="og:description" content="Vectors for words and entities can be learned by trying to model the text written about the entities. This leads to word vectors that score well on similarity tasks and entity vectors that produce excellent results on entity linking and question answering." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://www.jkk.name/reading-notes/old-blog/2017-11-15_entityvectors/" />
<meta property="article:modified_time" content="2021-11-03T17:10:03-04:00" /><meta property="og:site_name" content="Jonathan K. Kummerfeld" />
<meta itemprop="name" content="Learning Distributed Representations of Texts and Entities from Knowledge Base (Yamada et al., 2017)">
<meta itemprop="description" content="Vectors for words and entities can be learned by trying to model the text written about the entities. This leads to word vectors that score well on similarity tasks and entity vectors that produce excellent results on entity linking and question answering.">
<meta itemprop="dateModified" content="2021-11-03T17:10:03-04:00" />
<meta itemprop="wordCount" content="334">



<meta itemprop="keywords" content="" />
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Learning Distributed Representations of Texts and Entities from Knowledge Base (Yamada et al., 2017)"/>
<meta name="twitter:description" content="Vectors for words and entities can be learned by trying to model the text written about the entities. This leads to word vectors that score well on similarity tasks and entity vectors that produce excellent results on entity linking and question answering."/>




<link rel="preload" href="/scss/main.min.4d6a07626240bcddb820f906b204b0f3398627bb3ab14557de00450e4a44c7b9.css" as="style">
<link href="/scss/main.min.4d6a07626240bcddb820f906b204b0f3398627bb3ab14557de00450e4a44c7b9.css" rel="stylesheet" integrity="">


<script
  src="https://code.jquery.com/jquery-3.5.1.min.js"
  integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0="
  crossorigin="anonymous"></script>

<script
  src="https://unpkg.com/lunr@2.3.8/lunr.min.js"
  integrity="sha384-vRQ9bDyE0Wnu+lMfm57BlYLO0/XauFuKpVsZPs7KEDwYKktWi5+Kz3MP8++DFlRY"
  crossorigin="anonymous"></script>







<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-19179423-2', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>




  </head>
  <body class="td-page">
    <header>
      
<nav class="js-navbar-scroll navbar navbar-expand navbar-dark flex-column flex-md-row td-navbar">
        <a class="navbar-brand" href="/">
		<span class="navbar-logo"></span><span class="text-uppercase font-weight-bold">Jonathan K. Kummerfeld</span>
	</a>
	<div class="td-navbar-nav-scroll ml-md-auto" id="main_navbar">
		<ul class="navbar-nav mt-2 mt-lg-0">
			
			
			
			
		</ul>
	</div>
	<div class="navbar-nav d-none d-lg-block">



<input
  type="search"
  class="form-control td-search-input"
  placeholder="&#xf002; Search this site…"
  aria-label="Search this site…"
  autocomplete="off"
  
  data-offline-search-index-json-src="/offline-search-index.53b961db71346f3689872ba8323c57f2.json"
  data-offline-search-base-href="/"
  data-offline-search-max-results="10"
>

</div>
</nav>

    </header>
    <div class="container-fluid td-default td-outer">
      <main role="main" class="td-main">
        

<p>Since word2vec was released there have been a series of X2vec papers, though none have had the success of word vectors.
In this case the idea is to represent entities and chunks of text (words, sentences, paragraphs).</p>
<p>Entities are represented with vectors.
To get the vector for a chunk of text, they:</p>
<ol>
<li>Sum word vectors for the text.</li>
<li>Rescale to be of unit length.</li>
<li>Multiply by a weight matrix and add a bias.</li>
</ol>
<p>Then to learn these, negative log likelihood is used, where the probability is defined as a softmax over the dot product between entity and text vectors.
The data is a portion of Wikipedia annotated with entities as indicated by links (plus they say the entity the page is about is implicitly part of every sentence).</p>
<p>With these new vectors in hand, they try textual similarity, with strong results.
They also build a very simple entity linking system, a feed-forward network with these representations plus a few other features, and beat all prior work.
Similarly
They apply the same modeling approach to Quizball QA, also with strong results.</p>
<p>The simplicity and effectiveness of the model really is impressive.
Some qualitative examples are included, but hard to find trends in.
It does seem like a more reasonable vector learning approach than skip-thought and other similar approaches that rely only on text context - the entities provide something different, but clearly closely related.
That said, I feel like more ablation is needed to see what role each of these pieces is playing (are they learning better vectors, or using them in a way that is more effective? Or both?).</p>
<h2 id="citation">Citation</h2>
<p><a href="https://www.transacl.org/ojs/index.php/tacl/article/view/1065">Paper</a></p>
<div class="highlight"><pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bibtex" data-lang="bibtex"><span style="color:#000">@article</span><span style="color:#000;font-weight:bold">{</span><span style="color:#f57900">TACL1065</span><span style="color:#000;font-weight:bold">,</span>
<span style="color:#c4a000">author</span> <span style="color:#000;font-weight:bold">=</span> <span style="color:#4e9a06">{Yamada, Ikuya  and Shindo, Hiroyuki  and Takeda, Hideaki  and Takefuji, Yoshiyasu }</span><span style="color:#000;font-weight:bold">,</span>
<span style="color:#c4a000">title</span> <span style="color:#000;font-weight:bold">=</span> <span style="color:#4e9a06">{Learning Distributed Representations of Texts and Entities from Knowledge Base}</span><span style="color:#000;font-weight:bold">,</span>
<span style="color:#c4a000">title:</span> <span style="color:#a40000">{Learning</span> <span style="color:#a40000">Distributed</span> <span style="color:#a40000">Representations</span> <span style="color:#a40000">of</span> <span style="color:#a40000">Texts</span> <span style="color:#a40000">and</span> <span style="color:#a40000">Entities</span> <span style="color:#a40000">from</span> <span style="color:#a40000">Knowledge</span> <span style="color:#a40000">Base},</span>
<span style="color:#a40000">journal</span> <span style="color:#000;font-weight:bold">=</span> <span style="color:#4e9a06">{Transactions of the Association for Computational Linguistics}</span><span style="color:#000;font-weight:bold">,</span>
<span style="color:#c4a000">volume</span> <span style="color:#000;font-weight:bold">=</span> <span style="color:#4e9a06">{5}</span><span style="color:#000;font-weight:bold">,</span>
<span style="color:#c4a000">year</span> <span style="color:#000;font-weight:bold">=</span> <span style="color:#4e9a06">{2017}</span><span style="color:#000;font-weight:bold">,</span>
<span style="color:#c4a000">issn</span> <span style="color:#000;font-weight:bold">=</span> <span style="color:#4e9a06">{2307-387X}</span><span style="color:#000;font-weight:bold">,</span>
<span style="color:#c4a000">url</span> <span style="color:#000;font-weight:bold">=</span> <span style="color:#4e9a06">{https://www.transacl.org/ojs/index.php/tacl/article/view/1065}</span><span style="color:#000;font-weight:bold">,</span>
<span style="color:#c4a000">pages</span> <span style="color:#000;font-weight:bold">=</span> <span style="color:#4e9a06">{397--411}</span>
<span style="color:#000;font-weight:bold">}</span>
</code></pre></div>


      </main>
      
<footer class="bg-dark py-5 row d-print-none">
  <div class="container-fluid mx-sm-5">
    <div class="row">
      <div class="col-6 col-sm-4 text-xs-center order-sm-2">
        
        
        
<ul class="list-inline mb-0">
  
  <li class="list-inline-item mx-2 h3" data-toggle="tooltip" data-placement="top" title="Email" aria-label="Email">
    <a class="text-white" target="_blank" rel="noopener" href="mailto:jkummerf@umich.edu" aria-label="Email">
      <i class="fa fa-envelope"></i>
    </a>
  </li>
  
  <li class="list-inline-item mx-2 h3" data-toggle="tooltip" data-placement="top" title="Twitter" aria-label="Twitter">
    <a class="text-white" target="_blank" rel="noopener" href="https://twitter.com/jkkummerfeld" aria-label="Twitter">
      <i class="fab fa-twitter"></i>
    </a>
  </li>
  
  <li class="list-inline-item mx-2 h3" data-toggle="tooltip" data-placement="top" title="LinkedIn" aria-label="LinkedIn">
    <a class="text-white" target="_blank" rel="noopener" href="https://linkedin.com/in/jkkummerfeld/" aria-label="LinkedIn">
      <i class="fab fa-linkedin"></i>
    </a>
  </li>
  
</ul>

        
        
      </div>
      <div class="col-6 col-sm-4 text-right text-xs-center order-sm-3">
        
        
        
<ul class="list-inline mb-0">
  
  <li class="list-inline-item mx-2 h3" data-toggle="tooltip" data-placement="top" title="GitHub" aria-label="GitHub">
    <a class="text-white" target="_blank" rel="noopener" href="https://github.com/jkkummerfeld" aria-label="GitHub">
      <i class="fab fa-github"></i>
    </a>
  </li>
  
  <li class="list-inline-item mx-2 h3" data-toggle="tooltip" data-placement="top" title="ACL Anthology" aria-label="ACL Anthology">
    <a class="text-white" target="_blank" rel="noopener" href="https://aclanthology.org/anthology/people/j/jonathan-k-kummerfeld/" aria-label="ACL Anthology">
      <i class="icon icon-acl-logo"></i>
    </a>
  </li>
  
  <li class="list-inline-item mx-2 h3" data-toggle="tooltip" data-placement="top" title="Semantic Scholar" aria-label="Semantic Scholar">
    <a class="text-white" target="_blank" rel="noopener" href="https://semanticscholar.org/author/Jonathan-K.-Kummerfeld/1727211" aria-label="Semantic Scholar">
      <i class="ai ai-semantic-scholar"></i>
    </a>
  </li>
  
  <li class="list-inline-item mx-2 h3" data-toggle="tooltip" data-placement="top" title="Google Scholar" aria-label="Google Scholar">
    <a class="text-white" target="_blank" rel="noopener" href="https://scholar.google.com/citations?user=OsoNG9AAAAAJ" aria-label="Google Scholar">
      <i class="ai ai-google-scholar"></i>
    </a>
  </li>
  
  <li class="list-inline-item mx-2 h3" data-toggle="tooltip" data-placement="top" title="DBLP" aria-label="DBLP">
    <a class="text-white" target="_blank" rel="noopener" href="https://dblp.uni-trier.de/pers/hd/k/Kummerfeld:Jonathan_K=" aria-label="DBLP">
      <i class="ai ai-dblp"></i>
    </a>
  </li>
  
  <li class="list-inline-item mx-2 h3" data-toggle="tooltip" data-placement="top" title="ArXiv" aria-label="ArXiv">
    <a class="text-white" target="_blank" rel="noopener" href="https://arxiv.org/a/kummerfeld_j_1" aria-label="ArXiv">
      <i class="ai ai-arxiv"></i>
    </a>
  </li>
  
  <li class="list-inline-item mx-2 h3" data-toggle="tooltip" data-placement="top" title="OrcID" aria-label="OrcID">
    <a class="text-white" target="_blank" rel="noopener" href="https://orcid.org/0000-0001-5030-3016" aria-label="OrcID">
      <i class="ai ai-orcid"></i>
    </a>
  </li>
  
</ul>

        
        
      </div>
      <div class="col-12 col-sm-4 text-center py-2 order-sm-2">
        <small class="text-white">&copy; 2021 Jonathan K. Kummerfeld All Rights Reserved</small>
        
	
		<p class="mt-2"><a href="/about/">About</a></p>
	
      </div>
    </div>
  </div>
</footer>


    </div>
    <script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.1/dist/umd/popper.min.js" integrity="sha384-9/reFTGAW83EW2RDu2S0VKaIzap3H66lZH81PoYlFhbGU+6BZp6G7niu735Sk7lN" crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.0/dist/js/bootstrap.min.js" integrity="sha384-+YQ4JLhjyBLPDQt//I+STsc9iw4uQqACwlvpslubQzn4u2UU2UFM80nGisd026JF" crossorigin="anonymous"></script>





<script src='/js/tabpane-persist.js'></script>




 

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.2/dist/katex.min.css" integrity="sha384-Cqd8ihRLum0CCg8rz0hYKPoLZ3uw+gES2rXQXycqnL5pgVQIflxAUDS7ZSjITLb5" crossorigin="anonymous">

<script defer src="https://cdn.jsdelivr.net/npm/katex@0.13.2/dist/katex.min.js" integrity="sha384-1Or6BdeNQb0ezrmtGeqQHFpppNd7a/gw29xeiSikBbsb44xu3uAo8c7FwbF5jhbd" crossorigin="anonymous"></script>
 


<script defer src='https://cdn.jsdelivr.net/npm/katex@0.13.2/dist/contrib/auto-render.min.js' integrity='sha384-vZTG03m+2yp6N6BNi5iM4rW4oIwk5DfcNdFfxkk9ZWpDriOkXX8voJBFrAO7MpVl' crossorigin='anonymous' onload='renderMathInElement(document.body, null);'></script>














<script src="/js/main.min.da35b82a1ff45cca90044ed24861e456ad09e5523c8cfcdd66939e705b594419.js" integrity="sha256-2jW4Kh/0XMqQBE7SSGHkVq0J5VI8jPzdZpOecFtZRBk=" crossorigin="anonymous"></script>




  </body>
</html>