<!doctype html>
<html lang="en" class="no-js">
  <head>
    <link rel="stylesheet" href="https://www.jkk.name/plugins/my-custom/css/mycustom.css"><link rel="stylesheet" href="https://www.jkk.name/plugins/academic-icons/css/academicons.css">
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="generator" content="Hugo 0.111.3">
<link rel="alternate" type="application/rss&#43;xml" href="https://www.jkk.name/pubs/index.xml">
<meta name="robots" content="index, follow">


<link rel="shortcut icon" href="/favicons/favicon.ico" >
<link rel="apple-touch-icon" href="/favicons/apple-touch-icon-180x180.png" sizes="180x180">
<link rel="icon" type="image/png" href="/favicons/favicon-16x16.png" sizes="16x16">
<link rel="icon" type="image/png" href="/favicons/favicon-32x32.png" sizes="32x32">
<link rel="icon" type="image/png" href="/favicons/android-36x36.png" sizes="36x36">
<link rel="icon" type="image/png" href="/favicons/android-48x48.png" sizes="48x48">
<link rel="icon" type="image/png" href="/favicons/android-72x72.png" sizes="72x72">
<link rel="icon" type="image/png" href="/favicons/android-96x96.png" sizes="96x96">
<link rel="icon" type="image/png" href="/favicons/android-144x144.png" sizes="144x144">
<link rel="icon" type="image/png" href="/favicons/android-192x192.png" sizes="192x192">

<title>Publications | Jonathan K. Kummerfeld</title>
<meta name="description" content="These are my publications and prepints.
">
<meta property="og:title" content="Publications" />
<meta property="og:description" content="These are my publications and prepints.
" />
<meta property="og:type" content="website" />
<meta property="og:url" content="https://www.jkk.name/pubs/" /><meta property="og:site_name" content="Jonathan K. Kummerfeld" />
<meta itemprop="name" content="Publications">
<meta itemprop="description" content="These are my publications and prepints.
"><meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Publications"/>
<meta name="twitter:description" content="These are my publications and prepints.
"/>




<link rel="preload" href="/scss/main.min.0dfa6f2329873fc2190908b72854dd7514cdcd182b431bcdb412facf973beffe.css" as="style">
<link href="/scss/main.min.0dfa6f2329873fc2190908b72854dd7514cdcd182b431bcdb412facf973beffe.css" rel="stylesheet" integrity="">

<script
  src="https://code.jquery.com/jquery-3.6.0.min.js"
  integrity="sha384-vtXRMe3mGCbOeY7l30aIg8H9p3GdeSe4IFlP6G8JMa7o7lXvnz3GFKzPxzJdPfGK"
  crossorigin="anonymous"></script>
<script
  src="https://unpkg.com/lunr@2.3.9/lunr.min.js"
  integrity="sha384-203J0SNzyqHby3iU6hzvzltrWi/M41wOP5Gu+BiJMz5nwKykbkUx8Kp7iti0Lpli"
  crossorigin="anonymous"></script>

<script async src="https://www.googletagmanager.com/gtag/js?id=G-JVV2VPL5CX"></script>
<script>
var doNotTrack = false;
if (!doNotTrack) {
	window.dataLayer = window.dataLayer || [];
	function gtag(){dataLayer.push(arguments);}
	gtag('js', new Date());
	gtag('config', 'G-JVV2VPL5CX', { 'anonymize_ip': false });
}
</script>

  </head>
  <body class="td-section">
    <div class="container-fluid td-outer">
      <div class="td-main">
        <div class="row flex-xl-nowrap">
          <aside class="col-12 col-md-3 col-xl-2 td-sidebar d-print-none">
            
<div id="td-sidebar-menu" class="td-sidebar__inner">
  <nav class="collapse td-sidebar-nav" id="td-section-nav">
    <ul class="td-sidebar-nav__section pr-md-3 ul-0">
      <li class="td-sidebar-nav__section-title td-sidebar-nav__section with-child active-path" id="m--li">
  <a href="/" class="align-left pl-0 td-sidebar-link td-sidebar-link__section tree-root" id="m-"><span class="">Jonathan K. Kummerfeld&#39;s Homepage</span></a>
  <ul class="ul-1">
    <li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id="m-home-li">
  <a href="/home/" class="align-left pl-0 td-sidebar-link td-sidebar-link__section" id="m-home"><i class="fas fa-home"></i><span class="">Home</span></a>
</li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id="m-bio_and_cv-li">
  <a href="/bio_and_cv/" class="align-left pl-0 td-sidebar-link td-sidebar-link__section" id="m-bio_and_cv"><i class="fas fa-male"></i><span class="">Bio &amp; CV</span></a>
</li><li class="td-sidebar-nav__section-title td-sidebar-nav__section with-child" id="m-students-li">
  <a href="/students/" class="align-left pl-0 td-sidebar-link td-sidebar-link__section" id="m-students"><i class="fas fa-users"></i><span class="">Students</span></a>
  <ul class="ul-2 foldable">
    <li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child collapse" id="m-studentsrecruiting-phd-li">
  <a href="/students/recruiting-phd/" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id="m-studentsrecruiting-phd"><span class="">Recruiting: PhD</span></a>
</li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child collapse" id="m-studentsrecruiting-ms-li">
  <a href="/students/recruiting-ms/" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id="m-studentsrecruiting-ms"><span class="">Recruiting: Masters</span></a>
</li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child collapse" id="m-studentsrecruiting-ug-li">
  <a href="/students/recruiting-ug/" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id="m-studentsrecruiting-ug"><span class="">Recruiting: Undergraduates</span></a>
</li>
  </ul>
</li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id="m-pubs-li">
  <a href="/pubs/" class="align-left pl-0 active td-sidebar-link td-sidebar-link__section" id="m-pubs"><i class="fas fa-file-alt"></i><span class="td-sidebar-nav-active-item">Publications</span></a>
</li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id="m-teaching-li">
  <a href="/teaching/" class="align-left pl-0 td-sidebar-link td-sidebar-link__section" id="m-teaching"><i class="fas fa-graduation-cap"></i><span class="">Teaching</span></a>
</li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id="m-software-li">
  <a href="/software/" class="align-left pl-0 td-sidebar-link td-sidebar-link__section" id="m-software"><i class="fas fa-code"></i><span class="">Software</span></a>
</li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id="m-data-li">
  <a href="/data/" class="align-left pl-0 td-sidebar-link td-sidebar-link__section" id="m-data"><i class="fas fa-database"></i><span class="">Datasets</span></a>
</li><li class="td-sidebar-nav__section-title td-sidebar-nav__section with-child" id="m-reading-notes-li">
  <a href="/reading-notes/" class="align-left pl-0 td-sidebar-link td-sidebar-link__section" id="m-reading-notes"><i class="fas fa-book-reader"></i><span class="">Reading Notes</span></a>
  <ul class="ul-2 foldable">
    <li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child collapse" id="m-reading-notescoreference-li">
  <a href="/reading-notes/coreference/" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id="m-reading-notescoreference"><span class="">Coreference Resolution</span></a>
</li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child collapse" id="m-reading-notescrowdsourcing-li">
  <a href="/reading-notes/crowdsourcing/" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id="m-reading-notescrowdsourcing"><span class="">Crowdsourcing and Data Annotation</span></a>
</li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child collapse" id="m-reading-notesdiplomacy-li">
  <a href="/reading-notes/diplomacy/" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id="m-reading-notesdiplomacy"><span class="">Diplomacy</span></a>
</li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child collapse" id="m-reading-notesexsempar-li">
  <a href="/reading-notes/exsempar/" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id="m-reading-notesexsempar"><span class="">Executable Semantic Parsing</span></a>
</li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child collapse" id="m-reading-noteslanguage-models-li">
  <a href="/reading-notes/language-models/" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id="m-reading-noteslanguage-models"><span class="">Language Models</span></a>
</li><li class="td-sidebar-nav__section-title td-sidebar-nav__section with-child collapse" id="m-reading-notesold-blog-li">
  <a href="/reading-notes/old-blog/" title="Old Blog Posts" class="align-left pl-0 td-sidebar-link td-sidebar-link__section" id="m-reading-notesold-blog"><span class="">Olg Blog Posts</span></a>
  <ul class="ul-3 foldable">
    <li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child collapse" id="m-reading-notesold-blog2017-10-09_parsing-autoencoder-li">
  <a href="/reading-notes/old-blog/2017-10-09_parsing-autoencoder/" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id="m-reading-notesold-blog2017-10-09_parsing-autoencoder"><span class=""> Semantic Parsing with Semi-Supervised Sequential Autoencoders (Kocisky et al., EMNLP 2016)</span></a>
</li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child collapse" id="m-reading-notesold-blog2017-12-05_explainingpredictions-li">
  <a href="/reading-notes/old-blog/2017-12-05_explainingpredictions/" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id="m-reading-notesold-blog2017-12-05_explainingpredictions"><span class="">A causal framework for explaining the predictions of black-box sequence-to-sequence models (Alvarez-Melis et al., 2017)</span></a>
</li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child collapse" id="m-reading-notesold-blog2017-10-16_forumrnn-li">
  <a href="/reading-notes/old-blog/2017-10-16_forumrnn/" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id="m-reading-notesold-blog2017-10-16_forumrnn"><span class="">A Factored Neural Network Model for Characterizing Online Discussions in Vector Space (Cheng et al., EMNLP 2017)</span></a>
</li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child collapse" id="m-reading-notesold-blog2019-07-10_disentanglement-li">
  <a href="/reading-notes/old-blog/2019-07-10_disentanglement/" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id="m-reading-notesold-blog2019-07-10_disentanglement"><span class="">A Large-Scale Corpus for Conversation Disentanglement (Kummerfeld et al., 2019)</span></a>
</li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child collapse" id="m-reading-notesold-blog2017-12-01_nonsequencener-li">
  <a href="/reading-notes/old-blog/2017-12-01_nonsequencener/" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id="m-reading-notesold-blog2017-12-01_nonsequencener"><span class="">A Local Detection Approach for Named Entity Recognition and Mention Detection (Xu et al., 2017)</span></a>
</li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child collapse" id="m-reading-notesold-blog2020-10-04_crowdsrl-li">
  <a href="/reading-notes/old-blog/2020-10-04_crowdsrl/" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id="m-reading-notesold-blog2020-10-04_crowdsrl"><span class="">A Novel Workflow for Accurately and Efficiently Crowdsourcing Predicate Senses and Argument Labels (Jiang, et al., Findings of EMNLP 2020)</span></a>
</li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child collapse" id="m-reading-notesold-blog2017-12-12_multidomainwordvector-li">
  <a href="/reading-notes/old-blog/2017-12-12_multidomainwordvector/" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id="m-reading-notesold-blog2017-12-12_multidomainwordvector"><span class="">A Simple Regularization-based Algorithm for Learning Cross-Domain Word Embeddings (Yang et al., 2017)</span></a>
</li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child collapse" id="m-reading-notesold-blog2017-11-16_ucca-li">
  <a href="/reading-notes/old-blog/2017-11-16_ucca/" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id="m-reading-notesold-blog2017-11-16_ucca"><span class="">A Transition-Based Directed Acyclic Graph Parser for UCCA (Hershcovich et al., 2017)</span></a>
</li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child collapse" id="m-reading-notesold-blog2017-11-17_twostagediscourseparsing-li">
  <a href="/reading-notes/old-blog/2017-11-17_twostagediscourseparsing/" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id="m-reading-notesold-blog2017-11-17_twostagediscourseparsing"><span class="">A Two-Stage Parsing Method for Text-Level Discourse Analysis (Wang et al., 2017)</span></a>
</li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child collapse" id="m-reading-notesold-blog2017-11-29_abstractivesummarisation-li">
  <a href="/reading-notes/old-blog/2017-11-29_abstractivesummarisation/" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id="m-reading-notesold-blog2017-11-29_abstractivesummarisation"><span class="">Abstractive Document Summarization with a Graph-Based Attentional Neural Model (Tan et al., 2017)</span></a>
</li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child collapse" id="m-reading-notesold-blog2017-10-18_neuralamr-li">
  <a href="/reading-notes/old-blog/2017-10-18_neuralamr/" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id="m-reading-notesold-blog2017-10-18_neuralamr"><span class="">Addressing the Data Sparsity Issue in Neural AMR Parsing (Peng et al., EACL 2017)</span></a>
</li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child collapse" id="m-reading-notesold-blog2018-04-16_lm_analysis-li">
  <a href="/reading-notes/old-blog/2018-04-16_lm_analysis/" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id="m-reading-notesold-blog2018-04-16_lm_analysis"><span class="">An Analysis of Neural Language Modeling at Multiple Scales (Merity et al., 2018)</span></a>
</li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child collapse" id="m-reading-notesold-blog2019-09-22_conferenceapproach-li">
  <a href="/reading-notes/old-blog/2019-09-22_conferenceapproach/" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id="m-reading-notesold-blog2019-09-22_conferenceapproach"><span class="">Approaching Conferences</span></a>
</li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child collapse" id="m-reading-notesold-blog2017-11-07_spineparsinglstm-li">
  <a href="/reading-notes/old-blog/2017-11-07_spineparsinglstm/" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id="m-reading-notesold-blog2017-11-07_spineparsinglstm"><span class="">Arc-Standard Spinal Parsing with Stack-LSTMs (Ballesteros et al., 2017)</span></a>
</li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child collapse" id="m-reading-notesold-blog2017-10-20_onlyattention-li">
  <a href="/reading-notes/old-blog/2017-10-20_onlyattention/" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id="m-reading-notesold-blog2017-10-20_onlyattention"><span class="">Attention Is All You Need (Vaswani et al., ArXiv 2017)</span></a>
</li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child collapse" id="m-reading-notesold-blog2017-11-21_multiinputattention-li">
  <a href="/reading-notes/old-blog/2017-11-21_multiinputattention/" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id="m-reading-notesold-blog2017-11-21_multiinputattention"><span class="">Attention Strategies for Multi-Source Sequence-to-Sequence Learning (Libovicky et al., 2017)</span></a>
</li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child collapse" id="m-reading-notesold-blog2020-09-03_checklist-li">
  <a href="/reading-notes/old-blog/2020-09-03_checklist/" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id="m-reading-notesold-blog2020-09-03_checklist"><span class="">Beyond Accuracy: Behavioral Testing of NLP Models with CheckList (Ribeiro, et al., ACL 2020 Best Paper)</span></a>
</li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child collapse" id="m-reading-notesold-blog2020-09-07_chartdialogs-li">
  <a href="/reading-notes/old-blog/2020-09-07_chartdialogs/" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id="m-reading-notesold-blog2020-09-07_chartdialogs"><span class="">ChartDialogs: Plotting from Natural Language Instructions (Shao and Nakashole, ACL 2020)</span></a>
</li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child collapse" id="m-reading-notesold-blog2020-10-10_demographicembeddings-li">
  <a href="/reading-notes/old-blog/2020-10-10_demographicembeddings/" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id="m-reading-notesold-blog2020-10-10_demographicembeddings"><span class="">Compositional Demographic Word Embeddings (Welch et al., EMNLP 2020)</span></a>
</li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child collapse" id="m-reading-notesold-blog2020-09-25_crowdqasrl-li">
  <a href="/reading-notes/old-blog/2020-09-25_crowdqasrl/" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id="m-reading-notesold-blog2020-09-25_crowdqasrl"><span class="">Controlled Crowdsourcing for High-Quality QA-SRL Annotation (Roit, et al., ACL 2020)</span></a>
</li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child collapse" id="m-reading-notesold-blog2017-10-05-deftnn-li">
  <a href="/reading-notes/old-blog/2017-10-05-deftnn/" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id="m-reading-notesold-blog2017-10-05-deftnn"><span class="">DeftNN: Addressing Bottlenecks for DNN Execution on GPUs via Synapse Vector Elimination and Near-compute Data Fission (Hill et al., MICRO 2017)</span></a>
</li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child collapse" id="m-reading-notesold-blog2017-10-13_errordetection-li">
  <a href="/reading-notes/old-blog/2017-10-13_errordetection/" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id="m-reading-notesold-blog2017-10-13_errordetection"><span class="">Detecting annotation noise in automatically labelled data (Rehbein and Ruppenhofer, ACL 2017)</span></a>
</li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child collapse" id="m-reading-notesold-blog2017-10-30_neuralsequence-li">
  <a href="/reading-notes/old-blog/2017-10-30_neuralsequence/" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id="m-reading-notesold-blog2017-10-30_neuralsequence"><span class="">Dynamic Evaluation of Neural Sequence Models (Krause et al., 2017)</span></a>
</li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child collapse" id="m-reading-notesold-blog2017-10-24_dynamictransition-li">
  <a href="/reading-notes/old-blog/2017-10-24_dynamictransition/" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id="m-reading-notesold-blog2017-10-24_dynamictransition"><span class="">Dynamic Programming Algorithms for Transition-Based Dependency Parsers (Kuhlmann et al., ACL 2011)</span></a>
</li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child collapse" id="m-reading-notesold-blog2017-11-22_errorrepairparsing-li">
  <a href="/reading-notes/old-blog/2017-11-22_errorrepairparsing/" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id="m-reading-notesold-blog2017-11-22_errorrepairparsing"><span class="">Error-repair Dependency Parsing for Ungrammatical Texts (Sakaguchi et al., 2017)</span></a>
</li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child collapse" id="m-reading-notesold-blog2018-09-04_featureengineering-li">
  <a href="/reading-notes/old-blog/2018-09-04_featureengineering/" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id="m-reading-notesold-blog2018-09-04_featureengineering"><span class="">Evaluating the Utility of Hand-crafted Features in Sequence Labelling (Minghao Wu et al., 2018)</span></a>
</li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child collapse" id="m-reading-notesold-blog2018-01-28_crowdassistant-li">
  <a href="/reading-notes/old-blog/2018-01-28_crowdassistant/" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id="m-reading-notesold-blog2018-01-28_crowdassistant"><span class="">Evorus: A Crowd-powered Conversational Assistant Built to Automate Itself Over Time (Huang et al., 2018)</span></a>
</li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child collapse" id="m-reading-notesold-blog2018-06-12_parseradaptation-li">
  <a href="/reading-notes/old-blog/2018-06-12_parseradaptation/" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id="m-reading-notesold-blog2018-06-12_parseradaptation"><span class="">Extending a Parser to Distant Domains Using a Few Dozen Partially Annotated Examples (Vidur Joshi et al., 2018)</span></a>
</li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child collapse" id="m-reading-notesold-blog2017-10-06-madlibs-li">
  <a href="/reading-notes/old-blog/2017-10-06-madlibs/" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id="m-reading-notesold-blog2017-10-06-madlibs"><span class="">Filling the Blanks (hint: plural noun) for Mad Libs Humor (Hossain et al., EMNLP 2017)</span></a>
</li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child collapse" id="m-reading-notesold-blog2017-11-09_framesdataset-li">
  <a href="/reading-notes/old-blog/2017-11-09_framesdataset/" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id="m-reading-notesold-blog2017-11-09_framesdataset"><span class="">Frames: a corpus for adding memory to goal-oriented dialogue systems (El Asri et al., 2017)</span></a>
</li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child collapse" id="m-reading-notesold-blog2017-10-12_amralignment-li">
  <a href="/reading-notes/old-blog/2017-10-12_amralignment/" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id="m-reading-notesold-blog2017-10-12_amralignment"><span class="">Getting the Most out of AMR Parsing (Wang and Xue, EMNLP 2017)</span></a>
</li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child collapse" id="m-reading-notesold-blog2017-10-11_multimt-li">
  <a href="/reading-notes/old-blog/2017-10-11_multimt/" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id="m-reading-notesold-blog2017-10-11_multimt"><span class="">Google&#39;s Multilingual Neural Machine Translation System: Enabling Zero-Shot Translation (Johnson et al., TACL 2017)</span></a>
</li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child collapse" id="m-reading-notesold-blog2017-12-07_rarewordvectors-li">
  <a href="/reading-notes/old-blog/2017-12-07_rarewordvectors/" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id="m-reading-notesold-blog2017-12-07_rarewordvectors"><span class="">High-risk learning: acquiring new word vectors from tiny data (Herbelot et al., 2017)</span></a>
</li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child collapse" id="m-reading-notesold-blog2020-12-10_dynamicannoallocation-li">
  <a href="/reading-notes/old-blog/2020-12-10_dynamicannoallocation/" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id="m-reading-notesold-blog2020-12-10_dynamicannoallocation"><span class="">Improving Human-Labeled Data through Dynamic Automatic Conflict Resolution (Sun, et al., CoLing 2020)</span></a>
</li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child collapse" id="m-reading-notesold-blog2020-09-29_pretraininglm-li">
  <a href="/reading-notes/old-blog/2020-09-29_pretraininglm/" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id="m-reading-notesold-blog2020-09-29_pretraininglm"><span class="">Improving Low Compute Language Modeling with In-Domain Embedding Initialisation (Welch, Mihalcea, and Kummerfeld, EMNLP 2020)</span></a>
</li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child collapse" id="m-reading-notesold-blog2017-11-14_inorderparsing-li">
  <a href="/reading-notes/old-blog/2017-11-14_inorderparsing/" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id="m-reading-notesold-blog2017-11-14_inorderparsing"><span class="">In-Order Transition-based Constituent Parsing (Liu et al., 2017)</span></a>
</li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child collapse" id="m-reading-notesold-blog2020-10-12_taboo-li">
  <a href="/reading-notes/old-blog/2020-10-12_taboo/" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id="m-reading-notesold-blog2020-10-12_taboo"><span class="">Iterative Feature Mining for Constraint-Based Data Collection to Increase Data Diversity and Model Robustness (Larson, et al., EMNLP 2020)</span></a>
</li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child collapse" id="m-reading-notesold-blog2017-11-30_taggingrelations-li">
  <a href="/reading-notes/old-blog/2017-11-30_taggingrelations/" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id="m-reading-notesold-blog2017-11-30_taggingrelations"><span class="">Joint Extraction of Entities and Relations Based on a Novel Tagging Scheme (Zheng et al., 2017)</span></a>
</li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child collapse" id="m-reading-notesold-blog2017-11-03_discourserelations-li">
  <a href="/reading-notes/old-blog/2017-11-03_discourserelations/" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id="m-reading-notesold-blog2017-11-03_discourserelations"><span class="">Joint Modeling of Content and Discourse Relations in Dialogues (Qin et al., 2017)</span></a>
</li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child collapse" id="m-reading-notesold-blog2017-11-15_entityvectors-li">
  <a href="/reading-notes/old-blog/2017-11-15_entityvectors/" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id="m-reading-notesold-blog2017-11-15_entityvectors"><span class="">Learning Distributed Representations of Texts and Entities from Knowledge Base (Yamada et al., 2017)</span></a>
</li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child collapse" id="m-reading-notesold-blog2017-11-08_graphdialogue-li">
  <a href="/reading-notes/old-blog/2017-11-08_graphdialogue/" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id="m-reading-notesold-blog2017-11-08_graphdialogue"><span class="">Learning Symmetric Collaborative Dialogue Agents with Dynamic Knowledge Graph Embeddings (He et al., 2017)</span></a>
</li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child collapse" id="m-reading-notesold-blog2018-03-05_curriculum-li">
  <a href="/reading-notes/old-blog/2018-03-05_curriculum/" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id="m-reading-notesold-blog2018-03-05_curriculum"><span class="">Learning the Curriculum with Bayesian Optimization for Task-Specific Word Representation Learning (Tsvetkov et al., 2016)</span></a>
</li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child collapse" id="m-reading-notesold-blog2017-10-19_mace-li">
  <a href="/reading-notes/old-blog/2017-10-19_mace/" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id="m-reading-notesold-blog2017-10-19_mace"><span class="">Learning Whom to Trust with MACE (Hovy et al., NAACL 2013)</span></a>
</li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child collapse" id="m-reading-notesold-blog2017-11-10_kginlstm-li">
  <a href="/reading-notes/old-blog/2017-11-10_kginlstm/" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id="m-reading-notesold-blog2017-11-10_kginlstm"><span class="">Leveraging Knowledge Bases in LSTMs for Improving Machine Reading (Yang et al., 2017)</span></a>
</li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child collapse" id="m-reading-notesold-blog2017-10-23_alphagozero-li">
  <a href="/reading-notes/old-blog/2017-10-23_alphagozero/" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id="m-reading-notesold-blog2017-10-23_alphagozero"><span class="">Mastering the game of Go without human knowledge (Silver et al., Nature 2017)</span></a>
</li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child collapse" id="m-reading-notesold-blog2017-11-06_literarycharacters-li">
  <a href="/reading-notes/old-blog/2017-11-06_literarycharacters/" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id="m-reading-notesold-blog2017-11-06_literarycharacters"><span class="">Mr. Bennet, his coachman, and the Archbishop walk into a bar but only one of them gets recognized: On The Difficulty of Detecting Characters in Literary Texts (Vala et al., 2015)</span></a>
</li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child collapse" id="m-reading-notesold-blog2017-10-26_multimodalwordembeddings-li">
  <a href="/reading-notes/old-blog/2017-10-26_multimodalwordembeddings/" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id="m-reading-notesold-blog2017-10-26_multimodalwordembeddings"><span class="">Multimodal Word Distributions (Athiwaratkun and Wilson, 2017)</span></a>
</li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child collapse" id="m-reading-notesold-blog2017-10-17_nedisambiguation-li">
  <a href="/reading-notes/old-blog/2017-10-17_nedisambiguation/" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id="m-reading-notesold-blog2017-10-17_nedisambiguation"><span class="">Named Entity Disambiguation for Noisy Text (Eshel et al., CoNLL 2017)</span></a>
</li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child collapse" id="m-reading-notesold-blog2017-11-13_languagegame-li">
  <a href="/reading-notes/old-blog/2017-11-13_languagegame/" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id="m-reading-notesold-blog2017-11-13_languagegame"><span class="">Natural Language Does Not Emerge &#39;Naturally&#39; in Multi-Agent Dialog (Kottur et al., 2017)</span></a>
</li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child collapse" id="m-reading-notesold-blog2017-12-05_multidomainparsing-li">
  <a href="/reading-notes/old-blog/2017-12-05_multidomainparsing/" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id="m-reading-notesold-blog2017-12-05_multidomainparsing"><span class="">Neural Semantic Parsing over Multiple Knowledge-bases (Herzig et al., 2017)</span></a>
</li>
  </ul>
</li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child collapse" id="m-reading-notesmisc-li">
  <a href="/reading-notes/misc/" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id="m-reading-notesmisc"><span class="">Other</span></a>
</li>
  </ul>
</li><li class="td-sidebar-nav__section-title td-sidebar-nav__section with-child" id="m-advice-li">
  <a href="/advice/" class="align-left pl-0 td-sidebar-link td-sidebar-link__section" id="m-advice"><i class="fas fa-comment"></i><span class="">Advice</span></a>
  <ul class="ul-2 foldable">
    <li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child collapse" id="m-adviceposters-li">
  <a href="/advice/posters/" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id="m-adviceposters"><span class="">Academic Posters</span></a>
</li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child collapse" id="m-adviceemail-li">
  <a href="/advice/email/" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id="m-adviceemail"><span class="">Email Clients</span></a>
</li>
  </ul>
</li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id="m-group-management-li">
  <a href="/group-management/" class="align-left pl-0 td-sidebar-link td-sidebar-link__section" id="m-group-management"><i class="fas fa-book"></i><span class="">Group Processes</span></a>
</li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id="m-sponsor-li">
  <a href="/sponsor/" class="align-left pl-0 td-sidebar-link td-sidebar-link__section" id="m-sponsor"><i class="fas fa-dollar-sign"></i><span class="">Sponsors</span></a>
</li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id="m-contact-li">
  <a href="/contact/" class="align-left pl-0 td-sidebar-link td-sidebar-link__section" id="m-contact"><i class="fas fa-phone"></i><span class="">Contact</span></a>
</li>
  </ul>
</li>
    </ul>
  </nav>
  <form class="td-sidebar__search d-flex align-items-center">
    <input
  type="search"
  class="form-control td-search-input"
  placeholder="&#xf002; Search this site…"
  aria-label="Search this site…"
  autocomplete="off"
  
  data-offline-search-index-json-src="/offline-search-index.c71d80a00cca0926ad397542fbac00c1.json"
  data-offline-search-base-href="/"
  data-offline-search-max-results="10"
>

    <button class="btn btn-link td-sidebar__toggle d-md-none p-0 ml-3 fas fa-bars" type="button" data-toggle="collapse" data-target="#td-section-nav" aria-controls="td-docs-nav" aria-expanded="false" aria-label="Toggle section navigation">
    </button>
  </form>
  </div>


          </aside>
          <aside class="d-none d-xl-block col-xl-2 td-sidebar-toc d-print-none">
            
<div class="td-page-meta ml-2 pb-1 pt-2 mb-0">

</div>

            


<div class="td-toc"><nav id="TableOfContents">
  <ul>
    <li>
      <ul>
        <li><a href="#2024">2024</a></li>
        <li><a href="#2023">2023</a></li>
        <li><a href="#2022">2022</a></li>
        <li><a href="#2021">2021</a></li>
        <li><a href="#2020">2020</a></li>
        <li><a href="#2019">2019</a></li>
        <li><a href="#2018">2018</a></li>
        <li><a href="#2017">2017</a></li>
        <li><a href="#2016">2016</a></li>
        <li><a href="#2015">2015</a></li>
        <li><a href="#2013">2013</a></li>
        <li><a href="#2012">2012</a></li>
        <li><a href="#2011">2011</a></li>
        <li><a href="#2010">2010</a></li>
        <li><a href="#2009">2009</a></li>
        <li><a href="#2008">2008</a></li>
      </ul>
    </li>
    <li><a href="#non-archival">Non-Archival</a>
      <ul>
        <li><a href="#2024-1">2024</a></li>
        <li><a href="#2022-1">2022</a></li>
        <li><a href="#2020-1">2020</a></li>
        <li><a href="#2019-1">2019</a></li>
        <li><a href="#2018-1">2018</a></li>
        <li><a href="#2009-1">2009</a></li>
      </ul>
    </li>
  </ul>
</nav></div>



            

	
		
			
				
			
			



  
  

		
			
				
			
			



  
  

		
	

          </aside>
          <main class="col-12 col-md-9 col-xl-8 pl-md-5" role="main">
            
  

            

            
<div class="td-content">
  
	<header class="article-meta">
		
		
			
				


			
				


			
		
		
	</header>
        <div class="section-index">
    
    
    
    
    
    
    
    
    
</div>

	<h3 id="2024">2024</h3>
<div class="container pb-2">
  <div class="row">
    <div class="col-lg-6">
      <strong>An AI-Resilient Text Rendering Technique for Reading and Skimming Documents</strong>
      <br />
      <span class="text-muted">Ziwei Gu, Ian Arawjo, Kenneth Li, Jonathan K. Kummerfeld, Elena L. Glassman</span>
      <br />
      CHI<span class="text-muted">, 2024</span>
    </div>
    <div class="col-lg-6">
      <a class="btn btn-outline-primary btn-sm" href="https://arxiv.org/abs/2401.10873" target="_blank" rel="noopener"><span
    class="fontawesome-inline-svg"
    style="display: inline-flex; align-self: center; height:1em; width:1em; top: .125em; position: relative;"
><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path fill='currentColor' d="M256 0v128h128L256 0zM224 128L224 0H48C21.49 0 0 21.49 0 48v416C0 490.5 21.49 512 48 512h288c26.51 0 48-21.49 48-48V160h-127.1C238.3 160 224 145.7 224 128zM272 416h-160C103.2 416 96 408.8 96 400C96 391.2 103.2 384 112 384h160c8.836 0 16 7.162 16 16C288 408.8 280.8 416 272 416zM272 352h-160C103.2 352 96 344.8 96 336C96 327.2 103.2 320 112 320h160c8.836 0 16 7.162 16 16C288 344.8 280.8 352 272 352zM288 272C288 280.8 280.8 288 272 288h-160C103.2 288 96 280.8 96 272C96 263.2 103.2 256 112 256h160C280.8 256 288 263.2 288 272z"/></svg>
</span>
 PDF</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('ch124gptsm-abstract').style.display == 'block') {
  document.getElementById('ch124gptsm-abstract').style.display='none';
  } else {
  document.getElementById('ch124gptsm-abstract').style.display='block';
  }
  ">Abstract</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('ch124gptsm-cite').style.display == 'block') {
  document.getElementById('ch124gptsm-cite').style.display='none';
  } else {
  document.getElementById('ch124gptsm-cite').style.display='block';
  }
  ">BibTeX</a>
      
      
      
      
      
      
      
    </div>
  </div>
  <div class="row" id="ch124gptsm-abstract" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          Readers find text difficult to consume for many reasons. Summarization can address some of these difficulties, but introduce others, such as omitting, misrepresenting, or hallucinating information, which can be hard for a reader to notice. One approach to addressing this problem is to instead modify how the original text is rendered to make important information more salient. We introduce Grammar-Preserving Text Saliency Modulation (GP-TSM), a text rendering method with a novel means of identifying what to de-emphasize. Specifically, GP-TSM uses a recursive sentence compression method to identify successive levels of detail beyond the core meaning of a passage, which are de-emphasized by rendering words in successively lighter but still legible gray text. In a lab study (n=18), participants preferred GP-TSM over pre-existing word-level text rendering methods and were able to answer GRE reading comprehension questions more efficiently.
        </p>
    </div>
  </div>
  <div class="row" id="ch124gptsm-cite" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          
        <pre>
        @InProceedings{ch124gptsm,
  author    = {Ziwei Gu and Ian Arawjo and Kenneth Li and Jonathan K. Kummerfeld and Elena L. Glassman},
  title     = {An AI-Resilient Text Rendering Technique for Reading and Skimming Documents},
  booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
  location  = {Honolulu, HI, USA},
  month     = {May},
  year      = {2024},
  doi       = {},
  pages     = {},
  url       = {},
  arxiv     = {https://arxiv.org/abs/2401.10873},
  data      = {},
}
        </pre>
        
        </p>
    </div>
  </div>
</div>


<div class="container pb-2">
  <div class="row">
    <div class="col-lg-6">
      <strong>Supporting Sensemaking of Large Language Model Outputs at Scale\n</strong>
      <br />
      <span class="text-muted">Katy Ilonka Gero, Chelse Swoopes, Ziwei Gu, Jonathan K. Kummerfeld, Elena L. Glassman</span>
      <br />
      CHI<span class="text-muted">, 2024</span>
    </div>
    <div class="col-lg-6">
      <a class="btn btn-outline-primary btn-sm" href="https://arxiv.org/abs/2401.13726" target="_blank" rel="noopener"><span
    class="fontawesome-inline-svg"
    style="display: inline-flex; align-self: center; height:1em; width:1em; top: .125em; position: relative;"
><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path fill='currentColor' d="M256 0v128h128L256 0zM224 128L224 0H48C21.49 0 0 21.49 0 48v416C0 490.5 21.49 512 48 512h288c26.51 0 48-21.49 48-48V160h-127.1C238.3 160 224 145.7 224 128zM272 416h-160C103.2 416 96 408.8 96 400C96 391.2 103.2 384 112 384h160c8.836 0 16 7.162 16 16C288 408.8 280.8 416 272 416zM272 352h-160C103.2 352 96 344.8 96 336C96 327.2 103.2 320 112 320h160c8.836 0 16 7.162 16 16C288 344.8 280.8 352 272 352zM288 272C288 280.8 280.8 288 272 288h-160C103.2 288 96 280.8 96 272C96 263.2 103.2 256 112 256h160C280.8 256 288 263.2 288 272z"/></svg>
</span>
 PDF</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('ch124sense-abstract').style.display == 'block') {
  document.getElementById('ch124sense-abstract').style.display='none';
  } else {
  document.getElementById('ch124sense-abstract').style.display='block';
  }
  ">Abstract</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('ch124sense-cite').style.display == 'block') {
  document.getElementById('ch124sense-cite').style.display='none';
  } else {
  document.getElementById('ch124sense-cite').style.display='block';
  }
  ">BibTeX</a>
      
      
      
      
      
      
      
    </div>
  </div>
  <div class="row" id="ch124sense-abstract" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          Large language models (LLMs) are capable of generating multiple responses to a single prompt, yet little effort has been expended to help end-users or system designers make use of this capability. In this paper, we explore how to present many LLM responses at once. We design five features, which include both pre-existing and novel methods for computing similarities and differences across textual documents, as well as how to render their outputs. We report on a controlled user study (n=24) and eight case studies evaluating these features and how they support users in different tasks. We find that the features support a wide variety of sensemaking tasks and even make tasks previously considered to be too difficult by our participants now tractable. Finally, we present design guidelines to inform future explorations of new LLM interfaces.
        </p>
    </div>
  </div>
  <div class="row" id="ch124sense-cite" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          
        <pre>
        @InProceedings{ch124sense,
  author    = {Katy Ilonka Gero and Chelse Swoopes and Ziwei Gu and Jonathan K. Kummerfeld and Elena L. Glassman},
  title     = {Supporting Sensemaking of Large Language Model Outputs at Scale
},
  booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
  location  = {Honolulu, HI, USA},
  month     = {May},
  year      = {2024},
  doi       = {},
  pages     = {},
  url       = {},
  arxiv     = {https://arxiv.org/abs/2401.13726},
  data      = {},
}
        </pre>
        
        </p>
    </div>
  </div>
</div>


<div class="container pb-2">
  <div class="row">
    <div class="col-lg-6">
      <strong>A Comparative Multidimensional Analysis of Empathetic Systems</strong>
      <br />
      <span class="text-muted">Andrew Lee, Jonathan K. Kummerfeld, Lawrence C. An, Rada Mihalcea</span>
      <br />
      EACL<span class="text-muted">, 2024</span>
    </div>
    <div class="col-lg-6">
      <a class="btn btn-outline-primary btn-sm" href="" target="_blank" rel="noopener"><span
    class="fontawesome-inline-svg"
    style="display: inline-flex; align-self: center; height:1em; width:1em; top: .125em; position: relative;"
><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path fill='currentColor' d="M256 0v128h128L256 0zM224 128L224 0H48C21.49 0 0 21.49 0 48v416C0 490.5 21.49 512 48 512h288c26.51 0 48-21.49 48-48V160h-127.1C238.3 160 224 145.7 224 128zM272 416h-160C103.2 416 96 408.8 96 400C96 391.2 103.2 384 112 384h160c8.836 0 16 7.162 16 16C288 408.8 280.8 416 272 416zM272 352h-160C103.2 352 96 344.8 96 336C96 327.2 103.2 320 112 320h160c8.836 0 16 7.162 16 16C288 344.8 280.8 352 272 352zM288 272C288 280.8 280.8 288 272 288h-160C103.2 288 96 280.8 96 272C96 263.2 103.2 256 112 256h160C280.8 256 288 263.2 288 272z"/></svg>
</span>
 PDF</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('eacl24empathy-abstract').style.display == 'block') {
  document.getElementById('eacl24empathy-abstract').style.display='none';
  } else {
  document.getElementById('eacl24empathy-abstract').style.display='block';
  }
  ">Abstract</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('eacl24empathy-cite').style.display == 'block') {
  document.getElementById('eacl24empathy-cite').style.display='none';
  } else {
  document.getElementById('eacl24empathy-cite').style.display='block';
  }
  ">BibTeX</a>
      
      
      
      
      
      
      
    </div>
  </div>
  <div class="row" id="eacl24empathy-abstract" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          Recently, empathetic dialogue systems have received significant attention. While some researchers have noted limitations, e.g., that these systems tend to generate generic utterances, no study has systematically verified these issues.  We survey 21 systems, asking what progress has been made on the task. We observe multiple limitations of current evaluation procedures.  Most critically, studies tend to rely on a single non-reproducible empathy score, which inadequately reflects the multidimensional nature of empathy. To better understand the differences between systems, we comprehensively analyze each system with automated methods that are grounded in a variety of aspects of empathy.  We find that recent systems lack three important aspects of empathy: specificity, reflection levels, and diversity. Based on our results, we discuss problematic behaviors that may have gone undetected in prior evaluations, and offer guidance for developing future systems.
        </p>
    </div>
  </div>
  <div class="row" id="eacl24empathy-cite" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          
        <pre>
        @InProceedings{eacl24empathy,
  title     = {A Comparative Multidimensional Analysis of Empathetic Systems},
  author    = {Lee, Andrew and Kummerfeld, Jonathan K. and An, Lawrence C. and Mihalcea, Rada},
  year      = {2024},
  booktitle = {Proceedings of the 18th Conference of the European Chapter of the Association for Computational Linguistics},
  month     = {},
  url       = {},
  location  = {},
  pages     = {},
}
        </pre>
        
        </p>
    </div>
  </div>
</div>


<h3 id="2023">2023</h3>
<div class="container pb-2">
  <div class="row">
    <div class="col-lg-6">
      <strong>Interactive Text-to-{SQL} Generation via Editable Step-by-Step Explanations</strong>
      <br />
      <span class="text-muted">Yuan Tian, Zheng Zhang, Zheng Ning, Toby Li, Jonathan K. Kummerfeld, Tianyi Zhang</span>
      <br />
      EMNLP<span class="text-muted">, 2023</span>
    </div>
    <div class="col-lg-6">
      <a class="btn btn-outline-primary btn-sm" href="https://aclanthology.org/2023.emnlp-main.1004" target="_blank" rel="noopener"><span
    class="fontawesome-inline-svg"
    style="display: inline-flex; align-self: center; height:1em; width:1em; top: .125em; position: relative;"
><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path fill='currentColor' d="M256 0v128h128L256 0zM224 128L224 0H48C21.49 0 0 21.49 0 48v416C0 490.5 21.49 512 48 512h288c26.51 0 48-21.49 48-48V160h-127.1C238.3 160 224 145.7 224 128zM272 416h-160C103.2 416 96 408.8 96 400C96 391.2 103.2 384 112 384h160c8.836 0 16 7.162 16 16C288 408.8 280.8 416 272 416zM272 352h-160C103.2 352 96 344.8 96 336C96 327.2 103.2 320 112 320h160c8.836 0 16 7.162 16 16C288 344.8 280.8 352 272 352zM288 272C288 280.8 280.8 288 272 288h-160C103.2 288 96 280.8 96 272C96 263.2 103.2 256 112 256h160C280.8 256 288 263.2 288 272z"/></svg>
</span>
 PDF</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('emnlp23sql-abstract').style.display == 'block') {
  document.getElementById('emnlp23sql-abstract').style.display='none';
  } else {
  document.getElementById('emnlp23sql-abstract').style.display='block';
  }
  ">Abstract</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('emnlp23sql-cite').style.display == 'block') {
  document.getElementById('emnlp23sql-cite').style.display='none';
  } else {
  document.getElementById('emnlp23sql-cite').style.display='block';
  }
  ">BibTeX</a>
      
      
      
      
      <a class="btn btn-outline-primary btn-sm" href="https://github.com/magic-YuanTian/STEPS" target="_blank" rel="noopener"><span
    class="fontawesome-inline-svg"
    style="display: inline-flex; align-self: center; height:1em; width:1em; top: .125em; position: relative;"
><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512"><path fill='currentColor' d="M414.8 40.79L286.8 488.8C281.9 505.8 264.2 515.6 247.2 510.8C230.2 505.9 220.4 488.2 225.2 471.2L353.2 23.21C358.1 6.216 375.8-3.624 392.8 1.232C409.8 6.087 419.6 23.8 414.8 40.79H414.8zM518.6 121.4L630.6 233.4C643.1 245.9 643.1 266.1 630.6 278.6L518.6 390.6C506.1 403.1 485.9 403.1 473.4 390.6C460.9 378.1 460.9 357.9 473.4 345.4L562.7 256L473.4 166.6C460.9 154.1 460.9 133.9 473.4 121.4C485.9 108.9 506.1 108.9 518.6 121.4V121.4zM166.6 166.6L77.25 256L166.6 345.4C179.1 357.9 179.1 378.1 166.6 390.6C154.1 403.1 133.9 403.1 121.4 390.6L9.372 278.6C-3.124 266.1-3.124 245.9 9.372 233.4L121.4 121.4C133.9 108.9 154.1 108.9 166.6 121.4C179.1 133.9 179.1 154.1 166.6 166.6V166.6z"/></svg>
</span>
 Software</a>
      
      
      <a class="btn btn-outline-primary btn-sm" href="https://www.jkk.name/pub/emnlp23sql_poster.pdf" target="_blank" rel="noopener">Poster</a>
      
      
      
    </div>
  </div>
  <div class="row" id="emnlp23sql-abstract" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          Relational databases play an important role in business, science, and more. However, many users cannot fully unleash the analytical power of relational databases, because they are not familiar with database languages such as SQL. Many techniques have been proposed to automatically generate SQL from natural language, but they suffer from two issues: (1) they still make many mistakes, particularly for complex queries, and (2) they do not provide a flexible way for non-expert users to validate and refine incorrect queries. To address these issues, we introduce a new interaction mechanism that allows users to directly edit a step-by-step explanation of a query to fix errors. Our experiments on multiple datasets, as well as a user study with 24 participants, demonstrate that our approach can achieve better performance than multiple SOTA approaches. Our code and datasets are available at https://github.com/magic-YuanTian/STEPS.
        </p>
    </div>
  </div>
  <div class="row" id="emnlp23sql-cite" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          
        <pre>
        @inproceedings{emnlp23sql,
  title     = {Interactive Text-to-{SQL} Generation via Editable Step-by-Step Explanations},
  author    = {Yuan Tian and Zheng Zhang and Zheng Ning and Toby Li and Jonathan K. Kummerfeld and Tianyi Zhang},
  booktitle = {Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing},
  month     = {December},
  year      = {2023},
  address   = {Singapore},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2023.emnlp-main.1004},
  doi       = {10.18653/v1/2023.emnlp-main.1004},
  pages     = {16149--16166},
  software  = {https://github.com/magic-YuanTian/STEPS},
  poster    = {https://www.jkk.name/pub/emnlp23sql_poster.pdf},
}
        </pre>
        
        </p>
    </div>
  </div>
</div>


<div class="container pb-2">
  <div class="row">
    <div class="col-lg-6">
      <strong>Empathy Identification Systems are not Accurately Accounting for Context</strong>
      <br />
      <span class="text-muted">Andrew Lee, Jonathan K. Kummerfeld, Lawrence C. An, Rada Mihalcea</span>
      <br />
      EACL<span class="text-muted">, 2023</span>
    </div>
    <div class="col-lg-6">
      <a class="btn btn-outline-primary btn-sm" href="https://aclanthology.org/2023.eacl-main.123/" target="_blank" rel="noopener"><span
    class="fontawesome-inline-svg"
    style="display: inline-flex; align-self: center; height:1em; width:1em; top: .125em; position: relative;"
><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path fill='currentColor' d="M256 0v128h128L256 0zM224 128L224 0H48C21.49 0 0 21.49 0 48v416C0 490.5 21.49 512 48 512h288c26.51 0 48-21.49 48-48V160h-127.1C238.3 160 224 145.7 224 128zM272 416h-160C103.2 416 96 408.8 96 400C96 391.2 103.2 384 112 384h160c8.836 0 16 7.162 16 16C288 408.8 280.8 416 272 416zM272 352h-160C103.2 352 96 344.8 96 336C96 327.2 103.2 320 112 320h160c8.836 0 16 7.162 16 16C288 344.8 280.8 352 272 352zM288 272C288 280.8 280.8 288 272 288h-160C103.2 288 96 280.8 96 272C96 263.2 103.2 256 112 256h160C280.8 256 288 263.2 288 272z"/></svg>
</span>
 PDF</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('eacl23empathy-abstract').style.display == 'block') {
  document.getElementById('eacl23empathy-abstract').style.display='none';
  } else {
  document.getElementById('eacl23empathy-abstract').style.display='block';
  }
  ">Abstract</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('eacl23empathy-cite').style.display == 'block') {
  document.getElementById('eacl23empathy-cite').style.display='none';
  } else {
  document.getElementById('eacl23empathy-cite').style.display='block';
  }
  ">BibTeX</a>
      
      
      
      
      
      
      
    </div>
  </div>
  <div class="row" id="eacl23empathy-abstract" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          Understanding empathy in text dialogue data is a difficult, yet critical, skill for effective human-machine interaction. In this work, we ask whether systems are making meaningful progress on this challenge. We consider a simple model that checks if an input utterance is similar to a small set of empathetic examples. Crucially, the model does not look at what the utterance is a response to, i.e., the dialogue context. This model performs comparably to other work on standard benchmarks and even outperforms state-of-the-art models for empathetic rationale extraction by 16.7 points on T-F1 and 4.3 on IOU-F1. This indicates that current systems rely on the surface form of the response, rather than whether it is suitable in context. To confirm this, we create examples with dialogue contexts that change the interpretation of the response and show that current systems continue to label utterances as empathetic. We discuss the implications of our findings, including improvements for empathetic benchmarks and how our model can be an informative baseline.
        </p>
    </div>
  </div>
  <div class="row" id="eacl23empathy-cite" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          
        <pre>
        @InProceedings{eacl23empathy,
  title     = {Empathy Identification Systems are not Accurately Accounting for Context},
  author    = {Lee, Andrew and Kummerfeld, Jonathan K. and An, Lawrence C. and Mihalcea, Rada},
  year      = {2023},
  booktitle = {Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics},
  month     = {May},
  url       = {https://aclanthology.org/2023.eacl-main.123/},
  location  = {Dubrovnik, Croatia},
  pages     = {1686--1695},
}
        </pre>
        
        </p>
    </div>
  </div>
</div>


<div class="container pb-2">
  <div class="row">
    <div class="col-lg-6">
      <strong>Chat Disentanglement: Data for New Domains and Methods for More Accurate Annotation</strong>
      <br />
      <span class="text-muted">Sai R. Gouravajhala, Andrew M. Vernier, Yiming Shi, Zihan Li, Mark Ackerman, Jonathan K. Kummerfeld</span>
      <br />
      ALTA<span class="text-muted">, 2023</span>
    </div>
    <div class="col-lg-6">
      <a class="btn btn-outline-primary btn-sm" href="" target="_blank" rel="noopener"><span
    class="fontawesome-inline-svg"
    style="display: inline-flex; align-self: center; height:1em; width:1em; top: .125em; position: relative;"
><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path fill='currentColor' d="M256 0v128h128L256 0zM224 128L224 0H48C21.49 0 0 21.49 0 48v416C0 490.5 21.49 512 48 512h288c26.51 0 48-21.49 48-48V160h-127.1C238.3 160 224 145.7 224 128zM272 416h-160C103.2 416 96 408.8 96 400C96 391.2 103.2 384 112 384h160c8.836 0 16 7.162 16 16C288 408.8 280.8 416 272 416zM272 352h-160C103.2 352 96 344.8 96 336C96 327.2 103.2 320 112 320h160c8.836 0 16 7.162 16 16C288 344.8 280.8 352 272 352zM288 272C288 280.8 280.8 288 272 288h-160C103.2 288 96 280.8 96 272C96 263.2 103.2 256 112 256h160C280.8 256 288 263.2 288 272z"/></svg>
</span>
 PDF</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('alta23disentangle-abstract').style.display == 'block') {
  document.getElementById('alta23disentangle-abstract').style.display='none';
  } else {
  document.getElementById('alta23disentangle-abstract').style.display='block';
  }
  ">Abstract</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('alta23disentangle-cite').style.display == 'block') {
  document.getElementById('alta23disentangle-cite').style.display='none';
  } else {
  document.getElementById('alta23disentangle-cite').style.display='block';
  }
  ">BibTeX</a>
      
      
      
      <a class="btn btn-outline-primary btn-sm" href="https://www.jkk.name/irc-disentanglement" target="_blank" rel="noopener"><span
    class="fontawesome-inline-svg"
    style="display: inline-flex; align-self: center; height:1em; width:1em; top: .125em; position: relative;"
><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill='currentColor' d="M448 80V128C448 172.2 347.7 208 224 208C100.3 208 0 172.2 0 128V80C0 35.82 100.3 0 224 0C347.7 0 448 35.82 448 80zM393.2 214.7C413.1 207.3 433.1 197.8 448 186.1V288C448 332.2 347.7 368 224 368C100.3 368 0 332.2 0 288V186.1C14.93 197.8 34.02 207.3 54.85 214.7C99.66 230.7 159.5 240 224 240C288.5 240 348.3 230.7 393.2 214.7V214.7zM54.85 374.7C99.66 390.7 159.5 400 224 400C288.5 400 348.3 390.7 393.2 374.7C413.1 367.3 433.1 357.8 448 346.1V432C448 476.2 347.7 512 224 512C100.3 512 0 476.2 0 432V346.1C14.93 357.8 34.02 367.3 54.85 374.7z"/></svg>
</span>
 Data</a>
      
      
      
      
      
    </div>
  </div>
  <div class="row" id="alta23disentangle-abstract" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          
        </p>
    </div>
  </div>
  <div class="row" id="alta23disentangle-cite" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          
        <pre>
        @InProceedings{alta23disentangle,
  author    = {Sai R. Gouravajhala and Andrew M. Vernier and Yiming Shi and Zihan Li and Mark Ackerman and Jonathan K. Kummerfeld},
  title     = {Chat Disentanglement: Data for New Domains and Methods for More Accurate Annotation},
  booktitle = {Proceedings of the The 21st Annual Workshop of the Australasian Language Technology Association},
  location  = {Melbourne, Australia},
  month     = {November},
  year      = {2023},
  doi       = {},
  pages     = {},
  url       = {},
  arxiv     = {},
  data      = {https://www.jkk.name/irc-disentanglement},
}
        </pre>
        
        </p>
    </div>
  </div>
</div>


<h3 id="2022">2022</h3>
<div class="container pb-2">
  <div class="row">
    <div class="col-lg-6">
      <strong>Leveraging Similar Users for Personalized Language Modeling with Limited Data</strong>
      <br />
      <span class="text-muted">Charles Welch, Chenxi Gu, Jonathan K. Kummerfeld, Veronica Perez-Rosas, Rada Mihalcea</span>
      <br />
      ACL<span class="text-muted">, 2022</span>
    </div>
    <div class="col-lg-6">
      <a class="btn btn-outline-primary btn-sm" href="https://aclanthology.org/2022.acl-long.122" target="_blank" rel="noopener"><span
    class="fontawesome-inline-svg"
    style="display: inline-flex; align-self: center; height:1em; width:1em; top: .125em; position: relative;"
><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path fill='currentColor' d="M256 0v128h128L256 0zM224 128L224 0H48C21.49 0 0 21.49 0 48v416C0 490.5 21.49 512 48 512h288c26.51 0 48-21.49 48-48V160h-127.1C238.3 160 224 145.7 224 128zM272 416h-160C103.2 416 96 408.8 96 400C96 391.2 103.2 384 112 384h160c8.836 0 16 7.162 16 16C288 408.8 280.8 416 272 416zM272 352h-160C103.2 352 96 344.8 96 336C96 327.2 103.2 320 112 320h160c8.836 0 16 7.162 16 16C288 344.8 280.8 352 272 352zM288 272C288 280.8 280.8 288 272 288h-160C103.2 288 96 280.8 96 272C96 263.2 103.2 256 112 256h160C280.8 256 288 263.2 288 272z"/></svg>
</span>
 PDF</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('acl22personal-abstract').style.display == 'block') {
  document.getElementById('acl22personal-abstract').style.display='none';
  } else {
  document.getElementById('acl22personal-abstract').style.display='block';
  }
  ">Abstract</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('acl22personal-cite').style.display == 'block') {
  document.getElementById('acl22personal-cite').style.display='none';
  } else {
  document.getElementById('acl22personal-cite').style.display='block';
  }
  ">BibTeX</a>
      
      
      
      
      
      
      
    </div>
  </div>
  <div class="row" id="acl22personal-abstract" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          Personalized language models are designed and trained to capture language patterns specific to individual users. This makes them more accurate at predicting what a user will write. However, when a new user joins a platform and not enough text is available, it is harder to build effective personalized language models. We propose a solution for this problem, using a model trained on users that are similar to a new user. In this paper, we explore strategies for finding the similarity between new users and existing ones and methods for using the data from existing users who are a good match. We further explore the trade-off between available data for new users and how well their language can be modeled.
        </p>
    </div>
  </div>
  <div class="row" id="acl22personal-cite" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          
        <pre>
        @InProceedings{acl22personal,
  title     = {Leveraging Similar Users for Personalized Language Modeling with Limited Data},
  author    = {Welch, Charles and Gu, Chenxi and Kummerfeld, Jonathan K. and Perez-Rosas, Veronica and Mihalcea, Rada},
  booktitle = {Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  month     = {May},
  year      = {2022},
  address   = {Dublin, Ireland},
  url       = {https://aclanthology.org/2022.acl-long.122},
  doi       = {10.18653/v1/2022.acl-long.122},
  pages     = {1742--1752},
}
        </pre>
        
        </p>
    </div>
  </div>
</div>


<div class="container pb-2">
  <div class="row">
    <div class="col-lg-6">
      <strong>Using Paraphrases to Study Properties of Contextual Embeddings</strong>
      <br />
      <span class="text-muted">Laura Burdick, Jonathan K. Kummerfeld, Rada Mihalcea</span>
      <br />
      NAACL<span class="text-muted">, 2022</span>
    </div>
    <div class="col-lg-6">
      <a class="btn btn-outline-primary btn-sm" href="https://aclanthology.org/2022.naacl-main.338" target="_blank" rel="noopener"><span
    class="fontawesome-inline-svg"
    style="display: inline-flex; align-self: center; height:1em; width:1em; top: .125em; position: relative;"
><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path fill='currentColor' d="M256 0v128h128L256 0zM224 128L224 0H48C21.49 0 0 21.49 0 48v416C0 490.5 21.49 512 48 512h288c26.51 0 48-21.49 48-48V160h-127.1C238.3 160 224 145.7 224 128zM272 416h-160C103.2 416 96 408.8 96 400C96 391.2 103.2 384 112 384h160c8.836 0 16 7.162 16 16C288 408.8 280.8 416 272 416zM272 352h-160C103.2 352 96 344.8 96 336C96 327.2 103.2 320 112 320h160c8.836 0 16 7.162 16 16C288 344.8 280.8 352 272 352zM288 272C288 280.8 280.8 288 272 288h-160C103.2 288 96 280.8 96 272C96 263.2 103.2 256 112 256h160C280.8 256 288 263.2 288 272z"/></svg>
</span>
 PDF</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('naacl22embeddings-abstract').style.display == 'block') {
  document.getElementById('naacl22embeddings-abstract').style.display='none';
  } else {
  document.getElementById('naacl22embeddings-abstract').style.display='block';
  }
  ">Abstract</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('naacl22embeddings-cite').style.display == 'block') {
  document.getElementById('naacl22embeddings-cite').style.display='none';
  } else {
  document.getElementById('naacl22embeddings-cite').style.display='block';
  }
  ">BibTeX</a>
      
      
      
      
      
      
      
    </div>
  </div>
  <div class="row" id="naacl22embeddings-abstract" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          We use paraphrases as a unique source of data to analyze contextualized embeddings, with a particular focus on BERT. Because paraphrases naturally encode consistent word and phrase semantics, they provide a unique lens for investigating properties of embeddings. Using the Paraphrase Database{&#39;}s alignments, we study words within paraphrases as well as phrase representations. We find that contextual embeddings effectively handle polysemous words, but give synonyms surprisingly different representations in many cases. We confirm previous findings that BERT is sensitive to word order, but find slightly different patterns than prior work in terms of the level of contextualization across BERT{&#39;}s layers.
        </p>
    </div>
  </div>
  <div class="row" id="naacl22embeddings-cite" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          
        <pre>
        @InProceedings{naacl22embeddings,
  title     = {Using Paraphrases to Study Properties of Contextual Embeddings},
  author    = {Burdick, Laura and Kummerfeld, Jonathan K. and Mihalcea, Rada},
  booktitle = {Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
  location  = {Seattle, United States},
  pages     = {4558--4568},
  month     = {July},
  year      = {2022},
  url       = {https://aclanthology.org/2022.naacl-main.338},
}
        </pre>
        
        </p>
    </div>
  </div>
</div>


<div class="container pb-2">
  <div class="row">
    <div class="col-lg-6">
      <strong>Augmenting Task-Oriented Dialogue Systems with Relation Extraction</strong>
      <br />
      <span class="text-muted">Andrew Lee, Zhenguo Chen, Kevin Leach, Jonathan K. Kummerfeld</span>
      <br />
      AAAI Wokshop: Dialogue System Technology Challenges<span class="text-muted">, 2022</span>
    </div>
    <div class="col-lg-6">
      <a class="btn btn-outline-primary btn-sm" href="https://arxiv.org/pdf/2210.13344.pdf" target="_blank" rel="noopener"><span
    class="fontawesome-inline-svg"
    style="display: inline-flex; align-self: center; height:1em; width:1em; top: .125em; position: relative;"
><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path fill='currentColor' d="M256 0v128h128L256 0zM224 128L224 0H48C21.49 0 0 21.49 0 48v416C0 490.5 21.49 512 48 512h288c26.51 0 48-21.49 48-48V160h-127.1C238.3 160 224 145.7 224 128zM272 416h-160C103.2 416 96 408.8 96 400C96 391.2 103.2 384 112 384h160c8.836 0 16 7.162 16 16C288 408.8 280.8 416 272 416zM272 352h-160C103.2 352 96 344.8 96 336C96 327.2 103.2 320 112 320h160c8.836 0 16 7.162 16 16C288 344.8 280.8 352 272 352zM288 272C288 280.8 280.8 288 272 288h-160C103.2 288 96 280.8 96 272C96 263.2 103.2 256 112 256h160C280.8 256 288 263.2 288 272z"/></svg>
</span>
 PDF</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('ws-aaai-dstc22re-abstract').style.display == 'block') {
  document.getElementById('ws-aaai-dstc22re-abstract').style.display='none';
  } else {
  document.getElementById('ws-aaai-dstc22re-abstract').style.display='block';
  }
  ">Abstract</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('ws-aaai-dstc22re-cite').style.display == 'block') {
  document.getElementById('ws-aaai-dstc22re-cite').style.display='none';
  } else {
  document.getElementById('ws-aaai-dstc22re-cite').style.display='block';
  }
  ">BibTeX</a>
      
      
      
      
      
      
      
    </div>
  </div>
  <div class="row" id="ws-aaai-dstc22re-abstract" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          The standard task-oriented dialogue pipeline uses intent classification and slot-filling to interpret user utterances. While this approach can handle a wide range of queries, it does not extract the information needed to handle more complex queries that contain relationships between slots. We propose integration of relation extraction into this pipeline as an effective way to expand the capabilities of dialogue systems. We evaluate our approach by using an internal dataset with slot and relation annotations spanning three domains. Finally, we show how slot-filling annotation schemes can be simplified once the expressive power of relation annotations is available, reducing the number of slots while still capturing the user&#39;s intended meaning.
        </p>
    </div>
  </div>
  <div class="row" id="ws-aaai-dstc22re-cite" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          
        <pre>
        @InProceedings{ws-aaai-dstc22re,
  title     = {Augmenting Task-Oriented Dialogue Systems with Relation Extraction},
  author    = {Lee, Andrew and Chen, Zhenguo and Leach, Kevin and Kummerfeld, Jonathan K.},
  year      = {2022},
  booktitle = {10th Edition of the Dialog System Technology Challenges at AAAI 2022},
  month     = {March},
  url       = {https://arxiv.org/pdf/2210.13344.pdf},
}
        </pre>
        
        </p>
    </div>
  </div>
</div>


<h3 id="2021">2021</h3>
<div class="container pb-2">
  <div class="row">
    <div class="col-lg-6">
      <strong>Analyzing the Surprising Variability in Word Embedding Stability Across Languages</strong>
      <br />
      <span class="text-muted">Laura Burdick, Jonathan K. Kummerfeld, Rada Mihalcea</span>
      <br />
      EMNLP<span class="text-muted">, 2021</span>
    </div>
    <div class="col-lg-6">
      <a class="btn btn-outline-primary btn-sm" href="https://aclanthology.org/2021.emnlp-main.476" target="_blank" rel="noopener"><span
    class="fontawesome-inline-svg"
    style="display: inline-flex; align-self: center; height:1em; width:1em; top: .125em; position: relative;"
><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path fill='currentColor' d="M256 0v128h128L256 0zM224 128L224 0H48C21.49 0 0 21.49 0 48v416C0 490.5 21.49 512 48 512h288c26.51 0 48-21.49 48-48V160h-127.1C238.3 160 224 145.7 224 128zM272 416h-160C103.2 416 96 408.8 96 400C96 391.2 103.2 384 112 384h160c8.836 0 16 7.162 16 16C288 408.8 280.8 416 272 416zM272 352h-160C103.2 352 96 344.8 96 336C96 327.2 103.2 320 112 320h160c8.836 0 16 7.162 16 16C288 344.8 280.8 352 272 352zM288 272C288 280.8 280.8 288 272 288h-160C103.2 288 96 280.8 96 272C96 263.2 103.2 256 112 256h160C280.8 256 288 263.2 288 272z"/></svg>
</span>
 PDF</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('emnlp21stability-abstract').style.display == 'block') {
  document.getElementById('emnlp21stability-abstract').style.display='none';
  } else {
  document.getElementById('emnlp21stability-abstract').style.display='block';
  }
  ">Abstract</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('emnlp21stability-cite').style.display == 'block') {
  document.getElementById('emnlp21stability-cite').style.display='none';
  } else {
  document.getElementById('emnlp21stability-cite').style.display='block';
  }
  ">BibTeX</a>
      
      
      
      
      <a class="btn btn-outline-primary btn-sm" href="https://github.com/laura-burdick/multilingual-stability" target="_blank" rel="noopener"><span
    class="fontawesome-inline-svg"
    style="display: inline-flex; align-self: center; height:1em; width:1em; top: .125em; position: relative;"
><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512"><path fill='currentColor' d="M414.8 40.79L286.8 488.8C281.9 505.8 264.2 515.6 247.2 510.8C230.2 505.9 220.4 488.2 225.2 471.2L353.2 23.21C358.1 6.216 375.8-3.624 392.8 1.232C409.8 6.087 419.6 23.8 414.8 40.79H414.8zM518.6 121.4L630.6 233.4C643.1 245.9 643.1 266.1 630.6 278.6L518.6 390.6C506.1 403.1 485.9 403.1 473.4 390.6C460.9 378.1 460.9 357.9 473.4 345.4L562.7 256L473.4 166.6C460.9 154.1 460.9 133.9 473.4 121.4C485.9 108.9 506.1 108.9 518.6 121.4V121.4zM166.6 166.6L77.25 256L166.6 345.4C179.1 357.9 179.1 378.1 166.6 390.6C154.1 403.1 133.9 403.1 121.4 390.6L9.372 278.6C-3.124 266.1-3.124 245.9 9.372 233.4L121.4 121.4C133.9 108.9 154.1 108.9 166.6 121.4C179.1 133.9 179.1 154.1 166.6 166.6V166.6z"/></svg>
</span>
 Software</a>
      
      
      
      
      <a class="btn btn-outline-primary btn-sm" href="https://aclanthology.org/2021.emnlp-main.476.mp4" target="_blank" rel="noopener"><span
    class="fontawesome-inline-svg"
    style="display: inline-flex; align-self: center; height:1em; width:1em; top: .125em; position: relative;"
><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><path fill='currentColor' d="M384 112v288c0 26.51-21.49 48-48 48h-288c-26.51 0-48-21.49-48-48v-288c0-26.51 21.49-48 48-48h288C362.5 64 384 85.49 384 112zM576 127.5v256.9c0 25.5-29.17 40.39-50.39 25.79L416 334.7V177.3l109.6-75.56C546.9 87.13 576 102.1 576 127.5z"/></svg>
</span>
 Video</a>
      
    </div>
  </div>
  <div class="row" id="emnlp21stability-abstract" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          Word embeddings are powerful representations that form the foundation of many natural language processing architectures, both in English and in other languages. To gain further insight into word embeddings, we explore their stability (e.g., overlap between the nearest neighbors of a word in different embedding spaces) in diverse languages. We discuss linguistic properties that are related to stability, drawing out insights about correlations with affixing, language gender systems, and other features. This has implications for embedding use, particularly in research that uses them to study language trends.
        </p>
    </div>
  </div>
  <div class="row" id="emnlp21stability-cite" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          
        <pre>
        @InProceedings{emnlp21stability,
  title     = {Analyzing the Surprising Variability in Word Embedding Stability Across Languages},
  author    = {Burdick, Laura and Kummerfeld, Jonathan K. and Mihalcea, Rada},
  doi       = {10.18653/v1/2021.emnlp-main.476},
  booktitle = {Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing},
  month     = {November},
  year      = {2021},
  location  = {Online and Punta Cana, Dominican Republic},
  pages     = {5891--5901},
  url       = {https://aclanthology.org/2021.emnlp-main.476},
  arxiv     = {https://arxiv.org/pdf/2004.14876.pdf},
  video     = {https://aclanthology.org/2021.emnlp-main.476.mp4},
  software  = {https://github.com/laura-burdick/multilingual-stability},
}
        </pre>
        
        </p>
    </div>
  </div>
</div>


<div class="container pb-2">
  <div class="row">
    <div class="col-lg-6">
      <strong>Micromodels for Efficient, Explainable, and Reusable Systems: A Case Study on Mental Health</strong>
      <br />
      <span class="text-muted">Andrew Lee, Jonathan K. Kummerfeld, Lawrence C. An, Rada Mihalcea</span>
      <br />
      Findings of EMNLP<span class="text-muted">, 2021</span>
    </div>
    <div class="col-lg-6">
      <a class="btn btn-outline-primary btn-sm" href="https://aclanthology.org/2021.findings-emnlp.360" target="_blank" rel="noopener"><span
    class="fontawesome-inline-svg"
    style="display: inline-flex; align-self: center; height:1em; width:1em; top: .125em; position: relative;"
><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path fill='currentColor' d="M256 0v128h128L256 0zM224 128L224 0H48C21.49 0 0 21.49 0 48v416C0 490.5 21.49 512 48 512h288c26.51 0 48-21.49 48-48V160h-127.1C238.3 160 224 145.7 224 128zM272 416h-160C103.2 416 96 408.8 96 400C96 391.2 103.2 384 112 384h160c8.836 0 16 7.162 16 16C288 408.8 280.8 416 272 416zM272 352h-160C103.2 352 96 344.8 96 336C96 327.2 103.2 320 112 320h160c8.836 0 16 7.162 16 16C288 344.8 280.8 352 272 352zM288 272C288 280.8 280.8 288 272 288h-160C103.2 288 96 280.8 96 272C96 263.2 103.2 256 112 256h160C280.8 256 288 263.2 288 272z"/></svg>
</span>
 PDF</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('emnlp-findings21micromodels-abstract').style.display == 'block') {
  document.getElementById('emnlp-findings21micromodels-abstract').style.display='none';
  } else {
  document.getElementById('emnlp-findings21micromodels-abstract').style.display='block';
  }
  ">Abstract</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('emnlp-findings21micromodels-cite').style.display == 'block') {
  document.getElementById('emnlp-findings21micromodels-cite').style.display='none';
  } else {
  document.getElementById('emnlp-findings21micromodels-cite').style.display='block';
  }
  ">BibTeX</a>
      
      
      
      
      <a class="btn btn-outline-primary btn-sm" href="https://github.com/MichiganNLP/micromodels" target="_blank" rel="noopener"><span
    class="fontawesome-inline-svg"
    style="display: inline-flex; align-self: center; height:1em; width:1em; top: .125em; position: relative;"
><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512"><path fill='currentColor' d="M414.8 40.79L286.8 488.8C281.9 505.8 264.2 515.6 247.2 510.8C230.2 505.9 220.4 488.2 225.2 471.2L353.2 23.21C358.1 6.216 375.8-3.624 392.8 1.232C409.8 6.087 419.6 23.8 414.8 40.79H414.8zM518.6 121.4L630.6 233.4C643.1 245.9 643.1 266.1 630.6 278.6L518.6 390.6C506.1 403.1 485.9 403.1 473.4 390.6C460.9 378.1 460.9 357.9 473.4 345.4L562.7 256L473.4 166.6C460.9 154.1 460.9 133.9 473.4 121.4C485.9 108.9 506.1 108.9 518.6 121.4V121.4zM166.6 166.6L77.25 256L166.6 345.4C179.1 357.9 179.1 378.1 166.6 390.6C154.1 403.1 133.9 403.1 121.4 390.6L9.372 278.6C-3.124 266.1-3.124 245.9 9.372 233.4L121.4 121.4C133.9 108.9 154.1 108.9 166.6 121.4C179.1 133.9 179.1 154.1 166.6 166.6V166.6z"/></svg>
</span>
 Software</a>
      
      
      
      
    </div>
  </div>
  <div class="row" id="emnlp-findings21micromodels-abstract" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          Many statistical models have high accuracy on test benchmarks, but are not explainable, struggle in low-resource scenarios, cannot be reused for multiple tasks, and cannot easily integrate domain expertise. These factors limit their use, particularly in settings such as mental health, where it is difficult to annotate datasets and model outputs have significant impact. We introduce a micromodel architecture to address these challenges. Our approach allows researchers to build interpretable representations that embed domain knowledge and provide explanations throughout the model&#39;s decision process. We demonstrate the idea on multiple mental health tasks: depression classification, PTSD classification, and suicidal risk assessment. Our systems consistently produce strong results, even in low-resource scenarios, and are more interpretable than alternative methods.
        </p>
    </div>
  </div>
  <div class="row" id="emnlp-findings21micromodels-cite" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          
        <pre>
        @InProceedings{emnlp-findings21micromodels,
  title     = {Micromodels for Efficient, Explainable, and Reusable Systems: A Case Study on Mental Health},
  author    = {Lee, Andrew and Kummerfeld, Jonathan K. and An, Lawrence C. and Mihalcea, Rada},
  booktitle = {Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing: Findings},
  month     = {November},
  year      = {2021},
  location  = {Punta Cana, Dominican Republic},
  pages     = {4257--4272},
  url       = {https://aclanthology.org/2021.findings-emnlp.360},
  doi       = {10.18653/v1/2021.findings-emnlp.360},
  arxiv     = {https://arxiv.org/abs/2109.13770},
  software  = {https://github.com/MichiganNLP/micromodels},
}
        </pre>
        
        </p>
    </div>
  </div>
</div>


<div class="container pb-2">
  <div class="row">
    <div class="col-lg-6">
      <strong>Quantifying and Avoiding Unfair Qualification Labour in Crowdsourcing</strong>
      <br />
      <span class="text-muted">Jonathan K. Kummerfeld</span>
      <br />
      ACL (short)<span class="text-muted">, 2021</span>
    </div>
    <div class="col-lg-6">
      <a class="btn btn-outline-primary btn-sm" href="https://aclanthology.org/2021.acl-short.44/" target="_blank" rel="noopener"><span
    class="fontawesome-inline-svg"
    style="display: inline-flex; align-self: center; height:1em; width:1em; top: .125em; position: relative;"
><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path fill='currentColor' d="M256 0v128h128L256 0zM224 128L224 0H48C21.49 0 0 21.49 0 48v416C0 490.5 21.49 512 48 512h288c26.51 0 48-21.49 48-48V160h-127.1C238.3 160 224 145.7 224 128zM272 416h-160C103.2 416 96 408.8 96 400C96 391.2 103.2 384 112 384h160c8.836 0 16 7.162 16 16C288 408.8 280.8 416 272 416zM272 352h-160C103.2 352 96 344.8 96 336C96 327.2 103.2 320 112 320h160c8.836 0 16 7.162 16 16C288 344.8 280.8 352 272 352zM288 272C288 280.8 280.8 288 272 288h-160C103.2 288 96 280.8 96 272C96 263.2 103.2 256 112 256h160C280.8 256 288 263.2 288 272z"/></svg>
</span>
 PDF</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('acl21fair-work-abstract').style.display == 'block') {
  document.getElementById('acl21fair-work-abstract').style.display='none';
  } else {
  document.getElementById('acl21fair-work-abstract').style.display='block';
  }
  ">Abstract</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('acl21fair-work-cite').style.display == 'block') {
  document.getElementById('acl21fair-work-cite').style.display='none';
  } else {
  document.getElementById('acl21fair-work-cite').style.display='block';
  }
  ">BibTeX</a>
      
      <a class="btn btn-outline-primary btn-sm" href="https://aclanthology.org/attachments/2021.acl-short.44.OptionalSupplementaryMaterial.zip" target="_blank" rel="noopener">Supplementary Material</a>
      
      
      
      
      
      
      
      <a class="btn btn-outline-primary btn-sm" href="https://aclanthology.org/2021.acl-short.44.mp4" target="_blank" rel="noopener"><span
    class="fontawesome-inline-svg"
    style="display: inline-flex; align-self: center; height:1em; width:1em; top: .125em; position: relative;"
><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><path fill='currentColor' d="M384 112v288c0 26.51-21.49 48-48 48h-288c-26.51 0-48-21.49-48-48v-288c0-26.51 21.49-48 48-48h288C362.5 64 384 85.49 384 112zM576 127.5v256.9c0 25.5-29.17 40.39-50.39 25.79L416 334.7V177.3l109.6-75.56C546.9 87.13 576 102.1 576 127.5z"/></svg>
</span>
 Video</a>
      
    </div>
  </div>
  <div class="row" id="acl21fair-work-abstract" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          Extensive work has argued in favour of paying crowd workers a wage that is at least equivalent to the U.S. federal minimum wage. Meanwhile, research on collecting high quality annotations suggests using a qualification that requires workers to have previously completed a certain number of tasks. If most requesters who pay fairly require workers to have completed a large number of tasks already then workers need to complete a substantial amount of poorly paid work before they can earn a fair wage. Through analysis of worker discussions and guidance for researchers, we estimate that workers spend approximately 2.25 months of full time effort on poorly paid tasks in order to get the qualifications needed for better paid tasks. We discuss alternatives to this qualification and conduct a study of the correlation between qualifications and work quality on two NLP tasks. We find that it is possible to reduce the burden on workers while still collecting high quality data.
        </p>
    </div>
  </div>
  <div class="row" id="acl21fair-work-cite" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          
        <pre>
        @InProceedings{acl21fair-work,
  author    = {Kummerfeld, Jonathan K.},
  title     = {Quantifying and Avoiding Unfair Qualification Labour in Crowdsourcing},
  location  = {Online},
  booktitle = {Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 2: Short Papers)},
  month     = {August},
  year      = {2021},
  url       = {https://aclanthology.org/2021.acl-short.44/},
  pages     = {343--349},
  doi       = {10.18653/v1/2021.acl-short.44},
  arxiv     = {https://arxiv.org/abs/2105.12762},
  supplementary = {https://aclanthology.org/attachments/2021.acl-short.44.OptionalSupplementaryMaterial.zip},
  video     = {https://aclanthology.org/2021.acl-short.44.mp4},
}
        </pre>
        
        </p>
    </div>
  </div>
</div>


<div class="container pb-2">
  <div class="row">
    <div class="col-lg-6">
      <strong>Exploring Self-Identified Counseling Expertise in Online Support Forums</strong>
      <br />
      <span class="text-muted">Allison Lahnala, Yuntian Zhao, Charles Welch, Jonathan K. Kummerfeld, Lawrence C. An, Kenneth Resnicow, Rada Mihalcea, Verónica Pérez-Rosas</span>
      <br />
      Findings of ACL<span class="text-muted">, 2021</span>
    </div>
    <div class="col-lg-6">
      <a class="btn btn-outline-primary btn-sm" href="https://aclanthology.org/2021.findings-acl.392/" target="_blank" rel="noopener"><span
    class="fontawesome-inline-svg"
    style="display: inline-flex; align-self: center; height:1em; width:1em; top: .125em; position: relative;"
><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path fill='currentColor' d="M256 0v128h128L256 0zM224 128L224 0H48C21.49 0 0 21.49 0 48v416C0 490.5 21.49 512 48 512h288c26.51 0 48-21.49 48-48V160h-127.1C238.3 160 224 145.7 224 128zM272 416h-160C103.2 416 96 408.8 96 400C96 391.2 103.2 384 112 384h160c8.836 0 16 7.162 16 16C288 408.8 280.8 416 272 416zM272 352h-160C103.2 352 96 344.8 96 336C96 327.2 103.2 320 112 320h160c8.836 0 16 7.162 16 16C288 344.8 280.8 352 272 352zM288 272C288 280.8 280.8 288 272 288h-160C103.2 288 96 280.8 96 272C96 263.2 103.2 256 112 256h160C280.8 256 288 263.2 288 272z"/></svg>
</span>
 PDF</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('acl21counseling-abstract').style.display == 'block') {
  document.getElementById('acl21counseling-abstract').style.display='none';
  } else {
  document.getElementById('acl21counseling-abstract').style.display='block';
  }
  ">Abstract</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('acl21counseling-cite').style.display == 'block') {
  document.getElementById('acl21counseling-cite').style.display='none';
  } else {
  document.getElementById('acl21counseling-cite').style.display='block';
  }
  ">BibTeX</a>
      
      
      
      
      <a class="btn btn-outline-primary btn-sm" href="https://github.com/MichiganNLP/MHP-and-Peers-Reddit" target="_blank" rel="noopener"><span
    class="fontawesome-inline-svg"
    style="display: inline-flex; align-self: center; height:1em; width:1em; top: .125em; position: relative;"
><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512"><path fill='currentColor' d="M414.8 40.79L286.8 488.8C281.9 505.8 264.2 515.6 247.2 510.8C230.2 505.9 220.4 488.2 225.2 471.2L353.2 23.21C358.1 6.216 375.8-3.624 392.8 1.232C409.8 6.087 419.6 23.8 414.8 40.79H414.8zM518.6 121.4L630.6 233.4C643.1 245.9 643.1 266.1 630.6 278.6L518.6 390.6C506.1 403.1 485.9 403.1 473.4 390.6C460.9 378.1 460.9 357.9 473.4 345.4L562.7 256L473.4 166.6C460.9 154.1 460.9 133.9 473.4 121.4C485.9 108.9 506.1 108.9 518.6 121.4V121.4zM166.6 166.6L77.25 256L166.6 345.4C179.1 357.9 179.1 378.1 166.6 390.6C154.1 403.1 133.9 403.1 121.4 390.6L9.372 278.6C-3.124 266.1-3.124 245.9 9.372 233.4L121.4 121.4C133.9 108.9 154.1 108.9 166.6 121.4C179.1 133.9 179.1 154.1 166.6 166.6V166.6z"/></svg>
</span>
 Software</a>
      
      
      
      
    </div>
  </div>
  <div class="row" id="acl21counseling-abstract" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          A growing number of people engage in online health forums, making it important to understand the quality of the advice they receive. In this paper, we explore the role of expertise in responses provided to help-seeking posts regarding mental health. We study the differences between (1) interactions with peers; and (2) interactions with self-identified mental health professionals. First, we show that a classifier can distinguish between these two groups, indicating that their language use does in fact differ. To understand this difference, we perform several analyses addressing engagement aspects, including whether their comments engage the support-seeker further as well as linguistic aspects, such as dominant language and linguistic style matching. Our work contributes toward the developing efforts of understanding how health experts engage with health information- and support-seekers in social networks. More broadly, it is a step toward a deeper understanding of the styles of interactions that cultivate supportive engagement in online communities.
        </p>
    </div>
  </div>
  <div class="row" id="acl21counseling-cite" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          
        <pre>
        @InProceedings{acl21counseling,
  author    = {Lahnala, Allison and Zhao, Yuntian and Welch, Charles and Kummerfeld, Jonathan K. and An, Lawrence C. and Resnicow, Kenneth and Mihalcea, Rada and P{\\'e}rez-Rosas, Ver{\\'o}nica},
  title     = {Exploring Self-Identified Counseling Expertise in Online Support Forums},
  location  = {Online},
  booktitle = {Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021},
  month     = {August},
  year      = {2021},
  url       = {https://aclanthology.org/2021.findings-acl.392/},
  pages     = {4467--4480},
  doi       = {10.18653/v1/2021.findings-acl.392},
  software  = {https://github.com/MichiganNLP/MHP-and-Peers-Reddit},
}
        </pre>
        
        </p>
    </div>
  </div>
</div>


<div class="container pb-2">
  <div class="row">
    <div class="col-lg-6">
      <strong>Chord Embeddings: Analyzing What They Capture and Their Role for Next Chord Prediction and Artist Attribute Prediction</strong>
      <br />
      <span class="text-muted">Allison Lahnala, Gauri Kambhatla, Jiajun Peng, Matthew Whitehead, Gillian Minnehan, Eric Guldan, Jonathan K. Kummerfeld, Anıl Çamcı, Rada Mihalcea</span>
      <br />
      EvoMusArt<span class="text-muted">, 2021</span>
    </div>
    <div class="col-lg-6">
      <a class="btn btn-outline-primary btn-sm" href="https://arxiv.org/pdf/2102.02917.pdf" target="_blank" rel="noopener"><span
    class="fontawesome-inline-svg"
    style="display: inline-flex; align-self: center; height:1em; width:1em; top: .125em; position: relative;"
><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path fill='currentColor' d="M256 0v128h128L256 0zM224 128L224 0H48C21.49 0 0 21.49 0 48v416C0 490.5 21.49 512 48 512h288c26.51 0 48-21.49 48-48V160h-127.1C238.3 160 224 145.7 224 128zM272 416h-160C103.2 416 96 408.8 96 400C96 391.2 103.2 384 112 384h160c8.836 0 16 7.162 16 16C288 408.8 280.8 416 272 416zM272 352h-160C103.2 352 96 344.8 96 336C96 327.2 103.2 320 112 320h160c8.836 0 16 7.162 16 16C288 344.8 280.8 352 272 352zM288 272C288 280.8 280.8 288 272 288h-160C103.2 288 96 280.8 96 272C96 263.2 103.2 256 112 256h160C280.8 256 288 263.2 288 272z"/></svg>
</span>
 PDF</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('evomusart21-abstract').style.display == 'block') {
  document.getElementById('evomusart21-abstract').style.display='none';
  } else {
  document.getElementById('evomusart21-abstract').style.display='block';
  }
  ">Abstract</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('evomusart21-cite').style.display == 'block') {
  document.getElementById('evomusart21-cite').style.display='none';
  } else {
  document.getElementById('evomusart21-cite').style.display='block';
  }
  ">BibTeX</a>
      
      
      
      
      
      
      
    </div>
  </div>
  <div class="row" id="evomusart21-abstract" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          Natural language processing methods have been applied in a variety of music studies, drawing the connection between music and language. In this paper, we expand those approaches by investigating chord embeddings, which we apply in two case studies to address two key questions: (1) what musical information do chord embeddings capture?; and (2) how might musical applications benefit from them? In our analysis, we show that they capture similarities between chords that adhere to important relationships described in music theory. In the first case study, we demonstrate that using chord embeddings in a next chord prediction task yields predictions that more closely match those by experienced musicians. In the second case study, we show the potential benefits of using the representations in tasks related to musical stylometrics.
        </p>
    </div>
  </div>
  <div class="row" id="evomusart21-cite" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          
        <pre>
        @InProceedings{evomusart21,
  title     = {Chord Embeddings: Analyzing What They Capture and Their Role for Next Chord Prediction and Artist Attribute Prediction},
  author    = {Lahnala, Allison and Kambhatla, Gauri and Peng, Jiajun and Whitehead, Matthew and Minnehan, Gillian and Guldan, Eric and Kummerfeld, Jonathan K. and Çamcı, Anıl and Mihalcea, Rada},
  booktitle = {Proceedings of the 10th International Conference on Artificial Intelligence in Music, Sound, Art and Design},
  year      = {2021},
  month     = {April},
  url       = {https://arxiv.org/pdf/2102.02917.pdf},
  pages     = {171--186},
}
        </pre>
        
        </p>
    </div>
  </div>
</div>


<div class="container pb-2">
  <div class="row">
    <div class="col-lg-6">
      <strong>Overview of the Eighth Dialog System Technology Challenge: DSTC8</strong>
      <br />
      <span class="text-muted">Seokhwan Kim, Michel Galley, Chulaka Gunasekara, Sungjin Lee, Adam Atkinson, Peng Baolin, Hannes Schulz, Jianfeng Gao, Jinchao Li, Mahmoud Adada, Minlie Huang, Luis Lastras, Jonathan K. Kummerfeld, Walter S. Lasecki, Chiori Hori, Anoop Cherian, Tim Marks, Abhinav Rastogi, Xiaoxue Zang, Srinivas Sunkara, Raghav Gupta</span>
      <br />
      IEEE: TASLP<span class="text-muted">, 2021</span>
    </div>
    <div class="col-lg-6">
      <a class="btn btn-outline-primary btn-sm" href="https://ieeexplore.ieee.org/document/9426430" target="_blank" rel="noopener"><span
    class="fontawesome-inline-svg"
    style="display: inline-flex; align-self: center; height:1em; width:1em; top: .125em; position: relative;"
><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path fill='currentColor' d="M256 0v128h128L256 0zM224 128L224 0H48C21.49 0 0 21.49 0 48v416C0 490.5 21.49 512 48 512h288c26.51 0 48-21.49 48-48V160h-127.1C238.3 160 224 145.7 224 128zM272 416h-160C103.2 416 96 408.8 96 400C96 391.2 103.2 384 112 384h160c8.836 0 16 7.162 16 16C288 408.8 280.8 416 272 416zM272 352h-160C103.2 352 96 344.8 96 336C96 327.2 103.2 320 112 320h160c8.836 0 16 7.162 16 16C288 344.8 280.8 352 272 352zM288 272C288 280.8 280.8 288 272 288h-160C103.2 288 96 280.8 96 272C96 263.2 103.2 256 112 256h160C280.8 256 288 263.2 288 272z"/></svg>
</span>
 PDF</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('dstc8-ieee-abstract').style.display == 'block') {
  document.getElementById('dstc8-ieee-abstract').style.display='none';
  } else {
  document.getElementById('dstc8-ieee-abstract').style.display='block';
  }
  ">Abstract</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('dstc8-ieee-cite').style.display == 'block') {
  document.getElementById('dstc8-ieee-cite').style.display='none';
  } else {
  document.getElementById('dstc8-ieee-cite').style.display='block';
  }
  ">BibTeX</a>
      
      
      
      
      
      
      
    </div>
  </div>
  <div class="row" id="dstc8-ieee-abstract" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          This paper introduces the Eighth Dialog System Technology Challenge. In line with recent challenges, the eighth edition focuses on applying end-to-end dialog technologies in a pragmatic way for multi-domain task-completion, noetic response selection, audio visual scene-aware dialog, and schema-guided dialog state tracking tasks. This paper describes the task definition, provided datasets, baselines and evaluation set-up for each track. We also summarize the results of the submitted systems to highlight the overall trends of the state-of-the-art technologies for the tasks.
        </p>
    </div>
  </div>
  <div class="row" id="dstc8-ieee-cite" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          
        <pre>
        @Article{dstc8-ieee,
  title     = {Overview of the Eighth Dialog System Technology Challenge: DSTC8},
  author    = {Kim, Seokhwan and Galley, Michel and Gunasekara, Chulaka and Lee, Sungjin and Atkinson, Adam and Baolin, Peng and Schulz, Hannes and Gao, Jianfeng and Li, Jinchao and Adada, Mahmoud and Huang, Minlie and Lastras, Luis and Kummerfeld, Jonathan K. and Lasecki, Walter S. and Hori, Chiori and Cherian, Anoop and Marks, Tim and Rastogi, Abhinav and Zang, Xiaoxue and Sunkara, Srinivas and Gupta, Raghav},
  journal   = {IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  publisher = {IEEE},
  doi       = {10.1109/TASLP.2021.3078368},
  year      = {2021},
  url       = {https://ieeexplore.ieee.org/document/9426430},
  volume    = {29},
  number    = {1},
  pages     = {2529--2540},
}
        </pre>
        
        </p>
    </div>
  </div>
</div>


<div class="container pb-2">
  <div class="row">
    <div class="col-lg-6">
      <strong>To Batch or Not to Batch? Comparing Batching and Curriculum Learning Strategies across Tasks and Datasets</strong>
      <br />
      <span class="text-muted">Laura Burdick, Jonathan K. Kummerfeld, Rada Mihalcea</span>
      <br />
      Mathematics<span class="text-muted">, 2021</span>
    </div>
    <div class="col-lg-6">
      <a class="btn btn-outline-primary btn-sm" href="https://www.jkk.name/pub/math21batch.pdf" target="_blank" rel="noopener"><span
    class="fontawesome-inline-svg"
    style="display: inline-flex; align-self: center; height:1em; width:1em; top: .125em; position: relative;"
><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path fill='currentColor' d="M256 0v128h128L256 0zM224 128L224 0H48C21.49 0 0 21.49 0 48v416C0 490.5 21.49 512 48 512h288c26.51 0 48-21.49 48-48V160h-127.1C238.3 160 224 145.7 224 128zM272 416h-160C103.2 416 96 408.8 96 400C96 391.2 103.2 384 112 384h160c8.836 0 16 7.162 16 16C288 408.8 280.8 416 272 416zM272 352h-160C103.2 352 96 344.8 96 336C96 327.2 103.2 320 112 320h160c8.836 0 16 7.162 16 16C288 344.8 280.8 352 272 352zM288 272C288 280.8 280.8 288 272 288h-160C103.2 288 96 280.8 96 272C96 263.2 103.2 256 112 256h160C280.8 256 288 263.2 288 272z"/></svg>
</span>
 PDF</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('math21batch-abstract').style.display == 'block') {
  document.getElementById('math21batch-abstract').style.display='none';
  } else {
  document.getElementById('math21batch-abstract').style.display='block';
  }
  ">Abstract</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('math21batch-cite').style.display == 'block') {
  document.getElementById('math21batch-cite').style.display='none';
  } else {
  document.getElementById('math21batch-cite').style.display='block';
  }
  ">BibTeX</a>
      
      
      
      
      
      
      
    </div>
  </div>
  <div class="row" id="math21batch-abstract" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          Many natural language processing architectures are greatly affected by seemingly small design decisions, such as batching and curriculum learning (how the training data are ordered during training). In order to better understand the impact of these decisions, we present a systematic analysis of different curriculum learning strategies and different batching strategies. We consider multiple datasets for three tasks: text classification, sentence and phrase similarity, and part-of-speech tagging. Our experiments demonstrate that certain curriculum learning and batching decisions do increase performance substantially for some tasks.
        </p>
    </div>
  </div>
  <div class="row" id="math21batch-cite" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          
        <pre>
        @Article{math21batch,
  author    = {Burdick, Laura and Kummerfeld, Jonathan K. and Mihalcea, Rada},
  title     = {To Batch or Not to Batch? Comparing Batching and Curriculum Learning Strategies across Tasks and Datasets},
  journal   = {Mathematics},
  volume    = {9},
  year      = {2021},
  number    = {18},
  article-number = {2234},
  url       = {https://www.jkk.name/pub/math21batch.pdf},
  issn      = {2227-7390},
  doi      = {10.3390/math9182234}
}
        </pre>
        
        </p>
    </div>
  </div>
</div>


<div class="container pb-2">
  <div class="row">
    <div class="col-lg-6">
      <strong>Learning to Learn End-to-End Goal-Oriented Dialog From Related Dialog Tasks</strong>
      <br />
      <span class="text-muted">Janarthanan Rajendran, Jonathan K. Kummerfeld, Satinder Singh</span>
      <br />
      EMNLP Workshop: NLP4ConvAI<span class="text-muted">, 2021</span>
    </div>
    <div class="col-lg-6">
      <a class="btn btn-outline-primary btn-sm" href="https://aclanthology.org/2021.nlp4convai-1.16" target="_blank" rel="noopener"><span
    class="fontawesome-inline-svg"
    style="display: inline-flex; align-self: center; height:1em; width:1em; top: .125em; position: relative;"
><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path fill='currentColor' d="M256 0v128h128L256 0zM224 128L224 0H48C21.49 0 0 21.49 0 48v416C0 490.5 21.49 512 48 512h288c26.51 0 48-21.49 48-48V160h-127.1C238.3 160 224 145.7 224 128zM272 416h-160C103.2 416 96 408.8 96 400C96 391.2 103.2 384 112 384h160c8.836 0 16 7.162 16 16C288 408.8 280.8 416 272 416zM272 352h-160C103.2 352 96 344.8 96 336C96 327.2 103.2 320 112 320h160c8.836 0 16 7.162 16 16C288 344.8 280.8 352 272 352zM288 272C288 280.8 280.8 288 272 288h-160C103.2 288 96 280.8 96 272C96 263.2 103.2 256 112 256h160C280.8 256 288 263.2 288 272z"/></svg>
</span>
 PDF</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('ws-emnlp-convai21learn-abstract').style.display == 'block') {
  document.getElementById('ws-emnlp-convai21learn-abstract').style.display='none';
  } else {
  document.getElementById('ws-emnlp-convai21learn-abstract').style.display='block';
  }
  ">Abstract</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('ws-emnlp-convai21learn-cite').style.display == 'block') {
  document.getElementById('ws-emnlp-convai21learn-cite').style.display='none';
  } else {
  document.getElementById('ws-emnlp-convai21learn-cite').style.display='block';
  }
  ">BibTeX</a>
      
      
      
      
      
      
      
    </div>
  </div>
  <div class="row" id="ws-emnlp-convai21learn-abstract" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          For each goal-oriented dialog task of interest, large amounts of data need to be collected for end-to-end learning of a neural dialog system. Collecting that data is a costly and time-consuming process. Instead, we show that we can use only a small amount of data, supplemented with data from a related dialog task. Naively learning from related data fails to improve performance as the related data can be inconsistent with the target task. We describe a meta-learning based method that selectively learns from the related dialog task data. Our approach leads to significant accuracy improvements in an example dialog task.
        </p>
    </div>
  </div>
  <div class="row" id="ws-emnlp-convai21learn-cite" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          
        <pre>
        @InProceedings{ws-emnlp-convai21learn,
  author    = {Rajendran, Janarthanan and Kummerfeld, Jonathan K. and Singh, Satinder},
  title     = {Learning to Learn End-to-End Goal-Oriented Dialog From Related Dialog Tasks},
  location  = {Online},
  booktitle = {3rd Workshop on NLP for ConvAI},
  month     = {November},
  year      = {2021},
  url       = {https://aclanthology.org/2021.nlp4convai-1.16},
  pages     = {163--178},
  doi       = {10.18653/v1/2021.nlp4convai-1.16},
  arxiv     = {https://arxiv.org/abs/2110.15724},
}
        </pre>
        
        </p>
    </div>
  </div>
</div>


<h3 id="2020">2020</h3>
<div class="container pb-2">
  <div class="row">
    <div class="col-lg-6">
      <strong>Compositional Demographic Word Embeddings</strong>
      <br />
      <span class="text-muted">Charles Welch, Jonathan K. Kummerfeld, Verónica Pérez-Rosas, Rada Mihalcea</span>
      <br />
      EMNLP<span class="text-muted">, 2020</span>
    </div>
    <div class="col-lg-6">
      <a class="btn btn-outline-primary btn-sm" href="https://www.aclweb.org/anthology/2020.emnlp-main.334" target="_blank" rel="noopener"><span
    class="fontawesome-inline-svg"
    style="display: inline-flex; align-self: center; height:1em; width:1em; top: .125em; position: relative;"
><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path fill='currentColor' d="M256 0v128h128L256 0zM224 128L224 0H48C21.49 0 0 21.49 0 48v416C0 490.5 21.49 512 48 512h288c26.51 0 48-21.49 48-48V160h-127.1C238.3 160 224 145.7 224 128zM272 416h-160C103.2 416 96 408.8 96 400C96 391.2 103.2 384 112 384h160c8.836 0 16 7.162 16 16C288 408.8 280.8 416 272 416zM272 352h-160C103.2 352 96 344.8 96 336C96 327.2 103.2 320 112 320h160c8.836 0 16 7.162 16 16C288 344.8 280.8 352 272 352zM288 272C288 280.8 280.8 288 272 288h-160C103.2 288 96 280.8 96 272C96 263.2 103.2 256 112 256h160C280.8 256 288 263.2 288 272z"/></svg>
</span>
 PDF</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('emnlp20demographics-abstract').style.display == 'block') {
  document.getElementById('emnlp20demographics-abstract').style.display='none';
  } else {
  document.getElementById('emnlp20demographics-abstract').style.display='block';
  }
  ">Abstract</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('emnlp20demographics-cite').style.display == 'block') {
  document.getElementById('emnlp20demographics-cite').style.display='none';
  } else {
  document.getElementById('emnlp20demographics-cite').style.display='block';
  }
  ">BibTeX</a>
      
      
      <a class="btn btn-outline-primary btn-sm" href="/post/2020-10-10_demographicembeddings/" target="_blank" rel="noopener">Blog Post</a>
      
      
      
      
      
      
      <a class="btn btn-outline-primary btn-sm" href="https://slideslive.com/38939153" target="_blank" rel="noopener"><span
    class="fontawesome-inline-svg"
    style="display: inline-flex; align-self: center; height:1em; width:1em; top: .125em; position: relative;"
><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><path fill='currentColor' d="M384 112v288c0 26.51-21.49 48-48 48h-288c-26.51 0-48-21.49-48-48v-288c0-26.51 21.49-48 48-48h288C362.5 64 384 85.49 384 112zM576 127.5v256.9c0 25.5-29.17 40.39-50.39 25.79L416 334.7V177.3l109.6-75.56C546.9 87.13 576 102.1 576 127.5z"/></svg>
</span>
 Video</a>
      
    </div>
  </div>
  <div class="row" id="emnlp20demographics-abstract" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          Word embeddings are usually derived from corpora containing text from many individuals, thus leading to general purpose representations rather than individually personalized representations. While personalized embeddings can be useful to improve language model performance and other language processing tasks, they can only be computed for people with a large amount of longitudinal data, which is not the case for new users. We propose a new form of personalized word embeddings that use demographic-specific word representations derived compositionally from full or partial demographic information for a user (i.e., gender, age, location, religion). We show that the resulting demographic-aware word representations outperform generic word representations on two tasks for English: language modeling and word associations. We further explore the trade-off between the number of available attributes and their relative effectiveness and discuss the ethical implications of using them.
        </p>
    </div>
  </div>
  <div class="row" id="emnlp20demographics-cite" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          
        <pre>
        @InProceedings{emnlp20demographics,
  title     = {Compositional Demographic Word Embeddings},
  author    = {Welch, Charles and Kummerfeld, Jonathan K. and P{\\'e}rez-Rosas, Ver{\\'o}nica and Mihalcea, Rada},
  booktitle = {Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  month     = {November},
  year      = {2020},
  location  = {Online},
  pages     = {4076--4089},
  url       = {https://www.aclweb.org/anthology/2020.emnlp-main.334},
  doi       = {10.18653/v1/2020.emnlp-main.334},
  arxiv     = {https://arxiv.org/abs/2010.02986},
  blog_post = {/post/2020-10-10_demographicembeddings/},
  video     = {https://slideslive.com/38939153},
}
        </pre>
        
        </p>
    </div>
  </div>
</div>


<div class="container pb-2">
  <div class="row">
    <div class="col-lg-6">
      <strong>Improving Low Compute Language Modeling with In-Domain Embedding Initialisation</strong>
      <br />
      <span class="text-muted">Charles Welch, Rada Mihalcea, Jonathan K. Kummerfeld</span>
      <br />
      EMNLP (short)<span class="text-muted">, 2020</span>
    </div>
    <div class="col-lg-6">
      <a class="btn btn-outline-primary btn-sm" href="https://www.aclweb.org/anthology/2020.emnlp-main.696" target="_blank" rel="noopener"><span
    class="fontawesome-inline-svg"
    style="display: inline-flex; align-self: center; height:1em; width:1em; top: .125em; position: relative;"
><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path fill='currentColor' d="M256 0v128h128L256 0zM224 128L224 0H48C21.49 0 0 21.49 0 48v416C0 490.5 21.49 512 48 512h288c26.51 0 48-21.49 48-48V160h-127.1C238.3 160 224 145.7 224 128zM272 416h-160C103.2 416 96 408.8 96 400C96 391.2 103.2 384 112 384h160c8.836 0 16 7.162 16 16C288 408.8 280.8 416 272 416zM272 352h-160C103.2 352 96 344.8 96 336C96 327.2 103.2 320 112 320h160c8.836 0 16 7.162 16 16C288 344.8 280.8 352 272 352zM288 272C288 280.8 280.8 288 272 288h-160C103.2 288 96 280.8 96 272C96 263.2 103.2 256 112 256h160C280.8 256 288 263.2 288 272z"/></svg>
</span>
 PDF</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('emnlp20lm-abstract').style.display == 'block') {
  document.getElementById('emnlp20lm-abstract').style.display='none';
  } else {
  document.getElementById('emnlp20lm-abstract').style.display='block';
  }
  ">Abstract</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('emnlp20lm-cite').style.display == 'block') {
  document.getElementById('emnlp20lm-cite').style.display='none';
  } else {
  document.getElementById('emnlp20lm-cite').style.display='block';
  }
  ">BibTeX</a>
      
      <a class="btn btn-outline-primary btn-sm" href="https://www.aclweb.org/anthology/attachments/2020.emnlp-main.696.OptionalSupplementaryMaterial.zip" target="_blank" rel="noopener">Supplementary Material</a>
      
      
      <a class="btn btn-outline-primary btn-sm" href="/post/2020-09-29_pretraininglm/" target="_blank" rel="noopener">Blog Post</a>
      
      
      
      <a class="btn btn-outline-primary btn-sm" href="https://github.com/jkkummerfeld/emnlp20lm" target="_blank" rel="noopener"><span
    class="fontawesome-inline-svg"
    style="display: inline-flex; align-self: center; height:1em; width:1em; top: .125em; position: relative;"
><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512"><path fill='currentColor' d="M414.8 40.79L286.8 488.8C281.9 505.8 264.2 515.6 247.2 510.8C230.2 505.9 220.4 488.2 225.2 471.2L353.2 23.21C358.1 6.216 375.8-3.624 392.8 1.232C409.8 6.087 419.6 23.8 414.8 40.79H414.8zM518.6 121.4L630.6 233.4C643.1 245.9 643.1 266.1 630.6 278.6L518.6 390.6C506.1 403.1 485.9 403.1 473.4 390.6C460.9 378.1 460.9 357.9 473.4 345.4L562.7 256L473.4 166.6C460.9 154.1 460.9 133.9 473.4 121.4C485.9 108.9 506.1 108.9 518.6 121.4V121.4zM166.6 166.6L77.25 256L166.6 345.4C179.1 357.9 179.1 378.1 166.6 390.6C154.1 403.1 133.9 403.1 121.4 390.6L9.372 278.6C-3.124 266.1-3.124 245.9 9.372 233.4L121.4 121.4C133.9 108.9 154.1 108.9 166.6 121.4C179.1 133.9 179.1 154.1 166.6 166.6V166.6z"/></svg>
</span>
 Software</a>
      
      
      
      
      <a class="btn btn-outline-primary btn-sm" href="https://slideslive.com/38938903" target="_blank" rel="noopener"><span
    class="fontawesome-inline-svg"
    style="display: inline-flex; align-self: center; height:1em; width:1em; top: .125em; position: relative;"
><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><path fill='currentColor' d="M384 112v288c0 26.51-21.49 48-48 48h-288c-26.51 0-48-21.49-48-48v-288c0-26.51 21.49-48 48-48h288C362.5 64 384 85.49 384 112zM576 127.5v256.9c0 25.5-29.17 40.39-50.39 25.79L416 334.7V177.3l109.6-75.56C546.9 87.13 576 102.1 576 127.5z"/></svg>
</span>
 Video</a>
      
    </div>
  </div>
  <div class="row" id="emnlp20lm-abstract" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          Many NLP applications, such as biomedical data and technical support, have 10-100 million tokens of in-domain data and limited computational resources for learning from it. How should we train a language model in this scenario? Most language modeling research considers either a small dataset with a closed vocabulary (like the standard 1 million token Penn Treebank), or the whole web with byte-pair encoding. We show that for our target setting in English, initialising and freezing input embeddings using in-domain data can improve language model performance by providing a useful representation of rare words, and this pattern holds across several different domains. In the process, we show that the standard convention of tying input and output embeddings does not improve perplexity when initializing with embeddings trained on in-domain data.
        </p>
    </div>
  </div>
  <div class="row" id="emnlp20lm-cite" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          
        <pre>
        @InProceedings{emnlp20lm,
  title     = {Improving Low Compute Language Modeling with In-Domain Embedding Initialisation},
  author    = {Welch, Charles and Mihalcea, Rada and Kummerfeld, Jonathan K.},
  booktitle = {Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing},
  month     = {November},
  year      = {2020},
  location  = {Online},
  pages     = {8625--8634},
  url       = {https://www.aclweb.org/anthology/2020.emnlp-main.696},
  supplementary = {https://www.aclweb.org/anthology/attachments/2020.emnlp-main.696.OptionalSupplementaryMaterial.zip},
  doi       = {10.18653/v1/2020.emnlp-main.696},
  software  = {https://github.com/jkkummerfeld/emnlp20lm},
  arxiv     = {https://arxiv.org/abs/2009.14109},
  blog_post = {/post/2020-09-29_PretrainingLM/},
  video     = {https://slideslive.com/38938903},
}
        </pre>
        
        </p>
    </div>
  </div>
</div>


<div class="container pb-2">
  <div class="row">
    <div class="col-lg-6">
      <strong>Iterative Feature Mining for Constraint-Based Data Collection to Increase Data Diversity and Model Robustness</strong>
      <br />
      <span class="text-muted">Stefan Larson, Anthony Zheng, Anish Mahendran, Rishi Tekriwal, Adrian Cheung, Eric Guldan, Kevin Leach, Jonathan K. Kummerfeld</span>
      <br />
      EMNLP (short)<span class="text-muted">, 2020</span>
    </div>
    <div class="col-lg-6">
      <a class="btn btn-outline-primary btn-sm" href="https://www.aclweb.org/anthology/2020.emnlp-main.650" target="_blank" rel="noopener"><span
    class="fontawesome-inline-svg"
    style="display: inline-flex; align-self: center; height:1em; width:1em; top: .125em; position: relative;"
><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path fill='currentColor' d="M256 0v128h128L256 0zM224 128L224 0H48C21.49 0 0 21.49 0 48v416C0 490.5 21.49 512 48 512h288c26.51 0 48-21.49 48-48V160h-127.1C238.3 160 224 145.7 224 128zM272 416h-160C103.2 416 96 408.8 96 400C96 391.2 103.2 384 112 384h160c8.836 0 16 7.162 16 16C288 408.8 280.8 416 272 416zM272 352h-160C103.2 352 96 344.8 96 336C96 327.2 103.2 320 112 320h160c8.836 0 16 7.162 16 16C288 344.8 280.8 352 272 352zM288 272C288 280.8 280.8 288 272 288h-160C103.2 288 96 280.8 96 272C96 263.2 103.2 256 112 256h160C280.8 256 288 263.2 288 272z"/></svg>
</span>
 PDF</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('emnlp20taboo-abstract').style.display == 'block') {
  document.getElementById('emnlp20taboo-abstract').style.display='none';
  } else {
  document.getElementById('emnlp20taboo-abstract').style.display='block';
  }
  ">Abstract</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('emnlp20taboo-cite').style.display == 'block') {
  document.getElementById('emnlp20taboo-cite').style.display='none';
  } else {
  document.getElementById('emnlp20taboo-cite').style.display='block';
  }
  ">BibTeX</a>
      
      
      <a class="btn btn-outline-primary btn-sm" href="/post/2020-10-10_taboo/" target="_blank" rel="noopener">Blog Post</a>
      
      
      
      
      
      
      <a class="btn btn-outline-primary btn-sm" href="https://slideslive.com/38938895" target="_blank" rel="noopener"><span
    class="fontawesome-inline-svg"
    style="display: inline-flex; align-self: center; height:1em; width:1em; top: .125em; position: relative;"
><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><path fill='currentColor' d="M384 112v288c0 26.51-21.49 48-48 48h-288c-26.51 0-48-21.49-48-48v-288c0-26.51 21.49-48 48-48h288C362.5 64 384 85.49 384 112zM576 127.5v256.9c0 25.5-29.17 40.39-50.39 25.79L416 334.7V177.3l109.6-75.56C546.9 87.13 576 102.1 576 127.5z"/></svg>
</span>
 Video</a>
      
    </div>
  </div>
  <div class="row" id="emnlp20taboo-abstract" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          Diverse data is crucial for training robust models, but crowdsourced text often lacks diversity as workers tend to write simple variations from prompts. We propose a general approach for guiding workers to write more diverse text by iteratively constraining their writing. We show how prior workflows are special cases of our approach, and present a way to apply the approach to dialog tasks such as intent classification and slot-filling. Using our method, we create more challenging versions of test sets from prior dialog datasets and find dramatic performance drops for standard models. Finally, we show that our approach is complementary to recent work on improving data diversity, and training on data collected with our approach leads to more robust models.
        </p>
    </div>
  </div>
  <div class="row" id="emnlp20taboo-cite" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          
        <pre>
        @InProceedings{emnlp20taboo,
  title     = {Iterative Feature Mining for Constraint-Based Data Collection to Increase Data Diversity and Model Robustness},
  author    = {Larson, Stefan and Zheng, Anthony and Mahendran, Anish and Tekriwal, Rishi and Cheung, Adrian and Guldan, Eric and Leach, Kevin and Kummerfeld, Jonathan K.},
  booktitle = {Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  month     = {November},
  year      = {2020},
  location  = {Online},
  pages     = {8097--8106},
  url       = {https://www.aclweb.org/anthology/2020.emnlp-main.650},
  doi       = {10.18653/v1/2020.emnlp-main.650},
  blog_post = {/post/2020-10-10_taboo/},
  video     = {https://slideslive.com/38938895},
}
        </pre>
        
        </p>
    </div>
  </div>
</div>


<div class="container pb-2">
  <div class="row">
    <div class="col-lg-6">
      <strong>A Novel Workflow for Accurately and Efficiently Crowdsourcing Predicate Senses and Argument Labels</strong>
      <br />
      <span class="text-muted">Youxuan Jiang, Huaiyu Zhu, Jonathan K. Kummerfeld, Yunyao Li, Walter Lasecki</span>
      <br />
      Findings of EMNLP<span class="text-muted">, 2020</span>
    </div>
    <div class="col-lg-6">
      <a class="btn btn-outline-primary btn-sm" href="https://www.aclweb.org/anthology/2020.findings-emnlp.38" target="_blank" rel="noopener"><span
    class="fontawesome-inline-svg"
    style="display: inline-flex; align-self: center; height:1em; width:1em; top: .125em; position: relative;"
><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path fill='currentColor' d="M256 0v128h128L256 0zM224 128L224 0H48C21.49 0 0 21.49 0 48v416C0 490.5 21.49 512 48 512h288c26.51 0 48-21.49 48-48V160h-127.1C238.3 160 224 145.7 224 128zM272 416h-160C103.2 416 96 408.8 96 400C96 391.2 103.2 384 112 384h160c8.836 0 16 7.162 16 16C288 408.8 280.8 416 272 416zM272 352h-160C103.2 352 96 344.8 96 336C96 327.2 103.2 320 112 320h160c8.836 0 16 7.162 16 16C288 344.8 280.8 352 272 352zM288 272C288 280.8 280.8 288 272 288h-160C103.2 288 96 280.8 96 272C96 263.2 103.2 256 112 256h160C280.8 256 288 263.2 288 272z"/></svg>
</span>
 PDF</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('emnlp-findings20srl-abstract').style.display == 'block') {
  document.getElementById('emnlp-findings20srl-abstract').style.display='none';
  } else {
  document.getElementById('emnlp-findings20srl-abstract').style.display='block';
  }
  ">Abstract</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('emnlp-findings20srl-cite').style.display == 'block') {
  document.getElementById('emnlp-findings20srl-cite').style.display='none';
  } else {
  document.getElementById('emnlp-findings20srl-cite').style.display='block';
  }
  ">BibTeX</a>
      
      
      <a class="btn btn-outline-primary btn-sm" href="/post/2020-10-04_crowdsrl/" target="_blank" rel="noopener">Blog Post</a>
      
      
      
      
      
      
    </div>
  </div>
  <div class="row" id="emnlp-findings20srl-abstract" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          Resources for Semantic Role Labeling (SRL) are typically annotated by experts at great expense. Prior attempts to develop crowdsourcing methods have either had low accuracy or required substantial expert annotation. We propose a new multi-stage crowd workflow that substantially reduces expert involvement without sacrificing accuracy. In particular, we introduce a unique filter stage based on the key observation that crowd workers are able to almost perfectly filter out incorrect options for labels. Our three-stage workflow produces annotations with 95% accuracy for predicate labels and 93% for argument labels, which is comparable to expert agreement. Compared to prior work on crowdsourcing for SRL, we decrease expert effort by 4x, from 56% to 14% of cases. Our approach enables more scalable annotation of SRL, and could enable annotation of NLP tasks that have previously been considered too complex to effectively crowdsource.
        </p>
    </div>
  </div>
  <div class="row" id="emnlp-findings20srl-cite" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          
        <pre>
        @InProceedings{emnlp-findings20srl,
  title     = {A Novel Workflow for Accurately and Efficiently Crowdsourcing Predicate Senses and Argument Labels},
  author    = {Jiang, Youxuan and Zhu, Huaiyu and Kummerfeld, Jonathan K. and Li, Yunyao and Lasecki, Walter},
  booktitle = {Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: Findings},
  month     = {November},
  year      = {2020},
  location  = {Online},
  pages     = {415--421},
  url       = {https://www.aclweb.org/anthology/2020.findings-emnlp.38},
  doi       = {10.18653/v1/2020.findings-emnlp.38},
  blog_post = {/post/2020-10-04_CrowdSRL/},
}
        </pre>
        
        </p>
    </div>
  </div>
</div>


<div class="container pb-2">
  <div class="row">
    <div class="col-lg-6">
      <strong>Crowdsourced Detection of Emotionally Manipulative Language</strong>
      <br />
      <span class="text-muted">Jordan S. Huffaker, Jonathan K. Kummerfeld, Walter S. Lasecki, Mark S. Ackerman</span>
      <br />
      CHI<span class="text-muted">, 2020</span>
    </div>
    <div class="col-lg-6">
      <a class="btn btn-outline-primary btn-sm" href="https://www.jkk.name/pub/chi20anchor.pdf" target="_blank" rel="noopener"><span
    class="fontawesome-inline-svg"
    style="display: inline-flex; align-self: center; height:1em; width:1em; top: .125em; position: relative;"
><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path fill='currentColor' d="M256 0v128h128L256 0zM224 128L224 0H48C21.49 0 0 21.49 0 48v416C0 490.5 21.49 512 48 512h288c26.51 0 48-21.49 48-48V160h-127.1C238.3 160 224 145.7 224 128zM272 416h-160C103.2 416 96 408.8 96 400C96 391.2 103.2 384 112 384h160c8.836 0 16 7.162 16 16C288 408.8 280.8 416 272 416zM272 352h-160C103.2 352 96 344.8 96 336C96 327.2 103.2 320 112 320h160c8.836 0 16 7.162 16 16C288 344.8 280.8 352 272 352zM288 272C288 280.8 280.8 288 272 288h-160C103.2 288 96 280.8 96 272C96 263.2 103.2 256 112 256h160C280.8 256 288 263.2 288 272z"/></svg>
</span>
 PDF</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('chi20anchor-abstract').style.display == 'block') {
  document.getElementById('chi20anchor-abstract').style.display='none';
  } else {
  document.getElementById('chi20anchor-abstract').style.display='block';
  }
  ">Abstract</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('chi20anchor-cite').style.display == 'block') {
  document.getElementById('chi20anchor-cite').style.display='none';
  } else {
  document.getElementById('chi20anchor-cite').style.display='block';
  }
  ">BibTeX</a>
      
      
      
      
      
      
      
    </div>
  </div>
  <div class="row" id="chi20anchor-abstract" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          Detecting rhetoric that manipulates readers’ emotions requires distinguishing intrinsically emotional content (IEC; e.g., a parent losing a child) from emotionally manipulative language (EML; e.g., using fear-inducing language to spread anti-vaccine propaganda). However, this remains an open classifcation challenge for both automatic and crowdsourcing approaches. Machine Learning approaches only work in narrow domains where labeled training data is available, and non-expert annotators tend to confate IEC with EML. We introduce an approach, anchor comparison, that leverages workers’ ability to identify and remove instances of EML in text to create a paraphrased &#39;anchor text&#39;, which is then used as a comparison point to classify EML in the original content. We evaluate our approach with a dataset of news-style text snippets and show that precision and recall can be tuned for system builders’ needs. Our contribution is a crowdsourcing approach that enables non-expert disentanglement of social references from content.
        </p>
    </div>
  </div>
  <div class="row" id="chi20anchor-cite" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          
        <pre>
        @InProceedings{chi20anchor,
  author    = {Huffaker, Jordan S. and Kummerfeld, Jonathan K. and Lasecki, Walter S. and Ackerman, Mark S.},
  title     = {Crowdsourced Detection of Emotionally Manipulative Language},
  year      = {2020},
  publisher = {Association for Computing Machinery},
  booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
  isbn      = {9781450367080},
  address   = {New York, NY, USA},
  doi       = {10.1145/3313831.3376375},
  pages     = {1--14},
  location  = {Honolulu, HI, USA},
  url       = {https://www.jkk.name/pub/chi20anchor.pdf},
}
        </pre>
        
        </p>
    </div>
  </div>
</div>


<div class="container pb-2">
  <div class="row">
    <div class="col-lg-6">
      <strong>Overview of the seventh Dialog System Technology Challenge: DSTC7</strong>
      <br />
      <span class="text-muted">Luis Fernando D&#39;Haro, Koichiro Yoshino, Chiori Hori, Tim K. Marks, Lazaros Polymenakos, Jonathan K. Kummerfeld, Michel Galley, Xiang Gao</span>
      <br />
      CSL<span class="text-muted">, 2020</span>
    </div>
    <div class="col-lg-6">
      <a class="btn btn-outline-primary btn-sm" href="https://www.jkk.name/pub/csl20dstc.pdf" target="_blank" rel="noopener"><span
    class="fontawesome-inline-svg"
    style="display: inline-flex; align-self: center; height:1em; width:1em; top: .125em; position: relative;"
><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path fill='currentColor' d="M256 0v128h128L256 0zM224 128L224 0H48C21.49 0 0 21.49 0 48v416C0 490.5 21.49 512 48 512h288c26.51 0 48-21.49 48-48V160h-127.1C238.3 160 224 145.7 224 128zM272 416h-160C103.2 416 96 408.8 96 400C96 391.2 103.2 384 112 384h160c8.836 0 16 7.162 16 16C288 408.8 280.8 416 272 416zM272 352h-160C103.2 352 96 344.8 96 336C96 327.2 103.2 320 112 320h160c8.836 0 16 7.162 16 16C288 344.8 280.8 352 272 352zM288 272C288 280.8 280.8 288 272 288h-160C103.2 288 96 280.8 96 272C96 263.2 103.2 256 112 256h160C280.8 256 288 263.2 288 272z"/></svg>
</span>
 PDF</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('csl20dstc-abstract').style.display == 'block') {
  document.getElementById('csl20dstc-abstract').style.display='none';
  } else {
  document.getElementById('csl20dstc-abstract').style.display='block';
  }
  ">Abstract</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('csl20dstc-cite').style.display == 'block') {
  document.getElementById('csl20dstc-cite').style.display='none';
  } else {
  document.getElementById('csl20dstc-cite').style.display='block';
  }
  ">BibTeX</a>
      
      
      
      <a class="btn btn-outline-primary btn-sm" href="https://ibm.github.io/dstc-noesis/public/index.html" target="_blank" rel="noopener"><span
    class="fontawesome-inline-svg"
    style="display: inline-flex; align-self: center; height:1em; width:1em; top: .125em; position: relative;"
><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill='currentColor' d="M448 80V128C448 172.2 347.7 208 224 208C100.3 208 0 172.2 0 128V80C0 35.82 100.3 0 224 0C347.7 0 448 35.82 448 80zM393.2 214.7C413.1 207.3 433.1 197.8 448 186.1V288C448 332.2 347.7 368 224 368C100.3 368 0 332.2 0 288V186.1C14.93 197.8 34.02 207.3 54.85 214.7C99.66 230.7 159.5 240 224 240C288.5 240 348.3 230.7 393.2 214.7V214.7zM54.85 374.7C99.66 390.7 159.5 400 224 400C288.5 400 348.3 390.7 393.2 374.7C413.1 367.3 433.1 357.8 448 346.1V432C448 476.2 347.7 512 224 512C100.3 512 0 476.2 0 432V346.1C14.93 357.8 34.02 367.3 54.85 374.7z"/></svg>
</span>
 Data</a>
      
      
      
      
      
    </div>
  </div>
  <div class="row" id="csl20dstc-abstract" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          This paper provides detailed information about the seventh Dialog System Technology Challenge (DSTC7) and its three tracks aimed to explore the problem of building robust and accurate end-to-end dialog systems. In more detail, DSTC7 focuses on developing and exploring end-to-end technologies for the following three pragmatic challenges: (1) sentence selection for multiple domains, (2) generation of informational responses grounded in external knowledge, and (3) audio visual scene-aware dialog to allow conversations with users about objects and events around them. This paper summarizes the overall setup and results of DSTC7, including detailed descriptions of the different tracks, provided datasets and annotations, overview of the submitted systems and their final results. For Track 1, LSTM-based models performed best across both datasets, allowing teams to effectively handle task variants where no correct answer was present or when multiple paraphrases were included. For Track 2, RNN-based architectures augmented to incorporate facts by using two types of encoders: a dialog encoder and a fact encoder plus using attention mechanisms and a pointer-generator approach provided the best results. Finally, for Track 3, the best model used Hierarchical Attention mechanisms to combine the text and vision information obtaining a 22% better result than the baseline LSTM system for the human rating score. More than 220 participants were registered and about 40 teams participated in the final challenge. 32 scientific papers reporting the systems submitted to DSTC7, and 3 general technical papers for dialog technologies, were presented during the one-day wrap-up workshop at AAAI-19. During the workshop, we reviewed the state-of-the-art systems, shared novel approaches to the DSTC7 tasks, and discussed the future directions for the challenge (DSTC8).
        </p>
    </div>
  </div>
  <div class="row" id="csl20dstc-cite" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          
        <pre>
        @article{csl20dstc,
  title     = {Overview of the seventh Dialog System Technology Challenge: DSTC7},
  journal   = {Computer Speech & Language},
  pages     = {101068},
  year      = {2020},
  issn      = {0885-2308},
  doi       = {https://doi.org/10.1016/j.csl.2020.101068},
  url       = {https://www.jkk.name/pub/csl20dstc.pdf},
  alt-url   = {http://www.sciencedirect.com/science/article/pii/S0885230820300012},
  data      = {https://ibm.github.io/dstc-noesis/public/index.html},
  author    = {D'Haro, Luis Fernando and Yoshino, Koichiro and Hori, Chiori and Marks, Tim K. and Polymenakos, Lazaros and Kummerfeld, Jonathan K. and Galley, Michel and Gao, Xiang},
}
        </pre>
        
        </p>
    </div>
  </div>
</div>


<div class="container pb-2">
  <div class="row">
    <div class="col-lg-6">
      <strong>Inconsistencies in Crowdsourced Slot-Filling Annotations: A Typology and Identification Methods</strong>
      <br />
      <span class="text-muted">Stefan Larson, Adrian Cheung, Anish Mahendran, Kevin Leach, Jonathan K. Kummerfeld</span>
      <br />
      CoLing<span class="text-muted">, 2020</span>
    </div>
    <div class="col-lg-6">
      <a class="btn btn-outline-primary btn-sm" href="https://www.aclweb.org/anthology/2020.coling-main.442" target="_blank" rel="noopener"><span
    class="fontawesome-inline-svg"
    style="display: inline-flex; align-self: center; height:1em; width:1em; top: .125em; position: relative;"
><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path fill='currentColor' d="M256 0v128h128L256 0zM224 128L224 0H48C21.49 0 0 21.49 0 48v416C0 490.5 21.49 512 48 512h288c26.51 0 48-21.49 48-48V160h-127.1C238.3 160 224 145.7 224 128zM272 416h-160C103.2 416 96 408.8 96 400C96 391.2 103.2 384 112 384h160c8.836 0 16 7.162 16 16C288 408.8 280.8 416 272 416zM272 352h-160C103.2 352 96 344.8 96 336C96 327.2 103.2 320 112 320h160c8.836 0 16 7.162 16 16C288 344.8 280.8 352 272 352zM288 272C288 280.8 280.8 288 272 288h-160C103.2 288 96 280.8 96 272C96 263.2 103.2 256 112 256h160C280.8 256 288 263.2 288 272z"/></svg>
</span>
 PDF</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('coling20svp-abstract').style.display == 'block') {
  document.getElementById('coling20svp-abstract').style.display='none';
  } else {
  document.getElementById('coling20svp-abstract').style.display='block';
  }
  ">Abstract</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('coling20svp-cite').style.display == 'block') {
  document.getElementById('coling20svp-cite').style.display='none';
  } else {
  document.getElementById('coling20svp-cite').style.display='block';
  }
  ">BibTeX</a>
      
      
      
      
      
      
      
    </div>
  </div>
  <div class="row" id="coling20svp-abstract" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          Slot-filling models in task-driven dialog systems rely on carefully annotated training data. However, annotations by crowd workers are often inconsistent or contain errors. Simple solutions like manually checking annotations or having multiple workers label each sample are expensive and waste effort on samples that are correct. If we can identify inconsistencies, we can focus effort where it is needed. Toward this end, we define six inconsistency types in slot-filling annotations. Using three new noisy crowd-annotated datasets, we show that a wide range of inconsistencies occur and can impact system performance if not addressed. We then introduce automatic methods of identifying inconsistencies. Experiments on our new datasets show that these methods effectively reveal inconsistencies in data, though there is further scope for improvement.
        </p>
    </div>
  </div>
  <div class="row" id="coling20svp-cite" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          
        <pre>
        @InProceedings{coling20svp,
  title     = {Inconsistencies in Crowdsourced Slot-Filling Annotations: A Typology and Identification Methods},
  author    = {Larson, Stefan and Cheung, Adrian and Mahendran, Anish and Leach, Kevin and Kummerfeld, Jonathan K.},
  year      = {2020},
  month     = {December},
  booktitle = {Proceedings of the 28th International Conference on Computational Linguistics},
  url       = {https://www.aclweb.org/anthology/2020.coling-main.442},
  pages     = {5035--5046},
  location  = {Barcelona, Spain (Online)},
}
        </pre>
        
        </p>
    </div>
  </div>
</div>


<div class="container pb-2">
  <div class="row">
    <div class="col-lg-6">
      <strong>Exploring the Value of Personalized Word Embeddings</strong>
      <br />
      <span class="text-muted">Charles Welch, Jonathan K. Kummerfeld, Verónica Pérez-Rosas, Rada Mihalcea</span>
      <br />
      CoLing (short)<span class="text-muted">, 2020</span>
    </div>
    <div class="col-lg-6">
      <a class="btn btn-outline-primary btn-sm" href="https://www.aclweb.org/anthology/2020.coling-main.604" target="_blank" rel="noopener"><span
    class="fontawesome-inline-svg"
    style="display: inline-flex; align-self: center; height:1em; width:1em; top: .125em; position: relative;"
><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path fill='currentColor' d="M256 0v128h128L256 0zM224 128L224 0H48C21.49 0 0 21.49 0 48v416C0 490.5 21.49 512 48 512h288c26.51 0 48-21.49 48-48V160h-127.1C238.3 160 224 145.7 224 128zM272 416h-160C103.2 416 96 408.8 96 400C96 391.2 103.2 384 112 384h160c8.836 0 16 7.162 16 16C288 408.8 280.8 416 272 416zM272 352h-160C103.2 352 96 344.8 96 336C96 327.2 103.2 320 112 320h160c8.836 0 16 7.162 16 16C288 344.8 280.8 352 272 352zM288 272C288 280.8 280.8 288 272 288h-160C103.2 288 96 280.8 96 272C96 263.2 103.2 256 112 256h160C280.8 256 288 263.2 288 272z"/></svg>
</span>
 PDF</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('coling20personal-abstract').style.display == 'block') {
  document.getElementById('coling20personal-abstract').style.display='none';
  } else {
  document.getElementById('coling20personal-abstract').style.display='block';
  }
  ">Abstract</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('coling20personal-cite').style.display == 'block') {
  document.getElementById('coling20personal-cite').style.display='none';
  } else {
  document.getElementById('coling20personal-cite').style.display='block';
  }
  ">BibTeX</a>
      
      
      
      
      
      
      
    </div>
  </div>
  <div class="row" id="coling20personal-abstract" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          In this paper, we introduce personalized word embeddings, and examine their value for language modeling. We compare the performance of our proposed prediction model when using personalized versus generic word representations, and study how these representations can be leveraged for improved performance. We provide insight into what types of words can be more accurately predicted when building personalized models. Our results show that a subset of words belonging to specific psycholinguistic categories tend to vary more in their representations across users and that combining generic and personalized word embeddings yields the best performance, with a 4.7{%} relative reduction in perplexity. Additionally, we show that a language model using personalized word embeddings can be effectively used for authorship attribution.
        </p>
    </div>
  </div>
  <div class="row" id="coling20personal-cite" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          
        <pre>
        @InProceedings{coling20personal,
  title     = {Exploring the Value of Personalized Word Embeddings},
  author    = {Welch, Charles and Kummerfeld, Jonathan K. and P{\\'e}rez-Rosas, Ver{\\'o}nica and Mihalcea, Rada},
  year      = {2020},
  month     = {December},
  booktitle = {Proceedings of the 28th International Conference on Computational Linguistics},
  pages     = {6856--6862},
  location  = {Barcelona, Spain (Online)},
  url       = {https://www.aclweb.org/anthology/2020.coling-main.604},
}
        </pre>
        
        </p>
    </div>
  </div>
</div>


<h3 id="2019">2019</h3>
<div class="container pb-2">
  <div class="row">
    <div class="col-lg-6">
      <strong>No-Press Diplomacy: Modeling Multi-Agent Gameplay</strong>
      <br />
      <span class="text-muted">Philip Paquette, Yuchen Lu, Steven Bocco, Max O. Smith, Satya Ortiz-Gagné, Jonathan K. Kummerfeld, Joelle Pineau, Satinder Singh, Aaron Courville</span>
      <br />
      NeurIPS<span class="text-muted">, 2019</span>
    </div>
    <div class="col-lg-6">
      <a class="btn btn-outline-primary btn-sm" href="https://papers.nips.cc/paper/8697-no-press-diplomacy-modeling-multi-agent-gameplay" target="_blank" rel="noopener"><span
    class="fontawesome-inline-svg"
    style="display: inline-flex; align-self: center; height:1em; width:1em; top: .125em; position: relative;"
><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path fill='currentColor' d="M256 0v128h128L256 0zM224 128L224 0H48C21.49 0 0 21.49 0 48v416C0 490.5 21.49 512 48 512h288c26.51 0 48-21.49 48-48V160h-127.1C238.3 160 224 145.7 224 128zM272 416h-160C103.2 416 96 408.8 96 400C96 391.2 103.2 384 112 384h160c8.836 0 16 7.162 16 16C288 408.8 280.8 416 272 416zM272 352h-160C103.2 352 96 344.8 96 336C96 327.2 103.2 320 112 320h160c8.836 0 16 7.162 16 16C288 344.8 280.8 352 272 352zM288 272C288 280.8 280.8 288 272 288h-160C103.2 288 96 280.8 96 272C96 263.2 103.2 256 112 256h160C280.8 256 288 263.2 288 272z"/></svg>
</span>
 PDF</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('neurips19diplomacy-abstract').style.display == 'block') {
  document.getElementById('neurips19diplomacy-abstract').style.display='none';
  } else {
  document.getElementById('neurips19diplomacy-abstract').style.display='block';
  }
  ">Abstract</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('neurips19diplomacy-cite').style.display == 'block') {
  document.getElementById('neurips19diplomacy-cite').style.display='none';
  } else {
  document.getElementById('neurips19diplomacy-cite').style.display='block';
  }
  ">BibTeX</a>
      
      <a class="btn btn-outline-primary btn-sm" href="https://papers.nips.cc/paper/8697-no-press-diplomacy-modeling-multi-agent-gameplay-supplemental.zip" target="_blank" rel="noopener">Supplementary Material</a>
      
      
      <a class="btn btn-outline-primary btn-sm" href="/post/2019-09-13_diplomacynopress/" target="_blank" rel="noopener">Blog Post</a>
      
      
      
      
      
      
    </div>
  </div>
  <div class="row" id="neurips19diplomacy-abstract" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          Diplomacy is a seven-player non-stochastic, non-cooperative game, where agents acquire resources through a mix of teamwork and betrayal. Reliance on trust and coordination makes Diplomacy the first non-cooperative multi-agent benchmark for complex sequential social dilemmas in a rich environment. In this work, we focus on training an agent that learns to play the No Press version of Diplomacy where there is no dedicated communication channel between players. We present DipNet, a neural-network-based policy model for No Press Diplomacy. The model was trained on a new dataset of more than 150,000 human games. Our model is trained by supervised learning (SL) from expert trajectories, which is then used to initialize a reinforcement learning (RL) agent trained through self-play. Both the SL and RL agents demonstrate state-of-the-art No Press performance by beating popular rule-based bots.
        </p>
    </div>
  </div>
  <div class="row" id="neurips19diplomacy-cite" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          
        <pre>
        @InProceedings{neurips19diplomacy,
  author    = {Paquette, Philip and Lu, Yuchen and Bocco, Steven and Smith, Max O. and Ortiz-Gagn{\\'e}, Satya and Kummerfeld, Jonathan K. and Pineau, Joelle and Singh, Satinder and Courville, Aaron},
  title     = {No-Press Diplomacy: Modeling Multi-Agent Gameplay},
  booktitle = {Advances in Neural Information Processing Systems 32},
  year      = {2019},
  month     = {December},
  pages     = {4476--4487},
  url       = {https://papers.nips.cc/paper/8697-no-press-diplomacy-modeling-multi-agent-gameplay},
  supplementary = {https://papers.nips.cc/paper/8697-no-press-diplomacy-modeling-multi-agent-gameplay-supplemental.zip},
  arxiv     = {https://arxiv.org/abs/1909.02128},
  blog_post = {/post/2019-09-13_diplomacynopress/},
}
        </pre>
        
        </p>
    </div>
  </div>
</div>


<div class="container pb-2">
  <div class="row">
    <div class="col-lg-6">
      <strong>An Evaluation for Intent Classification and Out-of-Scope Prediction</strong>
      <br />
      <span class="text-muted">Stefan Larson, Anish Mahendran, Joseph J. Peper, Christopher Clarke, Andrew Lee, Parker Hill, Jonathan K. Kummerfeld, Kevin Leach, Michael A. Laurenzano, Lingjia Tang, Jason Mars</span>
      <br />
      EMNLP (short)<span class="text-muted">, 2019</span>
    </div>
    <div class="col-lg-6">
      <a class="btn btn-outline-primary btn-sm" href="https://www.aclweb.org/anthology/D19-1131/" target="_blank" rel="noopener"><span
    class="fontawesome-inline-svg"
    style="display: inline-flex; align-self: center; height:1em; width:1em; top: .125em; position: relative;"
><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path fill='currentColor' d="M256 0v128h128L256 0zM224 128L224 0H48C21.49 0 0 21.49 0 48v416C0 490.5 21.49 512 48 512h288c26.51 0 48-21.49 48-48V160h-127.1C238.3 160 224 145.7 224 128zM272 416h-160C103.2 416 96 408.8 96 400C96 391.2 103.2 384 112 384h160c8.836 0 16 7.162 16 16C288 408.8 280.8 416 272 416zM272 352h-160C103.2 352 96 344.8 96 336C96 327.2 103.2 320 112 320h160c8.836 0 16 7.162 16 16C288 344.8 280.8 352 272 352zM288 272C288 280.8 280.8 288 272 288h-160C103.2 288 96 280.8 96 272C96 263.2 103.2 256 112 256h160C280.8 256 288 263.2 288 272z"/></svg>
</span>
 PDF</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('emnlp19data-abstract').style.display == 'block') {
  document.getElementById('emnlp19data-abstract').style.display='none';
  } else {
  document.getElementById('emnlp19data-abstract').style.display='block';
  }
  ">Abstract</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('emnlp19data-cite').style.display == 'block') {
  document.getElementById('emnlp19data-cite').style.display='none';
  } else {
  document.getElementById('emnlp19data-cite').style.display='block';
  }
  ">BibTeX</a>
      
      
      
      <a class="btn btn-outline-primary btn-sm" href="https://github.com/clinc/oos-eval" target="_blank" rel="noopener"><span
    class="fontawesome-inline-svg"
    style="display: inline-flex; align-self: center; height:1em; width:1em; top: .125em; position: relative;"
><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill='currentColor' d="M448 80V128C448 172.2 347.7 208 224 208C100.3 208 0 172.2 0 128V80C0 35.82 100.3 0 224 0C347.7 0 448 35.82 448 80zM393.2 214.7C413.1 207.3 433.1 197.8 448 186.1V288C448 332.2 347.7 368 224 368C100.3 368 0 332.2 0 288V186.1C14.93 197.8 34.02 207.3 54.85 214.7C99.66 230.7 159.5 240 224 240C288.5 240 348.3 230.7 393.2 214.7V214.7zM54.85 374.7C99.66 390.7 159.5 400 224 400C288.5 400 348.3 390.7 393.2 374.7C413.1 367.3 433.1 357.8 448 346.1V432C448 476.2 347.7 512 224 512C100.3 512 0 476.2 0 432V346.1C14.93 357.8 34.02 367.3 54.85 374.7z"/></svg>
</span>
 Data</a>
      
      
      
      
      
    </div>
  </div>
  <div class="row" id="emnlp19data-abstract" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          Task-oriented dialog systems need to know when a query falls outside their range of supported intents, but current text classification corpora only define label sets that cover every example. We introduce a new dataset that includes queries that are out-of-scope---i.e., queries that do not fall into any of the system&#39;s supported intents. This poses a new challenge because models cannot assume that every query at inference time belongs to a system-supported intent class. Our dataset also covers 150 intent classes over 10 domains, capturing the breadth that a production task-oriented agent must handle. We evaluate a range of benchmark classifiers on our dataset along with several different out-of-scope identification schemes. We find that while the classifiers perform well on in-scope intent classification, they struggle to identify out-of-scope queries. Our dataset and evaluation fill an important gap in the field, offering a way of more rigorously and realistically benchmarking text classification in task-driven dialog systems.
        </p>
    </div>
  </div>
  <div class="row" id="emnlp19data-cite" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          
        <pre>
        @InProceedings{emnlp19data,
  title     = {An Evaluation for Intent Classification and Out-of-Scope Prediction},
  author    = {Larson, Stefan and Mahendran, Anish and Peper, Joseph J. and Clarke, Christopher and Lee, Andrew and Hill, Parker and Kummerfeld, Jonathan K. and Leach, Kevin and Laurenzano, Michael A. and Tang, Lingjia and Mars, Jason},
  booktitle = {Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing},
  month     = {November},
  year      = {2019},
  location  = {Hong Kong, China},
  pages     = {1311--1316},
  url       = {https://www.aclweb.org/anthology/D19-1131/},
  doi       = {10.18653/v1/D19-1131},
  data      = {https://github.com/clinc/oos-eval},
  arxiv     = {https://arxiv.org/abs/1909.02027},
}
        </pre>
        
        </p>
    </div>
  </div>
</div>


<div class="container pb-2">
  <div class="row">
    <div class="col-lg-6">
      <strong>A Large-Scale Corpus for Conversation Disentanglement</strong>
      <br />
      <span class="text-muted">Jonathan K. Kummerfeld, Sai R. Gouravajhala, Joseph J. Peper, Vignesh Athreya, Chulaka Gunasekara, Jatin Ganhotra, Siva Sankalp Patel, Lazaros Polymenakos, Walter S. Lasecki</span>
      <br />
      ACL<span class="text-muted">, 2019</span>
    </div>
    <div class="col-lg-6">
      <a class="btn btn-outline-primary btn-sm" href="https://www.aclweb.org/anthology/P19-1374.pdf" target="_blank" rel="noopener"><span
    class="fontawesome-inline-svg"
    style="display: inline-flex; align-self: center; height:1em; width:1em; top: .125em; position: relative;"
><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path fill='currentColor' d="M256 0v128h128L256 0zM224 128L224 0H48C21.49 0 0 21.49 0 48v416C0 490.5 21.49 512 48 512h288c26.51 0 48-21.49 48-48V160h-127.1C238.3 160 224 145.7 224 128zM272 416h-160C103.2 416 96 408.8 96 400C96 391.2 103.2 384 112 384h160c8.836 0 16 7.162 16 16C288 408.8 280.8 416 272 416zM272 352h-160C103.2 352 96 344.8 96 336C96 327.2 103.2 320 112 320h160c8.836 0 16 7.162 16 16C288 344.8 280.8 352 272 352zM288 272C288 280.8 280.8 288 272 288h-160C103.2 288 96 280.8 96 272C96 263.2 103.2 256 112 256h160C280.8 256 288 263.2 288 272z"/></svg>
</span>
 PDF</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('acl19disentangle-abstract').style.display == 'block') {
  document.getElementById('acl19disentangle-abstract').style.display='none';
  } else {
  document.getElementById('acl19disentangle-abstract').style.display='block';
  }
  ">Abstract</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('acl19disentangle-cite').style.display == 'block') {
  document.getElementById('acl19disentangle-cite').style.display='none';
  } else {
  document.getElementById('acl19disentangle-cite').style.display='block';
  }
  ">BibTeX</a>
      
      <a class="btn btn-outline-primary btn-sm" href="https://www.aclweb.org/anthology/attachments/P19-1374.Supplementary.pdf" target="_blank" rel="noopener">Supplementary Material</a>
      
      
      <a class="btn btn-outline-primary btn-sm" href="/post/2019-07-10_disentanglement/" target="_blank" rel="noopener">Blog Post</a>
      
      
      <a class="btn btn-outline-primary btn-sm" href="https://www.jkk.name/irc-disentanglement" target="_blank" rel="noopener"><span
    class="fontawesome-inline-svg"
    style="display: inline-flex; align-self: center; height:1em; width:1em; top: .125em; position: relative;"
><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill='currentColor' d="M448 80V128C448 172.2 347.7 208 224 208C100.3 208 0 172.2 0 128V80C0 35.82 100.3 0 224 0C347.7 0 448 35.82 448 80zM393.2 214.7C413.1 207.3 433.1 197.8 448 186.1V288C448 332.2 347.7 368 224 368C100.3 368 0 332.2 0 288V186.1C14.93 197.8 34.02 207.3 54.85 214.7C99.66 230.7 159.5 240 224 240C288.5 240 348.3 230.7 393.2 214.7V214.7zM54.85 374.7C99.66 390.7 159.5 400 224 400C288.5 400 348.3 390.7 393.2 374.7C413.1 367.3 433.1 357.8 448 346.1V432C448 476.2 347.7 512 224 512C100.3 512 0 476.2 0 432V346.1C14.93 357.8 34.02 367.3 54.85 374.7z"/></svg>
</span>
 Data</a>
      
      
      <a class="btn btn-outline-primary btn-sm" href="https://www.jkk.name/irc-disentanglement" target="_blank" rel="noopener"><span
    class="fontawesome-inline-svg"
    style="display: inline-flex; align-self: center; height:1em; width:1em; top: .125em; position: relative;"
><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512"><path fill='currentColor' d="M414.8 40.79L286.8 488.8C281.9 505.8 264.2 515.6 247.2 510.8C230.2 505.9 220.4 488.2 225.2 471.2L353.2 23.21C358.1 6.216 375.8-3.624 392.8 1.232C409.8 6.087 419.6 23.8 414.8 40.79H414.8zM518.6 121.4L630.6 233.4C643.1 245.9 643.1 266.1 630.6 278.6L518.6 390.6C506.1 403.1 485.9 403.1 473.4 390.6C460.9 378.1 460.9 357.9 473.4 345.4L562.7 256L473.4 166.6C460.9 154.1 460.9 133.9 473.4 121.4C485.9 108.9 506.1 108.9 518.6 121.4V121.4zM166.6 166.6L77.25 256L166.6 345.4C179.1 357.9 179.1 378.1 166.6 390.6C154.1 403.1 133.9 403.1 121.4 390.6L9.372 278.6C-3.124 266.1-3.124 245.9 9.372 233.4L121.4 121.4C133.9 108.9 154.1 108.9 166.6 121.4C179.1 133.9 179.1 154.1 166.6 166.6V166.6z"/></svg>
</span>
 Software</a>
      
      
      <a class="btn btn-outline-primary btn-sm" href="https://www.jkk.name/pub/acl19disentangle_poster.pdf" target="_blank" rel="noopener">Poster</a>
      
      
      
    </div>
  </div>
  <div class="row" id="acl19disentangle-abstract" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          Disentangling conversations mixed together in a single stream of messages is a difficult task, made harder by the lack of large manually annotated datasets. We created a new dataset of 77,563 messages manually annotated with reply-structure graphs that both disentangle conversations and define internal conversation structure. Our data is 16 times larger than all previously released datasets combined, the first to include adjudication of annotation disagreements, and the first to include context. We use our data to re-examine prior work, in particular, finding that 89% of conversations in a widely used dialogue corpus are either missing messages or contain extra messages. Our manually-annotated data presents an opportunity to develop robust data-driven methods for conversation disentanglement, which will help advance dialogue research.
        </p>
    </div>
  </div>
  <div class="row" id="acl19disentangle-cite" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          
        <pre>
        @InProceedings{acl19disentangle,
  author    = {Kummerfeld, Jonathan K. and Gouravajhala, Sai R. and Peper, Joseph J. and Athreya, Vignesh and Gunasekara, Chulaka and Ganhotra, Jatin and Patel, Siva Sankalp and Polymenakos, Lazaros and Lasecki, Walter S.},
  title     = {A Large-Scale Corpus for Conversation Disentanglement},
  location  = {Florence, Italy},
  booktitle = {Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
  month     = {July},
  year      = {2019},
  url       = {https://www.aclweb.org/anthology/P19-1374.pdf},
  pages     = {3846--3856},
  doi       = {10.18653/v1/P19-1374},
  arxiv     = {https://arxiv.org/abs/1810.11118},
  software  = {https://www.jkk.name/irc-disentanglement},
  data      = {https://www.jkk.name/irc-disentanglement},
  blog_post = {/post/2019-07-10_disentanglement/},
  supplementary = {https://www.aclweb.org/anthology/attachments/P19-1374.Supplementary.pdf},
  poster    = {https://www.jkk.name/pub/acl19disentangle_poster.pdf},
}
        </pre>
        
        </p>
    </div>
  </div>
</div>


<div class="container pb-2">
  <div class="row">
    <div class="col-lg-6">
      <strong>SLATE: A Super-Lightweight Annotation Tool for Experts</strong>
      <br />
      <span class="text-muted">Jonathan K. Kummerfeld</span>
      <br />
      ACL (demo)<span class="text-muted">, 2019</span>
    </div>
    <div class="col-lg-6">
      <a class="btn btn-outline-primary btn-sm" href="https://www.aclweb.org/anthology/P19-3002.pdf" target="_blank" rel="noopener"><span
    class="fontawesome-inline-svg"
    style="display: inline-flex; align-self: center; height:1em; width:1em; top: .125em; position: relative;"
><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path fill='currentColor' d="M256 0v128h128L256 0zM224 128L224 0H48C21.49 0 0 21.49 0 48v416C0 490.5 21.49 512 48 512h288c26.51 0 48-21.49 48-48V160h-127.1C238.3 160 224 145.7 224 128zM272 416h-160C103.2 416 96 408.8 96 400C96 391.2 103.2 384 112 384h160c8.836 0 16 7.162 16 16C288 408.8 280.8 416 272 416zM272 352h-160C103.2 352 96 344.8 96 336C96 327.2 103.2 320 112 320h160c8.836 0 16 7.162 16 16C288 344.8 280.8 352 272 352zM288 272C288 280.8 280.8 288 272 288h-160C103.2 288 96 280.8 96 272C96 263.2 103.2 256 112 256h160C280.8 256 288 263.2 288 272z"/></svg>
</span>
 PDF</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('acl19slate-abstract').style.display == 'block') {
  document.getElementById('acl19slate-abstract').style.display='none';
  } else {
  document.getElementById('acl19slate-abstract').style.display='block';
  }
  ">Abstract</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('acl19slate-cite').style.display == 'block') {
  document.getElementById('acl19slate-cite').style.display='none';
  } else {
  document.getElementById('acl19slate-cite').style.display='block';
  }
  ">BibTeX</a>
      
      
      
      
      <a class="btn btn-outline-primary btn-sm" href="https://www.jkk.name/slate" target="_blank" rel="noopener"><span
    class="fontawesome-inline-svg"
    style="display: inline-flex; align-self: center; height:1em; width:1em; top: .125em; position: relative;"
><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512"><path fill='currentColor' d="M414.8 40.79L286.8 488.8C281.9 505.8 264.2 515.6 247.2 510.8C230.2 505.9 220.4 488.2 225.2 471.2L353.2 23.21C358.1 6.216 375.8-3.624 392.8 1.232C409.8 6.087 419.6 23.8 414.8 40.79H414.8zM518.6 121.4L630.6 233.4C643.1 245.9 643.1 266.1 630.6 278.6L518.6 390.6C506.1 403.1 485.9 403.1 473.4 390.6C460.9 378.1 460.9 357.9 473.4 345.4L562.7 256L473.4 166.6C460.9 154.1 460.9 133.9 473.4 121.4C485.9 108.9 506.1 108.9 518.6 121.4V121.4zM166.6 166.6L77.25 256L166.6 345.4C179.1 357.9 179.1 378.1 166.6 390.6C154.1 403.1 133.9 403.1 121.4 390.6L9.372 278.6C-3.124 266.1-3.124 245.9 9.372 233.4L121.4 121.4C133.9 108.9 154.1 108.9 166.6 121.4C179.1 133.9 179.1 154.1 166.6 166.6V166.6z"/></svg>
</span>
 Software</a>
      
      
      <a class="btn btn-outline-primary btn-sm" href="https://www.jkk.name/pub/acl19slate_poster.pdf" target="_blank" rel="noopener">Poster</a>
      
      
      
    </div>
  </div>
  <div class="row" id="acl19slate-abstract" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          Many annotation tools have been developed, covering a wide variety of tasks and providing features like user management, pre-processing, and automatic labeling. However, all of these tools use a Graphical User Interface, and often require substantial effort for installation and configuration. This paper presents a new annotation tool that is designed to fill the niche of a lightweight interface for users with a terminal-based workflow. Slate supports annotation at different scales (spans of characters, tokens, and lines, or a document) and of different types (free text, labels, and links), with easily customisable keybindings, and unicode support. In a user study comparing with other tools it was consistently the easiest to install and use. Slate fills a need not met by existing systems, and has already been used to annotate two corpora, one of which involved over 250 hours of annotation effort.
        </p>
    </div>
  </div>
  <div class="row" id="acl19slate-cite" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          
        <pre>
        @InProceedings{acl19slate,
  title     = {SLATE: A Super-Lightweight Annotation Tool for Experts},
  author    = {Kummerfeld, Jonathan K.},
  booktitle = {Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: System Demonstrations},
  location  = {Florence, Italy},
  month     = {July},
  year      = {2019},
  pages     = {7--12},
  url       = {https://www.aclweb.org/anthology/P19-3002.pdf},
  doi       = {10.18653/v1/P19-3002},
  software  = {https://www.jkk.name/slate},
  poster    = {https://www.jkk.name/pub/acl19slate_poster.pdf},
}
        </pre>
        
        </p>
    </div>
  </div>
</div>


<div class="container pb-2">
  <div class="row">
    <div class="col-lg-6">
      <strong>Outlier Detection for Improved Data Quality and Diversity in Dialog Systems</strong>
      <br />
      <span class="text-muted">Stefan Larson, Anish Mahendran, Andrew Lee, Jonathan K. Kummerfeld, Parker Hill, Michael Laurenzano, Johann Hauswald, Lingjia Tang, Jason Mars</span>
      <br />
      NAACL<span class="text-muted">, 2019</span>
    </div>
    <div class="col-lg-6">
      <a class="btn btn-outline-primary btn-sm" href="https://www.aclweb.org/anthology/N19-1051.pdf" target="_blank" rel="noopener"><span
    class="fontawesome-inline-svg"
    style="display: inline-flex; align-self: center; height:1em; width:1em; top: .125em; position: relative;"
><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path fill='currentColor' d="M256 0v128h128L256 0zM224 128L224 0H48C21.49 0 0 21.49 0 48v416C0 490.5 21.49 512 48 512h288c26.51 0 48-21.49 48-48V160h-127.1C238.3 160 224 145.7 224 128zM272 416h-160C103.2 416 96 408.8 96 400C96 391.2 103.2 384 112 384h160c8.836 0 16 7.162 16 16C288 408.8 280.8 416 272 416zM272 352h-160C103.2 352 96 344.8 96 336C96 327.2 103.2 320 112 320h160c8.836 0 16 7.162 16 16C288 344.8 280.8 352 272 352zM288 272C288 280.8 280.8 288 272 288h-160C103.2 288 96 280.8 96 272C96 263.2 103.2 256 112 256h160C280.8 256 288 263.2 288 272z"/></svg>
</span>
 PDF</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('naacl19outliers-abstract').style.display == 'block') {
  document.getElementById('naacl19outliers-abstract').style.display='none';
  } else {
  document.getElementById('naacl19outliers-abstract').style.display='block';
  }
  ">Abstract</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('naacl19outliers-cite').style.display == 'block') {
  document.getElementById('naacl19outliers-cite').style.display='none';
  } else {
  document.getElementById('naacl19outliers-cite').style.display='block';
  }
  ">BibTeX</a>
      
      
      
      <a class="btn btn-outline-primary btn-sm" href="https://github.com/clinc/uniqueness" target="_blank" rel="noopener"><span
    class="fontawesome-inline-svg"
    style="display: inline-flex; align-self: center; height:1em; width:1em; top: .125em; position: relative;"
><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill='currentColor' d="M448 80V128C448 172.2 347.7 208 224 208C100.3 208 0 172.2 0 128V80C0 35.82 100.3 0 224 0C347.7 0 448 35.82 448 80zM393.2 214.7C413.1 207.3 433.1 197.8 448 186.1V288C448 332.2 347.7 368 224 368C100.3 368 0 332.2 0 288V186.1C14.93 197.8 34.02 207.3 54.85 214.7C99.66 230.7 159.5 240 224 240C288.5 240 348.3 230.7 393.2 214.7V214.7zM54.85 374.7C99.66 390.7 159.5 400 224 400C288.5 400 348.3 390.7 393.2 374.7C413.1 367.3 433.1 357.8 448 346.1V432C448 476.2 347.7 512 224 512C100.3 512 0 476.2 0 432V346.1C14.93 357.8 34.02 367.3 54.85 374.7z"/></svg>
</span>
 Data</a>
      
      
      
      
      
    </div>
  </div>
  <div class="row" id="naacl19outliers-abstract" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          In a corpus of data, outliers are either errors: mistakes in the data that are counterproductive, or are unique: informative samples that improve model robustness. Identifying outliers can lead to better datasets by (1) removing noise in datasets and (2) guiding collection of additional data to fill gaps. However, the problem of detecting both outlier types has received relatively little attention in NLP, particularly for dialog systems. We introduce a simple and effective technique for detecting both erroneous and unique samples in a corpus of short texts using neural sentence embeddings combined with distance-based outlier detection. We also present a novel data collection pipeline built atop our detection technique to automatically and iteratively mine unique data samples while discarding erroneous samples. Experiments show that our outlier detection technique is effective at finding errors while our data collection pipeline yields highly diverse corpora that in turn produce more robust intent classification and slot-filling models.
        </p>
    </div>
  </div>
  <div class="row" id="naacl19outliers-cite" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          
        <pre>
        @InProceedings{naacl19outliers,
  title     = {Outlier Detection for Improved Data Quality and Diversity in Dialog Systems},
  author    = {Larson, Stefan and Mahendran, Anish and Lee, Andrew and Kummerfeld, Jonathan K. and Hill, Parker and Laurenzano, Michael and Hauswald, Johann and Tang, Lingjia and Mars, Jason},
  year      = {2019},
  booktitle = {Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)},
  pages     = {517--527},
  data      = {https://github.com/clinc/uniqueness},
  month     = {June},
  arxiv     = {https://arxiv.org/abs/1904.03122},
  url       = {https://www.aclweb.org/anthology/N19-1051.pdf},
  doi       = {10.18653/v1/N19-1051},
  location  = {Minneapolis, Minnesota},
}
        </pre>
        
        </p>
    </div>
  </div>
</div>


<div class="container pb-2">
  <div class="row">
    <div class="col-lg-6">
      <strong>Look Who&rsquo;s Talking: Inferring Speaker Attributes from Personal Longitudinal Dialog</strong>
      <br />
      <span class="text-muted">Charles Welch, Verónica Pérez-Rosas, Jonathan K. Kummerfeld, Rada Mihalcea</span>
      <br />
      Best Student Paper - CICLing<span class="text-muted">, 2019</span>
    </div>
    <div class="col-lg-6">
      <a class="btn btn-outline-primary btn-sm" href="https://www.jkk.name/pub/cicling19personal.pdf" target="_blank" rel="noopener"><span
    class="fontawesome-inline-svg"
    style="display: inline-flex; align-self: center; height:1em; width:1em; top: .125em; position: relative;"
><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path fill='currentColor' d="M256 0v128h128L256 0zM224 128L224 0H48C21.49 0 0 21.49 0 48v416C0 490.5 21.49 512 48 512h288c26.51 0 48-21.49 48-48V160h-127.1C238.3 160 224 145.7 224 128zM272 416h-160C103.2 416 96 408.8 96 400C96 391.2 103.2 384 112 384h160c8.836 0 16 7.162 16 16C288 408.8 280.8 416 272 416zM272 352h-160C103.2 352 96 344.8 96 336C96 327.2 103.2 320 112 320h160c8.836 0 16 7.162 16 16C288 344.8 280.8 352 272 352zM288 272C288 280.8 280.8 288 272 288h-160C103.2 288 96 280.8 96 272C96 263.2 103.2 256 112 256h160C280.8 256 288 263.2 288 272z"/></svg>
</span>
 PDF</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('cicling19personal-abstract').style.display == 'block') {
  document.getElementById('cicling19personal-abstract').style.display='none';
  } else {
  document.getElementById('cicling19personal-abstract').style.display='block';
  }
  ">Abstract</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('cicling19personal-cite').style.display == 'block') {
  document.getElementById('cicling19personal-cite').style.display='none';
  } else {
  document.getElementById('cicling19personal-cite').style.display='block';
  }
  ">BibTeX</a>
      
      
      
      
      
      
      
    </div>
  </div>
  <div class="row" id="cicling19personal-abstract" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          We examine a large dialog corpus obtained from the conversation history of a single individual with 104 conversation partners. The corpus consists of half a million instant messages, across several messaging platforms. We focus our analyses on seven speaker attributes, each of which partitions the set of speakers, namely: gender; relative age; family member; romantic partner; classmate; co-worker; and native to the same country. In addition to the content of the messages, we examine conversational aspects such as the time messages are sent, messaging frequency, psycholinguistic word categories, linguistic mirroring, and graph-based features reflecting how people in the corpus mention each other. We present two sets of experiments predicting each attribute using (1) short context windows; and (2) a larger set of messages. We find that using all features leads to gains of 9-14% over using message text only.
        </p>
    </div>
  </div>
  <div class="row" id="cicling19personal-cite" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          
        <pre>
        @InProceedings{cicling19personal,
  title     = {Look Who's Talking: Inferring Speaker Attributes from Personal Longitudinal Dialog},
  year      = {2019},
  author    = {Welch, Charles and P{\\'e}rez-Rosas, Ver{\\'o}nica and Kummerfeld, Jonathan K. and Mihalcea, Rada},
  address   = {La Rochelle, France},
  booktitle = {Proceedings of the 20th International Conference on Computational Linguistics and Intelligent Text Processing (CICLing)},
  publisher = {Springer},
  month     = {April},
  awards    = {Best Student Paper Award},
  url       = {https://www.jkk.name/pub/cicling19personal.pdf},
  arxiv     = {https://arxiv.org/abs/1904.11610},
}
        </pre>
        
        </p>
    </div>
  </div>
</div>


<div class="container pb-2">
  <div class="row">
    <div class="col-lg-6">
      <strong>Learning from Personal Longitudinal Dialog Data</strong>
      <br />
      <span class="text-muted">Charles Welch, Verónica Pérez-Rosas, Jonathan K. Kummerfeld, Rada Mihalcea</span>
      <br />
      IEEE Intelligent Systems<span class="text-muted">, 2019</span>
    </div>
    <div class="col-lg-6">
      <a class="btn btn-outline-primary btn-sm" href="https://www.jkk.name/pub/ieee19personal.pdf" target="_blank" rel="noopener"><span
    class="fontawesome-inline-svg"
    style="display: inline-flex; align-self: center; height:1em; width:1em; top: .125em; position: relative;"
><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path fill='currentColor' d="M256 0v128h128L256 0zM224 128L224 0H48C21.49 0 0 21.49 0 48v416C0 490.5 21.49 512 48 512h288c26.51 0 48-21.49 48-48V160h-127.1C238.3 160 224 145.7 224 128zM272 416h-160C103.2 416 96 408.8 96 400C96 391.2 103.2 384 112 384h160c8.836 0 16 7.162 16 16C288 408.8 280.8 416 272 416zM272 352h-160C103.2 352 96 344.8 96 336C96 327.2 103.2 320 112 320h160c8.836 0 16 7.162 16 16C288 344.8 280.8 352 272 352zM288 272C288 280.8 280.8 288 272 288h-160C103.2 288 96 280.8 96 272C96 263.2 103.2 256 112 256h160C280.8 256 288 263.2 288 272z"/></svg>
</span>
 PDF</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('ieee19personal-abstract').style.display == 'block') {
  document.getElementById('ieee19personal-abstract').style.display='none';
  } else {
  document.getElementById('ieee19personal-abstract').style.display='block';
  }
  ">Abstract</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('ieee19personal-cite').style.display == 'block') {
  document.getElementById('ieee19personal-cite').style.display='none';
  } else {
  document.getElementById('ieee19personal-cite').style.display='block';
  }
  ">BibTeX</a>
      
      
      
      
      
      
      
    </div>
  </div>
  <div class="row" id="ieee19personal-abstract" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          We explore the use of longitudinal dialog data for two dialog prediction tasks: next message prediction and response time prediction. We show that a neural model using personal data that leverages a combination of message content, style matching, time features, and speaker attributes leads to the best results for both tasks, with error rate reductions of up to 15% compared to a classifier that relies exclusively on message content and to a classifier that does not use personal data.
        </p>
    </div>
  </div>
  <div class="row" id="ieee19personal-cite" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          
        <pre>
        @Article{ieee19personal,
  author    = {Welch, Charles and P{\\'e}rez-Rosas, Ver{\\'o}nica and Kummerfeld, Jonathan K. and Mihalcea, Rada},
  editor    = {Erik Cambria},
  title     = {Learning from Personal Longitudinal Dialog Data},
  year      = {2019},
  journal   = {IEEE Intelligent Systems},
  volume    = {34},
  number    = {4},
  pages     = {16--23},
  url       = {https://www.jkk.name/pub/ieee19personal.pdf},
}
        </pre>
        
        </p>
    </div>
  </div>
</div>


<h3 id="2018">2018</h3>
<div class="container pb-2">
  <div class="row">
    <div class="col-lg-6">
      <strong>Improving Text-to-SQL Evaluation Methodology</strong>
      <br />
      <span class="text-muted">Catherine Finegan-Dollak*, Jonathan K. Kummerfeld*, Li Zhang, Karthik Ramanathan, Sesh Sadasivam, Rui Zhang, Dragomir Radev</span>
      <br />
      ACL<span class="text-muted">, 2018</span>
    </div>
    <div class="col-lg-6">
      <a class="btn btn-outline-primary btn-sm" href="https://aclanthology.org/P18-1033.pdf" target="_blank" rel="noopener"><span
    class="fontawesome-inline-svg"
    style="display: inline-flex; align-self: center; height:1em; width:1em; top: .125em; position: relative;"
><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path fill='currentColor' d="M256 0v128h128L256 0zM224 128L224 0H48C21.49 0 0 21.49 0 48v416C0 490.5 21.49 512 48 512h288c26.51 0 48-21.49 48-48V160h-127.1C238.3 160 224 145.7 224 128zM272 416h-160C103.2 416 96 408.8 96 400C96 391.2 103.2 384 112 384h160c8.836 0 16 7.162 16 16C288 408.8 280.8 416 272 416zM272 352h-160C103.2 352 96 344.8 96 336C96 327.2 103.2 320 112 320h160c8.836 0 16 7.162 16 16C288 344.8 280.8 352 272 352zM288 272C288 280.8 280.8 288 272 288h-160C103.2 288 96 280.8 96 272C96 263.2 103.2 256 112 256h160C280.8 256 288 263.2 288 272z"/></svg>
</span>
 PDF</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('acl18sql-abstract').style.display == 'block') {
  document.getElementById('acl18sql-abstract').style.display='none';
  } else {
  document.getElementById('acl18sql-abstract').style.display='block';
  }
  ">Abstract</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('acl18sql-cite').style.display == 'block') {
  document.getElementById('acl18sql-cite').style.display='none';
  } else {
  document.getElementById('acl18sql-cite').style.display='block';
  }
  ">BibTeX</a>
      
      
      
      <a class="btn btn-outline-primary btn-sm" href="https://www.jkk.name/text2sql-data" target="_blank" rel="noopener"><span
    class="fontawesome-inline-svg"
    style="display: inline-flex; align-self: center; height:1em; width:1em; top: .125em; position: relative;"
><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill='currentColor' d="M448 80V128C448 172.2 347.7 208 224 208C100.3 208 0 172.2 0 128V80C0 35.82 100.3 0 224 0C347.7 0 448 35.82 448 80zM393.2 214.7C413.1 207.3 433.1 197.8 448 186.1V288C448 332.2 347.7 368 224 368C100.3 368 0 332.2 0 288V186.1C14.93 197.8 34.02 207.3 54.85 214.7C99.66 230.7 159.5 240 224 240C288.5 240 348.3 230.7 393.2 214.7V214.7zM54.85 374.7C99.66 390.7 159.5 400 224 400C288.5 400 348.3 390.7 393.2 374.7C413.1 367.3 433.1 357.8 448 346.1V432C448 476.2 347.7 512 224 512C100.3 512 0 476.2 0 432V346.1C14.93 357.8 34.02 367.3 54.85 374.7z"/></svg>
</span>
 Data</a>
      
      
      <a class="btn btn-outline-primary btn-sm" href="https://www.jkk.name/text2sql-data" target="_blank" rel="noopener"><span
    class="fontawesome-inline-svg"
    style="display: inline-flex; align-self: center; height:1em; width:1em; top: .125em; position: relative;"
><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512"><path fill='currentColor' d="M414.8 40.79L286.8 488.8C281.9 505.8 264.2 515.6 247.2 510.8C230.2 505.9 220.4 488.2 225.2 471.2L353.2 23.21C358.1 6.216 375.8-3.624 392.8 1.232C409.8 6.087 419.6 23.8 414.8 40.79H414.8zM518.6 121.4L630.6 233.4C643.1 245.9 643.1 266.1 630.6 278.6L518.6 390.6C506.1 403.1 485.9 403.1 473.4 390.6C460.9 378.1 460.9 357.9 473.4 345.4L562.7 256L473.4 166.6C460.9 154.1 460.9 133.9 473.4 121.4C485.9 108.9 506.1 108.9 518.6 121.4V121.4zM166.6 166.6L77.25 256L166.6 345.4C179.1 357.9 179.1 378.1 166.6 390.6C154.1 403.1 133.9 403.1 121.4 390.6L9.372 278.6C-3.124 266.1-3.124 245.9 9.372 233.4L121.4 121.4C133.9 108.9 154.1 108.9 166.6 121.4C179.1 133.9 179.1 154.1 166.6 166.6V166.6z"/></svg>
</span>
 Software</a>
      
      
      <a class="btn btn-outline-primary btn-sm" href="https://www.aclweb.org/anthology/attachments/P18-1033.Poster.pdf" target="_blank" rel="noopener">Poster</a>
      
      
      
    </div>
  </div>
  <div class="row" id="acl18sql-abstract" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          To be informative, an evaluation must measure how well systems generalize to realistic unseen data. We identify limitations of and propose improvements to current evaluations of text-to-SQL systems. First, we compare human-generated and automatically generated questions, characterizing properties of queries necessary for real-world applications. To facilitate evaluation on multiple datasets, we release standardized and improved versions of seven existing datasets and one new text-to-SQL dataset. Second, we show that the current division of data into training and test sets measures robustness to variations in the way questions are asked, but only partially tests how well systems generalize to new queries; therefore, we propose a complementary dataset split for evaluation of future work. Finally, we demonstrate how the common practice of anonymizing variables during evaluation removes an important challenge of the task. Our observations highlight key difficulties, and our methodology enables effective measurement of future development.
        </p>
    </div>
  </div>
  <div class="row" id="acl18sql-cite" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          
        <pre>
        @InProceedings{acl18sql,
  author    = {Finegan-Dollak\\*, Catherine and Kummerfeld\\*, Jonathan K. and Zhang, Li and Ramanathan, Karthik and Sadasivam, Sesh and Zhang, Rui and Radev, Dragomir},
  title     = {Improving Text-to-SQL Evaluation Methodology},
  booktitle = {Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  month     = {July},
  year      = {2018},
  address   = {Melbourne, Victoria, Australia},
  pages     = {351--360},
  doi       = {10.18653/v1/P18-1033},
  url       = {https://aclanthology.org/P18-1033.pdf},
  arxiv     = {https://arxiv.org/abs/1806.09029},
  software  = {https://www.jkk.name/text2sql-data},
  data      = {https://www.jkk.name/text2sql-data},
  poster    = {https://www.aclweb.org/anthology/attachments/P18-1033.Poster.pdf},
}
        </pre>
        
        </p>
    </div>
  </div>
</div>


<div class="container pb-2">
  <div class="row">
    <div class="col-lg-6">
      <strong>Factors Influencing the Surprising Instability of Word Embeddings</strong>
      <br />
      <span class="text-muted">Laura Burdick, Jonathan K. Kummerfeld, Rada Mihalcea</span>
      <br />
      NAACL<span class="text-muted">, 2018</span>
    </div>
    <div class="col-lg-6">
      <a class="btn btn-outline-primary btn-sm" href="https://aclanthology.org/N18-1190.pdf" target="_blank" rel="noopener"><span
    class="fontawesome-inline-svg"
    style="display: inline-flex; align-self: center; height:1em; width:1em; top: .125em; position: relative;"
><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path fill='currentColor' d="M256 0v128h128L256 0zM224 128L224 0H48C21.49 0 0 21.49 0 48v416C0 490.5 21.49 512 48 512h288c26.51 0 48-21.49 48-48V160h-127.1C238.3 160 224 145.7 224 128zM272 416h-160C103.2 416 96 408.8 96 400C96 391.2 103.2 384 112 384h160c8.836 0 16 7.162 16 16C288 408.8 280.8 416 272 416zM272 352h-160C103.2 352 96 344.8 96 336C96 327.2 103.2 320 112 320h160c8.836 0 16 7.162 16 16C288 344.8 280.8 352 272 352zM288 272C288 280.8 280.8 288 272 288h-160C103.2 288 96 280.8 96 272C96 263.2 103.2 256 112 256h160C280.8 256 288 263.2 288 272z"/></svg>
</span>
 PDF</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('naacl18embeddings-abstract').style.display == 'block') {
  document.getElementById('naacl18embeddings-abstract').style.display='none';
  } else {
  document.getElementById('naacl18embeddings-abstract').style.display='block';
  }
  ">Abstract</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('naacl18embeddings-cite').style.display == 'block') {
  document.getElementById('naacl18embeddings-cite').style.display='none';
  } else {
  document.getElementById('naacl18embeddings-cite').style.display='block';
  }
  ">BibTeX</a>
      
      
      
      
      
      
      
    </div>
  </div>
  <div class="row" id="naacl18embeddings-abstract" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          Despite the recent popularity of word embedding methods, there is only a small body of work exploring the limitations of these representations. In this paper, we consider one aspect of embedding spaces, namely their stability. We show that even relatively high frequency words (100-200 occurrences) are often unstable. We provide empirical evidence for how various factors contribute to the stability of word embeddings, and we analyze the effects of stability on downstream tasks.
        </p>
    </div>
  </div>
  <div class="row" id="naacl18embeddings-cite" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          
        <pre>
        @InProceedings{naacl18embeddings,
  author    = {Burdick, Laura and Kummerfeld, Jonathan K. and Mihalcea, Rada},
  title     = {Factors Influencing the Surprising Instability of Word Embeddings},
  booktitle = {Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)},
  year      = {2018},
  month     = {June},
  location  = {New Orleans, Louisiana, USA},
  url       = {https://aclanthology.org/N18-1190.pdf},
  pages     = {2092--2102},
  arxiv     = {https://arxiv.org/abs/1804.09692},
  doi       = {10.18653/v1/N18-1190},
}
        </pre>
        
        </p>
    </div>
  </div>
</div>


<div class="container pb-2">
  <div class="row">
    <div class="col-lg-6">
      <strong>Effective Crowdsourcing for a New Type of Summarization Task</strong>
      <br />
      <span class="text-muted">Youxuan Jiang, Catherine Finegan-Dollak, Jonathan K. Kummerfeld, Walter Lasecki</span>
      <br />
      NAACL (short)<span class="text-muted">, 2018</span>
    </div>
    <div class="col-lg-6">
      <a class="btn btn-outline-primary btn-sm" href="https://aclanthology.org/N18-2099.pdf" target="_blank" rel="noopener"><span
    class="fontawesome-inline-svg"
    style="display: inline-flex; align-self: center; height:1em; width:1em; top: .125em; position: relative;"
><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path fill='currentColor' d="M256 0v128h128L256 0zM224 128L224 0H48C21.49 0 0 21.49 0 48v416C0 490.5 21.49 512 48 512h288c26.51 0 48-21.49 48-48V160h-127.1C238.3 160 224 145.7 224 128zM272 416h-160C103.2 416 96 408.8 96 400C96 391.2 103.2 384 112 384h160c8.836 0 16 7.162 16 16C288 408.8 280.8 416 272 416zM272 352h-160C103.2 352 96 344.8 96 336C96 327.2 103.2 320 112 320h160c8.836 0 16 7.162 16 16C288 344.8 280.8 352 272 352zM288 272C288 280.8 280.8 288 272 288h-160C103.2 288 96 280.8 96 272C96 263.2 103.2 256 112 256h160C280.8 256 288 263.2 288 272z"/></svg>
</span>
 PDF</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('naacl18summary-abstract').style.display == 'block') {
  document.getElementById('naacl18summary-abstract').style.display='none';
  } else {
  document.getElementById('naacl18summary-abstract').style.display='block';
  }
  ">Abstract</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('naacl18summary-cite').style.display == 'block') {
  document.getElementById('naacl18summary-cite').style.display='none';
  } else {
  document.getElementById('naacl18summary-cite').style.display='block';
  }
  ">BibTeX</a>
      
      
      
      
      
      
      
    </div>
  </div>
  <div class="row" id="naacl18summary-abstract" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          Most summarization research focuses on summarizing the entire given text, but in practice readers are often interested in only one aspect of the document or conversation. We propose &#39;targeted summarization&#39; as an umbrella category for summarization tasks that intentionally consider only parts of the input data. This covers query-based summarization, update summarization, and a new task we propose where the goal is to summarize a particular aspect of a document. However, collecting data for this new task is hard because directly asking annotators (e.g., crowd workers) to write summaries leads to data with low accuracy when there are a large number of facts to include.  We introduce a novel crowdsourcing workflow, Pin-Refine, that allows us to collect highquality summaries for our task, a necessary step for the development of automatic systems.
        </p>
    </div>
  </div>
  <div class="row" id="naacl18summary-cite" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          
        <pre>
        @InProceedings{naacl18summary,
  author    = {Jiang, Youxuan and Finegan-Dollak, Catherine and Kummerfeld, Jonathan K. and Lasecki, Walter},
  title     = {Effective Crowdsourcing for a New Type of Summarization Task},
  booktitle = {Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers)},
  pages     = {628--633},
  year      = {2018},
  month     = {June},
  location  = {New Orleans, Louisiana, USA},
  url       = {https://aclanthology.org/N18-2099.pdf},
  doi       = {10.18653/v1/N18-2099},
}
        </pre>
        
        </p>
    </div>
  </div>
</div>


<div class="container pb-2">
  <div class="row">
    <div class="col-lg-6">
      <strong>Data Collection for a Production Dialogue System: A Startup Perspective</strong>
      <br />
      <span class="text-muted">Yiping Kang, Yunqi Zhang, Jonathan K. Kummerfeld, Parker Hill, Johann Hauswald, Michael A. Laurenzano, Lingjia Tang, Jason Mars</span>
      <br />
      NAACL (industry)<span class="text-muted">, 2018</span>
    </div>
    <div class="col-lg-6">
      <a class="btn btn-outline-primary btn-sm" href="https://aclanthology.org/N18-3005.pdf" target="_blank" rel="noopener"><span
    class="fontawesome-inline-svg"
    style="display: inline-flex; align-self: center; height:1em; width:1em; top: .125em; position: relative;"
><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path fill='currentColor' d="M256 0v128h128L256 0zM224 128L224 0H48C21.49 0 0 21.49 0 48v416C0 490.5 21.49 512 48 512h288c26.51 0 48-21.49 48-48V160h-127.1C238.3 160 224 145.7 224 128zM272 416h-160C103.2 416 96 408.8 96 400C96 391.2 103.2 384 112 384h160c8.836 0 16 7.162 16 16C288 408.8 280.8 416 272 416zM272 352h-160C103.2 352 96 344.8 96 336C96 327.2 103.2 320 112 320h160c8.836 0 16 7.162 16 16C288 344.8 280.8 352 272 352zM288 272C288 280.8 280.8 288 272 288h-160C103.2 288 96 280.8 96 272C96 263.2 103.2 256 112 256h160C280.8 256 288 263.2 288 272z"/></svg>
</span>
 PDF</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('naacl18data-abstract').style.display == 'block') {
  document.getElementById('naacl18data-abstract').style.display='none';
  } else {
  document.getElementById('naacl18data-abstract').style.display='block';
  }
  ">Abstract</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('naacl18data-cite').style.display == 'block') {
  document.getElementById('naacl18data-cite').style.display='none';
  } else {
  document.getElementById('naacl18data-cite').style.display='block';
  }
  ">BibTeX</a>
      
      
      
      
      
      
      
      <a class="btn btn-outline-primary btn-sm" href="https://vimeo.com/277631102" target="_blank" rel="noopener"><span
    class="fontawesome-inline-svg"
    style="display: inline-flex; align-self: center; height:1em; width:1em; top: .125em; position: relative;"
><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><path fill='currentColor' d="M384 112v288c0 26.51-21.49 48-48 48h-288c-26.51 0-48-21.49-48-48v-288c0-26.51 21.49-48 48-48h288C362.5 64 384 85.49 384 112zM576 127.5v256.9c0 25.5-29.17 40.39-50.39 25.79L416 334.7V177.3l109.6-75.56C546.9 87.13 576 102.1 576 127.5z"/></svg>
</span>
 Video</a>
      
    </div>
  </div>
  <div class="row" id="naacl18data-abstract" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          Industrial dialogue systems such as Apple Siri and Google Assistant require large scale diverse training data to enable their sophisticated conversation capabilities. Crowdsourcing is a scalable and inexpensive data collection method, but collecting high quality data efficiently requires thoughtful orchestration of crowdsourcing jobs. Prior study of data collection process has focused on tasks with limited scope and performed intrinsic data analysis, which may not be indicative of impact on trained model performance. In this paper, we present a study of crowdsourcing methods for a user intent classification task in one of our deployed dialogue systems. Our task requires classification over 47 possible user intents and contains many intent pairs with subtle differences. We consider different crowdsourcing job types and job prompts, quantitatively analyzing the quality of collected data and downstream model performance on a test set of real user queries from production logs. Our observations provide insight into how design decisions impact crowdsourced data quality, with clear recommendations for future data collection for dialogue systems.
        </p>
    </div>
  </div>
  <div class="row" id="naacl18data-cite" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          
        <pre>
        @InProceedings{naacl18data,
  author    = {Kang, Yiping and Zhang, Yunqi and Kummerfeld, Jonathan K. and Hill, Parker and Hauswald, Johann and Laurenzano, Michael A. and Tang, Lingjia and Mars, Jason},
  doi       = {10.18653/v1/N18-3005},
  title     = {Data Collection for a Production Dialogue System: A Startup Perspective},
  booktitle = {Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 3 (Industry Papers)},
  pages     = {33--40},
  year      = {2018},
  month     = {June},
  location  = {New Orleans, Louisiana, USA},
  url       = {https://aclanthology.org/N18-3005.pdf},
  video     = {https://vimeo.com/277631102},
}
        </pre>
        
        </p>
    </div>
  </div>
</div>


<div class="container pb-2">
  <div class="row">
    <div class="col-lg-6">
      <strong>World Knowledge for Abstract Meaning Representation Parsing</strong>
      <br />
      <span class="text-muted">Charles Welch, Jonathan K. Kummerfeld, Song Feng, Rada Mihalcea</span>
      <br />
      LREC<span class="text-muted">, 2018</span>
    </div>
    <div class="col-lg-6">
      <a class="btn btn-outline-primary btn-sm" href="http://www.lrec-conf.org/proceedings/lrec2018/pdf/1085.pdf" target="_blank" rel="noopener"><span
    class="fontawesome-inline-svg"
    style="display: inline-flex; align-self: center; height:1em; width:1em; top: .125em; position: relative;"
><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path fill='currentColor' d="M256 0v128h128L256 0zM224 128L224 0H48C21.49 0 0 21.49 0 48v416C0 490.5 21.49 512 48 512h288c26.51 0 48-21.49 48-48V160h-127.1C238.3 160 224 145.7 224 128zM272 416h-160C103.2 416 96 408.8 96 400C96 391.2 103.2 384 112 384h160c8.836 0 16 7.162 16 16C288 408.8 280.8 416 272 416zM272 352h-160C103.2 352 96 344.8 96 336C96 327.2 103.2 320 112 320h160c8.836 0 16 7.162 16 16C288 344.8 280.8 352 272 352zM288 272C288 280.8 280.8 288 272 288h-160C103.2 288 96 280.8 96 272C96 263.2 103.2 256 112 256h160C280.8 256 288 263.2 288 272z"/></svg>
</span>
 PDF</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('lrec18amr-abstract').style.display == 'block') {
  document.getElementById('lrec18amr-abstract').style.display='none';
  } else {
  document.getElementById('lrec18amr-abstract').style.display='block';
  }
  ">Abstract</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('lrec18amr-cite').style.display == 'block') {
  document.getElementById('lrec18amr-cite').style.display='none';
  } else {
  document.getElementById('lrec18amr-cite').style.display='block';
  }
  ">BibTeX</a>
      
      
      
      
      
      
      
    </div>
  </div>
  <div class="row" id="lrec18amr-abstract" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          In this paper we explore the role played by world knowledge in semantic parsing. We look at the types of errors that currently exist in a state-of-the-art Abstract Meaning Representation (AMR) parser, and explore the problem of how to integrate world knowledge to reduce these errors. We look at three types of knowledge from (1) WordNet hypernyms and super senses, (2) Wikipedia entity links, and (3) retraining a named entity recognizer to identify concepts in AMR. The retrained entity recognizer is not perfect and cannot recognize all concepts in AMR and we examine the limitations of the named entity features using a set of oracles. The oracles show how performance increases if it can recognize different subsets of AMR concepts. These results show improvement on multiple fine-grained metrics, including a 6% increase in named entity F-score, and provide insight into the potential of world knowledge for future work in Abstract Meaning Representation parsing.
        </p>
    </div>
  </div>
  <div class="row" id="lrec18amr-cite" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          
        <pre>
        @InProceedings{lrec18amr,
  author    = {Welch, Charles and Kummerfeld, Jonathan K. and Feng, Song and Mihalcea, Rada},
  title     = {World Knowledge for Abstract Meaning Representation Parsing},
  booktitle = {Proceedings of the Eleventh International Conference on Language Resources and Evaluation (LREC 2018)},
  year      = {2018},
  month     = {May},
  location  = {Miyazaki, Japan},
  url       = {http://www.lrec-conf.org/proceedings/lrec2018/pdf/1085.pdf},
}
        </pre>
        
        </p>
    </div>
  </div>
</div>


<h3 id="2017">2017</h3>
<div class="container pb-2">
  <div class="row">
    <div class="col-lg-6">
      <strong>Parsing with Traces: An O(\(n^4\)) Algorithm and a Structural Representation</strong>
      <br />
      <span class="text-muted">Jonathan K. Kummerfeld, Dan Klein</span>
      <br />
      TACL<span class="text-muted">, 2017</span>
    </div>
    <div class="col-lg-6">
      <a class="btn btn-outline-primary btn-sm" href="https://aclanthology.org/Q17-1031.pdf" target="_blank" rel="noopener"><span
    class="fontawesome-inline-svg"
    style="display: inline-flex; align-self: center; height:1em; width:1em; top: .125em; position: relative;"
><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path fill='currentColor' d="M256 0v128h128L256 0zM224 128L224 0H48C21.49 0 0 21.49 0 48v416C0 490.5 21.49 512 48 512h288c26.51 0 48-21.49 48-48V160h-127.1C238.3 160 224 145.7 224 128zM272 416h-160C103.2 416 96 408.8 96 400C96 391.2 103.2 384 112 384h160c8.836 0 16 7.162 16 16C288 408.8 280.8 416 272 416zM272 352h-160C103.2 352 96 344.8 96 336C96 327.2 103.2 320 112 320h160c8.836 0 16 7.162 16 16C288 344.8 280.8 352 272 352zM288 272C288 280.8 280.8 288 272 288h-160C103.2 288 96 280.8 96 272C96 263.2 103.2 256 112 256h160C280.8 256 288 263.2 288 272z"/></svg>
</span>
 PDF</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('tacl17parsing-abstract').style.display == 'block') {
  document.getElementById('tacl17parsing-abstract').style.display='none';
  } else {
  document.getElementById('tacl17parsing-abstract').style.display='block';
  }
  ">Abstract</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('tacl17parsing-cite').style.display == 'block') {
  document.getElementById('tacl17parsing-cite').style.display='none';
  } else {
  document.getElementById('tacl17parsing-cite').style.display='block';
  }
  ">BibTeX</a>
      
      
      
      
      <a class="btn btn-outline-primary btn-sm" href="https://www.jkk.name/1ec-graph-parser/" target="_blank" rel="noopener"><span
    class="fontawesome-inline-svg"
    style="display: inline-flex; align-self: center; height:1em; width:1em; top: .125em; position: relative;"
><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512"><path fill='currentColor' d="M414.8 40.79L286.8 488.8C281.9 505.8 264.2 515.6 247.2 510.8C230.2 505.9 220.4 488.2 225.2 471.2L353.2 23.21C358.1 6.216 375.8-3.624 392.8 1.232C409.8 6.087 419.6 23.8 414.8 40.79H414.8zM518.6 121.4L630.6 233.4C643.1 245.9 643.1 266.1 630.6 278.6L518.6 390.6C506.1 403.1 485.9 403.1 473.4 390.6C460.9 378.1 460.9 357.9 473.4 345.4L562.7 256L473.4 166.6C460.9 154.1 460.9 133.9 473.4 121.4C485.9 108.9 506.1 108.9 518.6 121.4V121.4zM166.6 166.6L77.25 256L166.6 345.4C179.1 357.9 179.1 378.1 166.6 390.6C154.1 403.1 133.9 403.1 121.4 390.6L9.372 278.6C-3.124 266.1-3.124 245.9 9.372 233.4L121.4 121.4C133.9 108.9 154.1 108.9 166.6 121.4C179.1 133.9 179.1 154.1 166.6 166.6V166.6z"/></svg>
</span>
 Software</a>
      
      
      
      
      <a class="btn btn-outline-primary btn-sm" href="https://vimeo.com/238235203" target="_blank" rel="noopener"><span
    class="fontawesome-inline-svg"
    style="display: inline-flex; align-self: center; height:1em; width:1em; top: .125em; position: relative;"
><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><path fill='currentColor' d="M384 112v288c0 26.51-21.49 48-48 48h-288c-26.51 0-48-21.49-48-48v-288c0-26.51 21.49-48 48-48h288C362.5 64 384 85.49 384 112zM576 127.5v256.9c0 25.5-29.17 40.39-50.39 25.79L416 334.7V177.3l109.6-75.56C546.9 87.13 576 102.1 576 127.5z"/></svg>
</span>
 Video</a>
      
    </div>
  </div>
  <div class="row" id="tacl17parsing-abstract" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          General treebank analyses are graph structured, but parsers are typically restricted to tree structures for efficiency and modeling reasons.  We propose a new representation and algorithm for a class of graph structures that is flexible enough to cover almost all treebank structures, while still admitting efficient learning and inference. In particular, we consider directed, acyclic, one-endpoint-crossing graph structures, which cover most long-distance dislocation, shared argumentation, and similar tree-violating linguistic phenomena. We describe how to convert phrase structure parses, including traces, to our new representation in a reversible manner. Our dynamic program uniquely decomposes structures, is sound and complete, and covers 97.3% of the Penn English Treebank. We also implement a proofof-concept parser that recovers a range of null elements and trace types.
        </p>
    </div>
  </div>
  <div class="row" id="tacl17parsing-cite" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          
        <pre>
        @InProceedings{tacl17parsing,
  author    = {Kummerfeld, Jonathan K. and Klein, Dan},
  title     = {Parsing with Traces: An O($n^4$) Algorithm and a Structural Representation},
  booktitle = {Transactions of the Association for Computational Linguistics},
  doi       = {10.1162/tacl_a_00072},
  volume    = {5},
  issn      = {2307-387X},
  pages     = {441--454},
  year      = {2017},
  url       = {https://aclanthology.org/Q17-1031.pdf},
  arxiv     = {https://arxiv.org/abs/1707.04221},
  software  = {https://www.jkk.name/1ec-graph-parser/},
  interview = {https://soundcloud.com/nlp-highlights/46-parsing-with-traces-with-jonathan-kummerfeld},
  video     = {https://vimeo.com/238235203},
}
        </pre>
        
        </p>
    </div>
  </div>
</div>


<div class="container pb-2">
  <div class="row">
    <div class="col-lg-6">
      <strong>Identifying Products in Online Cybercrime Marketplaces: A Dataset for Fine-grained Domain Adaptation</strong>
      <br />
      <span class="text-muted">Greg Durrett, Jonathan K. Kummerfeld, Taylor Berg-Kirkpatrick, Rebecca S. Portnoff, Sadia Afroz, Damon McCoy, Kirill Levchenko, Vern Paxson</span>
      <br />
      EMNLP<span class="text-muted">, 2017</span>
    </div>
    <div class="col-lg-6">
      <a class="btn btn-outline-primary btn-sm" href="https://www.aclweb.org/anthology/D17-1275.pdf" target="_blank" rel="noopener"><span
    class="fontawesome-inline-svg"
    style="display: inline-flex; align-self: center; height:1em; width:1em; top: .125em; position: relative;"
><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path fill='currentColor' d="M256 0v128h128L256 0zM224 128L224 0H48C21.49 0 0 21.49 0 48v416C0 490.5 21.49 512 48 512h288c26.51 0 48-21.49 48-48V160h-127.1C238.3 160 224 145.7 224 128zM272 416h-160C103.2 416 96 408.8 96 400C96 391.2 103.2 384 112 384h160c8.836 0 16 7.162 16 16C288 408.8 280.8 416 272 416zM272 352h-160C103.2 352 96 344.8 96 336C96 327.2 103.2 320 112 320h160c8.836 0 16 7.162 16 16C288 344.8 280.8 352 272 352zM288 272C288 280.8 280.8 288 272 288h-160C103.2 288 96 280.8 96 272C96 263.2 103.2 256 112 256h160C280.8 256 288 263.2 288 272z"/></svg>
</span>
 PDF</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('emnlp17forums-abstract').style.display == 'block') {
  document.getElementById('emnlp17forums-abstract').style.display='none';
  } else {
  document.getElementById('emnlp17forums-abstract').style.display='block';
  }
  ">Abstract</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('emnlp17forums-cite').style.display == 'block') {
  document.getElementById('emnlp17forums-cite').style.display='none';
  } else {
  document.getElementById('emnlp17forums-cite').style.display='block';
  }
  ">BibTeX</a>
      
      <a class="btn btn-outline-primary btn-sm" href="https://www.aclweb.org/anthology/attachments/D17-1275.Attachment.zip" target="_blank" rel="noopener">Supplementary Material</a>
      
      
      
      
      <a class="btn btn-outline-primary btn-sm" href="https://evidencebasedsecurity.org/forums/" target="_blank" rel="noopener"><span
    class="fontawesome-inline-svg"
    style="display: inline-flex; align-self: center; height:1em; width:1em; top: .125em; position: relative;"
><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512"><path fill='currentColor' d="M414.8 40.79L286.8 488.8C281.9 505.8 264.2 515.6 247.2 510.8C230.2 505.9 220.4 488.2 225.2 471.2L353.2 23.21C358.1 6.216 375.8-3.624 392.8 1.232C409.8 6.087 419.6 23.8 414.8 40.79H414.8zM518.6 121.4L630.6 233.4C643.1 245.9 643.1 266.1 630.6 278.6L518.6 390.6C506.1 403.1 485.9 403.1 473.4 390.6C460.9 378.1 460.9 357.9 473.4 345.4L562.7 256L473.4 166.6C460.9 154.1 460.9 133.9 473.4 121.4C485.9 108.9 506.1 108.9 518.6 121.4V121.4zM166.6 166.6L77.25 256L166.6 345.4C179.1 357.9 179.1 378.1 166.6 390.6C154.1 403.1 133.9 403.1 121.4 390.6L9.372 278.6C-3.124 266.1-3.124 245.9 9.372 233.4L121.4 121.4C133.9 108.9 154.1 108.9 166.6 121.4C179.1 133.9 179.1 154.1 166.6 166.6V166.6z"/></svg>
</span>
 Software</a>
      
      
      
      
    </div>
  </div>
  <div class="row" id="emnlp17forums-abstract" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          One weakness of machine-learned NLP models is that they typically perform poorly on out-of-domain data. In this work, we study the task of identifying products being bought and sold in online cybercrime forums, which exhibits particularly challenging cross-domain effects.  We formulate a task that represents a hybrid of slot-filling information extraction and named entity recognition and annotate data from four different forums.  Each of these forums constitutes its own &#39;fine-grained domain&#39; in that the forums cover different market sectors with different properties, even though all forums are in the broad domain of cybercrime. We characterize these domain differences in the context of a learning-based system: supervised models see decreased accuracy when applied to new forums, and standard techniques for semi-supervised learning and domain adaptation have limited effectiveness on this data, which suggests the need to improve these techniques. We release a dataset of 1,938 annotated posts from across the four forums.
        </p>
    </div>
  </div>
  <div class="row" id="emnlp17forums-cite" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          
        <pre>
        @InProceedings{emnlp17forums,
  author    = {Durrett, Greg and Kummerfeld, Jonathan K. and Berg-Kirkpatrick, Taylor and Portnoff, Rebecca S. and Afroz, Sadia and McCoy, Damon and Levchenko, Kirill and Paxson, Vern},
  title     = {Identifying Products in Online Cybercrime Marketplaces: A Dataset for Fine-grained Domain Adaptation},
  arxiv     = {https://arxiv.org/abs/1708.09609},
  booktitle = {Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing},
  doi       = {10.18653/v1/D17-1275},
  year      = {2017},
  month     = {September},
  location  = {Copenhagen, Denmark},
  url       = {https://www.aclweb.org/anthology/D17-1275.pdf},
  pages     = {2588--2597},
  software  = {https://evidencebasedsecurity.org/forums/},
  supplementary = {https://www.aclweb.org/anthology/attachments/D17-1275.Attachment.zip},
}
        </pre>
        
        </p>
    </div>
  </div>
</div>


<div class="container pb-2">
  <div class="row">
    <div class="col-lg-6">
      <strong>Understanding Task Design Trade-offs in Crowdsourced Paraphrase Collection</strong>
      <br />
      <span class="text-muted">Youxuan Jiang, Jonathan K. Kummerfeld, Walter S. Lasecki</span>
      <br />
      ACL (short)<span class="text-muted">, 2017</span>
    </div>
    <div class="col-lg-6">
      <a class="btn btn-outline-primary btn-sm" href="https://aclanthology.org/P17-2017.pdf" target="_blank" rel="noopener"><span
    class="fontawesome-inline-svg"
    style="display: inline-flex; align-self: center; height:1em; width:1em; top: .125em; position: relative;"
><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path fill='currentColor' d="M256 0v128h128L256 0zM224 128L224 0H48C21.49 0 0 21.49 0 48v416C0 490.5 21.49 512 48 512h288c26.51 0 48-21.49 48-48V160h-127.1C238.3 160 224 145.7 224 128zM272 416h-160C103.2 416 96 408.8 96 400C96 391.2 103.2 384 112 384h160c8.836 0 16 7.162 16 16C288 408.8 280.8 416 272 416zM272 352h-160C103.2 352 96 344.8 96 336C96 327.2 103.2 320 112 320h160c8.836 0 16 7.162 16 16C288 344.8 280.8 352 272 352zM288 272C288 280.8 280.8 288 272 288h-160C103.2 288 96 280.8 96 272C96 263.2 103.2 256 112 256h160C280.8 256 288 263.2 288 272z"/></svg>
</span>
 PDF</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('acl17paraphrase-abstract').style.display == 'block') {
  document.getElementById('acl17paraphrase-abstract').style.display='none';
  } else {
  document.getElementById('acl17paraphrase-abstract').style.display='block';
  }
  ">Abstract</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('acl17paraphrase-cite').style.display == 'block') {
  document.getElementById('acl17paraphrase-cite').style.display='none';
  } else {
  document.getElementById('acl17paraphrase-cite').style.display='block';
  }
  ">BibTeX</a>
      
      
      
      <a class="btn btn-outline-primary btn-sm" href="https://www.aclweb.org/anthology/attachments/P17-2017.Datasets.zip" target="_blank" rel="noopener"><span
    class="fontawesome-inline-svg"
    style="display: inline-flex; align-self: center; height:1em; width:1em; top: .125em; position: relative;"
><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill='currentColor' d="M448 80V128C448 172.2 347.7 208 224 208C100.3 208 0 172.2 0 128V80C0 35.82 100.3 0 224 0C347.7 0 448 35.82 448 80zM393.2 214.7C413.1 207.3 433.1 197.8 448 186.1V288C448 332.2 347.7 368 224 368C100.3 368 0 332.2 0 288V186.1C14.93 197.8 34.02 207.3 54.85 214.7C99.66 230.7 159.5 240 224 240C288.5 240 348.3 230.7 393.2 214.7V214.7zM54.85 374.7C99.66 390.7 159.5 400 224 400C288.5 400 348.3 390.7 393.2 374.7C413.1 367.3 433.1 357.8 448 346.1V432C448 476.2 347.7 512 224 512C100.3 512 0 476.2 0 432V346.1C14.93 357.8 34.02 367.3 54.85 374.7z"/></svg>
</span>
 Data</a>
      
      
      
      
      
      <a class="btn btn-outline-primary btn-sm" href="https://vimeo.com/234958413" target="_blank" rel="noopener"><span
    class="fontawesome-inline-svg"
    style="display: inline-flex; align-self: center; height:1em; width:1em; top: .125em; position: relative;"
><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><path fill='currentColor' d="M384 112v288c0 26.51-21.49 48-48 48h-288c-26.51 0-48-21.49-48-48v-288c0-26.51 21.49-48 48-48h288C362.5 64 384 85.49 384 112zM576 127.5v256.9c0 25.5-29.17 40.39-50.39 25.79L416 334.7V177.3l109.6-75.56C546.9 87.13 576 102.1 576 127.5z"/></svg>
</span>
 Video</a>
      
    </div>
  </div>
  <div class="row" id="acl17paraphrase-abstract" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          Linguistically diverse datasets are critical for training and evaluating robust machine learning systems, but data collection is a costly process that often requires experts. Crowdsourcing the process of paraphrase generation is an effective means of expanding natural language datasets, but there has been limited analysis of the trade-offs that arise when designing tasks. In this paper, we present the first systematic study of the key factors in crowdsourcing paraphrase collection. We consider variations in instructions, incentives, data domains, and workflows. We manually analyzed paraphrases for correctness, grammaticality, and linguistic diversity. Our observations provide new insight into the trade-offs between accuracy and diversity in crowd responses that arise as a result of task design, providing guidance for future paraphrase generation procedures.
        </p>
    </div>
  </div>
  <div class="row" id="acl17paraphrase-cite" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          
        <pre>
        @InProceedings{acl17paraphrase,
  author    = {Jiang, Youxuan and Kummerfeld, Jonathan K. and Lasecki, Walter S.},
  doi       = {10.18653/v1/P17-2017},
  title     = {Understanding Task Design Trade-offs in Crowdsourced Paraphrase Collection},
  booktitle = {Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)},
  month     = {July},
  year      = {2017},
  location  = {Vancouver, Canada},
  pages     = {103--109},
  url       = {https://aclanthology.org/P17-2017.pdf},
  data      = {https://www.aclweb.org/anthology/attachments/P17-2017.Datasets.zip},
  slidespdf = {https://www.aclweb.org/anthology/attachments/P17-2017.Presentation.pdf},
  video     = {https://vimeo.com/234958413},
  arxiv     = {https://arxiv.org/abs/1704.05753},
}
        </pre>
        
        </p>
    </div>
  </div>
</div>


<div class="container pb-2">
  <div class="row">
    <div class="col-lg-6">
      <strong>Tools for Automated Analysis of Cybercriminal Markets</strong>
      <br />
      <span class="text-muted">Rebecca S. Portnoff, Sadia Afroz, Greg Durrett, Jonathan K. Kummerfeld, Taylor Berg-Kirkpatrick, Damon McCoy, Kirill Levchenko, Vern Paxson</span>
      <br />
      WWW<span class="text-muted">, 2017</span>
    </div>
    <div class="col-lg-6">
      <a class="btn btn-outline-primary btn-sm" href="https://www.jkk.name/pub/www17forums.pdf" target="_blank" rel="noopener"><span
    class="fontawesome-inline-svg"
    style="display: inline-flex; align-self: center; height:1em; width:1em; top: .125em; position: relative;"
><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path fill='currentColor' d="M256 0v128h128L256 0zM224 128L224 0H48C21.49 0 0 21.49 0 48v416C0 490.5 21.49 512 48 512h288c26.51 0 48-21.49 48-48V160h-127.1C238.3 160 224 145.7 224 128zM272 416h-160C103.2 416 96 408.8 96 400C96 391.2 103.2 384 112 384h160c8.836 0 16 7.162 16 16C288 408.8 280.8 416 272 416zM272 352h-160C103.2 352 96 344.8 96 336C96 327.2 103.2 320 112 320h160c8.836 0 16 7.162 16 16C288 344.8 280.8 352 272 352zM288 272C288 280.8 280.8 288 272 288h-160C103.2 288 96 280.8 96 272C96 263.2 103.2 256 112 256h160C280.8 256 288 263.2 288 272z"/></svg>
</span>
 PDF</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('www17forums-abstract').style.display == 'block') {
  document.getElementById('www17forums-abstract').style.display='none';
  } else {
  document.getElementById('www17forums-abstract').style.display='block';
  }
  ">Abstract</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('www17forums-cite').style.display == 'block') {
  document.getElementById('www17forums-cite').style.display='none';
  } else {
  document.getElementById('www17forums-cite').style.display='block';
  }
  ">BibTeX</a>
      
      
      
      
      <a class="btn btn-outline-primary btn-sm" href="http://evidencebasedsecurity.org/forums/" target="_blank" rel="noopener"><span
    class="fontawesome-inline-svg"
    style="display: inline-flex; align-self: center; height:1em; width:1em; top: .125em; position: relative;"
><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512"><path fill='currentColor' d="M414.8 40.79L286.8 488.8C281.9 505.8 264.2 515.6 247.2 510.8C230.2 505.9 220.4 488.2 225.2 471.2L353.2 23.21C358.1 6.216 375.8-3.624 392.8 1.232C409.8 6.087 419.6 23.8 414.8 40.79H414.8zM518.6 121.4L630.6 233.4C643.1 245.9 643.1 266.1 630.6 278.6L518.6 390.6C506.1 403.1 485.9 403.1 473.4 390.6C460.9 378.1 460.9 357.9 473.4 345.4L562.7 256L473.4 166.6C460.9 154.1 460.9 133.9 473.4 121.4C485.9 108.9 506.1 108.9 518.6 121.4V121.4zM166.6 166.6L77.25 256L166.6 345.4C179.1 357.9 179.1 378.1 166.6 390.6C154.1 403.1 133.9 403.1 121.4 390.6L9.372 278.6C-3.124 266.1-3.124 245.9 9.372 233.4L121.4 121.4C133.9 108.9 154.1 108.9 166.6 121.4C179.1 133.9 179.1 154.1 166.6 166.6V166.6z"/></svg>
</span>
 Software</a>
      
      
      
      
    </div>
  </div>
  <div class="row" id="www17forums-abstract" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          Underground forums are widely used by criminals to buy and sell a host of stolen items, datasets, resources, and criminal services.  These forums contain important resources for understanding cybercrime.  However, the number of forums, their size, and the domain expertise required to understand the markets makes manual exploration of these forums unscalable. In this work, we propose an automated, top-down approach for analyzing underground forums.  Our approach uses natural language processing and machine learning to automatically generate high-level information about underground forums, first identifying posts related to transactions, and then extracting products and prices. We also demonstrate, via a pair of case studies, how an analyst can use these automated approaches to investigate other categories of products and transactions. We use eight distinct forums to assess our tools: Antichat, Blackhat World, Carders, Darkode, Hack Forums, Hell, L33tCrew and Nulled. Our automated approach is fast and accurate, achieving over 80% accuracy in detecting post category, product, and prices.
        </p>
    </div>
  </div>
  <div class="row" id="www17forums-cite" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          
        <pre>
        @InProceedings{www17forums,
  title     = {Tools for Automated Analysis of Cybercriminal Markets},
  author    = {Portnoff, Rebecca S. and Afroz, Sadia and Durrett, Greg and Kummerfeld, Jonathan K. and Berg-Kirkpatrick, Taylor and McCoy, Damon and Levchenko, Kirill and Paxson, Vern},
  booktitle = {Proceedings of 26th International World Wide Web conference},
  pages     = {657--666},
  month     = {April},
  year      = {2017},
  location  = {Perth, Australia},
  url       = {https://www.jkk.name/pub/www17forums.pdf},
  software  = {http://evidencebasedsecurity.org/forums/},
}
        </pre>
        
        </p>
    </div>
  </div>
</div>


<h3 id="2016">2016</h3>
<div class="container pb-2">
  <div class="row">
    <div class="col-lg-6">
      <strong>Algorithms for Identifying Syntactic Errors and Parsing with Graph Structured Output</strong>
      <br />
      <span class="text-muted">Jonathan K. Kummerfeld</span>
      <br />
      EECS Department, University of California, Berkeley<span class="text-muted">, 2016</span>
    </div>
    <div class="col-lg-6">
      <a class="btn btn-outline-primary btn-sm" href="https://www2.eecs.berkeley.edu/Pubs/TechRpts/2016/EECS-2016-138.html" target="_blank" rel="noopener"><span
    class="fontawesome-inline-svg"
    style="display: inline-flex; align-self: center; height:1em; width:1em; top: .125em; position: relative;"
><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path fill='currentColor' d="M256 0v128h128L256 0zM224 128L224 0H48C21.49 0 0 21.49 0 48v416C0 490.5 21.49 512 48 512h288c26.51 0 48-21.49 48-48V160h-127.1C238.3 160 224 145.7 224 128zM272 416h-160C103.2 416 96 408.8 96 400C96 391.2 103.2 384 112 384h160c8.836 0 16 7.162 16 16C288 408.8 280.8 416 272 416zM272 352h-160C103.2 352 96 344.8 96 336C96 327.2 103.2 320 112 320h160c8.836 0 16 7.162 16 16C288 344.8 280.8 352 272 352zM288 272C288 280.8 280.8 288 272 288h-160C103.2 288 96 280.8 96 272C96 263.2 103.2 256 112 256h160C280.8 256 288 263.2 288 272z"/></svg>
</span>
 PDF</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('thesis16parsing-abstract').style.display == 'block') {
  document.getElementById('thesis16parsing-abstract').style.display='none';
  } else {
  document.getElementById('thesis16parsing-abstract').style.display='block';
  }
  ">Abstract</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('thesis16parsing-cite').style.display == 'block') {
  document.getElementById('thesis16parsing-cite').style.display='none';
  } else {
  document.getElementById('thesis16parsing-cite').style.display='block';
  }
  ">BibTeX</a>
      
      
      
      
      
      
      
    </div>
  </div>
  <div class="row" id="thesis16parsing-abstract" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          Representation of syntactic structure is a core area of research in Computational Linguistics, disambiguating distinctions in meaning that are crucial for correct interpretation of language. Development of algorithms and statistical models over the past three decades has led to systems that are accurate enough to be deployed in industry, playing a key role in products such as Google Search and Apple Siri. However, syntactic parsers today are usually constrained to tree representations of language, and performance is interpreted through a single metric that conveys no linguistic information regarding remaining errors.\n\nIn this dissertation, we present new algorithms for error analysis and parsing. The heart of our approach to error analysis is the use of structural transformations to identify more meaningful classes of errors, and to enable comparisons across formalisms. For parsing, we combine a novel dynamic program with careful choices in syntactic representation to create an efficient parser that produces graph structured output. Together, these developments allowed us to evaluate the outstanding challenges in parsing and to address a key weakness in current work.\n\nFirst, we present a search algorithm that, given two structures, finds a sequence of modifications leading from one structure to the other. We applied this algorithm to syntactic error analysis, where one structure is the output of a parser, the other is the correct parse, and each modification corresponds to fixing one error. We constructed a tool based on the algorithm and analyzed variations in behavior between parsers, types of text, and languages. Our observations shine light on several assumptions about syntactic errors, showing some to be true and others to be false. For example, prepositional phrase attachment errors are indeed a major issue, while coordination scope errors do not hurt performance as much as expected.\n\nNext, we describe an algorithm that builds a parse in one syntactic representation to match a parse in another representation. Specifically, we build phrase structure parses from Combinatory Categorial Grammar derivations. Our approach follows the philosophy of CCG, defining specific phrase structures for each lexical category and generic rules for combinatory steps. The new parse is built by following the CCG derivation bottom-up, gradually building the corresponding phrase structure parse. This produced significantly more accurate parses than past work, and enabled us to compare performance of several parsers across formalisms.\n\nFinally, we address a weakness we observed in phrase structure parsers: the exclusion of syntactic trace structures for computational convenience. We present an efficient dynamic programming algorithm that constructs the graph structure that has the highest score under an edge-factored scoring function. We define a parse representation compatible with the algorithm, and show how certain linguistic distinctions dramatically impact coverage. We also show various ways to modify the algorithm to improve performance by exploiting properties of observed linguistic structure. This approach to syntactic parsing is the first to cover virtually all structure encoded in the Penn Treebank.
        </p>
    </div>
  </div>
  <div class="row" id="thesis16parsing-cite" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          
        <pre>
        @PhDThesis{thesis16parsing,
  title     = {Algorithms for Identifying Syntactic Errors and Parsing with Graph Structured Output},
  author    = {Kummerfeld, Jonathan K.},
  year      = {2016},
  month     = {Aug},
  location  = {Berkeley, CA, USA},
  school    = {EECS Department, University of California, Berkeley},
  number    = {UCB/EECS-2016-138},
  url       = {https://www2.eecs.berkeley.edu/Pubs/TechRpts/2016/EECS-2016-138.html},

  In this dissertation, we present new algorithms for error analysis and parsing. The heart of our approach to error analysis is the use of structural transformations to identify more meaningful classes of errors, and to enable comparisons across formalisms. For parsing, we combine a novel dynamic program with careful choices in syntactic representation to create an efficient parser that produces graph structured output. Together, these developments allowed us to evaluate the outstanding challenges in parsing and to address a key weakness in current work.

  First, we present a search algorithm that, given two structures, finds a sequence of modifications leading from one structure to the other. We applied this algorithm to syntactic error analysis, where one structure is the output of a parser, the other is the correct parse, and each modification corresponds to fixing one error. We constructed a tool based on the algorithm and analyzed variations in behavior between parsers, types of text, and languages. Our observations shine light on several assumptions about syntactic errors, showing some to be true and others to be false. For example, prepositional phrase attachment errors are indeed a major issue, while coordination scope errors do not hurt performance as much as expected.

  Next, we describe an algorithm that builds a parse in one syntactic representation to match a parse in another representation. Specifically, we build phrase structure parses from Combinatory Categorial Grammar derivations. Our approach follows the philosophy of CCG, defining specific phrase structures for each lexical category and generic rules for combinatory steps. The new parse is built by following the CCG derivation bottom-up, gradually building the corresponding phrase structure parse. This produced significantly more accurate parses than past work, and enabled us to compare performance of several parsers across formalisms.

  Finally, we address a weakness we observed in phrase structure parsers: the exclusion of syntactic trace structures for computational convenience. We present an efficient dynamic programming algorithm that constructs the graph structure that has the highest score under an edge-factored scoring function. We define a parse representation compatible with the algorithm, and show how certain linguistic distinctions dramatically impact coverage. We also show various ways to modify the algorithm to improve performance by exploiting properties of observed linguistic structure. This approach to syntactic parsing is the first to cover virtually all structure encoded in the Penn Treebank.},
}
        </pre>
        
        </p>
    </div>
  </div>
</div>


<h3 id="2015">2015</h3>
<div class="container pb-2">
  <div class="row">
    <div class="col-lg-6">
      <strong>An Empirical Analysis of Optimization for Max-Margin NLP</strong>
      <br />
      <span class="text-muted">Jonathan K. Kummerfeld, Taylor Berg-Kirkpatrick, Dan Klein</span>
      <br />
      EMNLP (short)<span class="text-muted">, 2015</span>
    </div>
    <div class="col-lg-6">
      <a class="btn btn-outline-primary btn-sm" href="https://www.jkk.name/pub/emnlp15learn.pdf" target="_blank" rel="noopener"><span
    class="fontawesome-inline-svg"
    style="display: inline-flex; align-self: center; height:1em; width:1em; top: .125em; position: relative;"
><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path fill='currentColor' d="M256 0v128h128L256 0zM224 128L224 0H48C21.49 0 0 21.49 0 48v416C0 490.5 21.49 512 48 512h288c26.51 0 48-21.49 48-48V160h-127.1C238.3 160 224 145.7 224 128zM272 416h-160C103.2 416 96 408.8 96 400C96 391.2 103.2 384 112 384h160c8.836 0 16 7.162 16 16C288 408.8 280.8 416 272 416zM272 352h-160C103.2 352 96 344.8 96 336C96 327.2 103.2 320 112 320h160c8.836 0 16 7.162 16 16C288 344.8 280.8 352 272 352zM288 272C288 280.8 280.8 288 272 288h-160C103.2 288 96 280.8 96 272C96 263.2 103.2 256 112 256h160C280.8 256 288 263.2 288 272z"/></svg>
</span>
 PDF</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('emnlp15learn-abstract').style.display == 'block') {
  document.getElementById('emnlp15learn-abstract').style.display='none';
  } else {
  document.getElementById('emnlp15learn-abstract').style.display='block';
  }
  ">Abstract</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('emnlp15learn-cite').style.display == 'block') {
  document.getElementById('emnlp15learn-cite').style.display='none';
  } else {
  document.getElementById('emnlp15learn-cite').style.display='block';
  }
  ">BibTeX</a>
      
      
      
      
      <a class="btn btn-outline-primary btn-sm" href="https://github.com/tberg12/murphy" target="_blank" rel="noopener"><span
    class="fontawesome-inline-svg"
    style="display: inline-flex; align-self: center; height:1em; width:1em; top: .125em; position: relative;"
><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512"><path fill='currentColor' d="M414.8 40.79L286.8 488.8C281.9 505.8 264.2 515.6 247.2 510.8C230.2 505.9 220.4 488.2 225.2 471.2L353.2 23.21C358.1 6.216 375.8-3.624 392.8 1.232C409.8 6.087 419.6 23.8 414.8 40.79H414.8zM518.6 121.4L630.6 233.4C643.1 245.9 643.1 266.1 630.6 278.6L518.6 390.6C506.1 403.1 485.9 403.1 473.4 390.6C460.9 378.1 460.9 357.9 473.4 345.4L562.7 256L473.4 166.6C460.9 154.1 460.9 133.9 473.4 121.4C485.9 108.9 506.1 108.9 518.6 121.4V121.4zM166.6 166.6L77.25 256L166.6 345.4C179.1 357.9 179.1 378.1 166.6 390.6C154.1 403.1 133.9 403.1 121.4 390.6L9.372 278.6C-3.124 266.1-3.124 245.9 9.372 233.4L121.4 121.4C133.9 108.9 154.1 108.9 166.6 121.4C179.1 133.9 179.1 154.1 166.6 166.6V166.6z"/></svg>
</span>
 Software</a>
      
      
      <a class="btn btn-outline-primary btn-sm" href="https://www.jkk.name/pub/emnlp15learn_poster.png" target="_blank" rel="noopener">Poster</a>
      
      
      
    </div>
  </div>
  <div class="row" id="emnlp15learn-abstract" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          Despite the convexity of structured max-margin objectives (Taskar et al., 2004; Tsochantaridis et al., 2004), the many ways to optimize them are not equally effective in practice. We compare a range of online optimization methods over a variety of structured NLP tasks (coreference, summarization, parsing, etc) and find several broad trends. First, margin methods do tend to outperform both likelihood and the perceptron. Second, for max-margin objectives, primal  optimization methods are often more robust and progress faster than dual methods. This advantage  is most pronounced for tasks with dense or continuous-valued features. Overall, we argue for a particularly simple online primal subgradient descent method that, despite being rarely mentioned in the literature, is surprisingly effective in relation to its alternatives.
        </p>
    </div>
  </div>
  <div class="row" id="emnlp15learn-cite" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          
        <pre>
        @InProceedings{emnlp15learn,
  title     = {An Empirical Analysis of Optimization for Max-Margin NLP},
  author    = {Kummerfeld, Jonathan K. and Berg-Kirkpatrick, Taylor and Klein, Dan},
  doi       = {10.18653/v1/D15-1032},
  booktitle = {Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing},
  month     = {September},
  year      = {2015},
  location  = {Lisbon, Portugal},
  pages     = {273--279},
  url       = {https://www.jkk.name/pub/emnlp15learn.pdf},
  poster    = {https://www.jkk.name/pub/emnlp15learn_poster.png},
  software  = {https://github.com/tberg12/murphy},
}
        </pre>
        
        </p>
    </div>
  </div>
</div>


<h3 id="2013">2013</h3>
<div class="container pb-2">
  <div class="row">
    <div class="col-lg-6">
      <strong>Error-Driven Analysis of Challenges in Coreference Resolution</strong>
      <br />
      <span class="text-muted">Jonathan K. Kummerfeld, Dan Klein</span>
      <br />
      EMNLP<span class="text-muted">, 2013</span>
    </div>
    <div class="col-lg-6">
      <a class="btn btn-outline-primary btn-sm" href="https://aclanthology.org/D13-1027.pdf" target="_blank" rel="noopener"><span
    class="fontawesome-inline-svg"
    style="display: inline-flex; align-self: center; height:1em; width:1em; top: .125em; position: relative;"
><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path fill='currentColor' d="M256 0v128h128L256 0zM224 128L224 0H48C21.49 0 0 21.49 0 48v416C0 490.5 21.49 512 48 512h288c26.51 0 48-21.49 48-48V160h-127.1C238.3 160 224 145.7 224 128zM272 416h-160C103.2 416 96 408.8 96 400C96 391.2 103.2 384 112 384h160c8.836 0 16 7.162 16 16C288 408.8 280.8 416 272 416zM272 352h-160C103.2 352 96 344.8 96 336C96 327.2 103.2 320 112 320h160c8.836 0 16 7.162 16 16C288 344.8 280.8 352 272 352zM288 272C288 280.8 280.8 288 272 288h-160C103.2 288 96 280.8 96 272C96 263.2 103.2 256 112 256h160C280.8 256 288 263.2 288 272z"/></svg>
</span>
 PDF</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('emnlp13analysis-abstract').style.display == 'block') {
  document.getElementById('emnlp13analysis-abstract').style.display='none';
  } else {
  document.getElementById('emnlp13analysis-abstract').style.display='block';
  }
  ">Abstract</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('emnlp13analysis-cite').style.display == 'block') {
  document.getElementById('emnlp13analysis-cite').style.display='none';
  } else {
  document.getElementById('emnlp13analysis-cite').style.display='block';
  }
  ">BibTeX</a>
      
      
      
      
      <a class="btn btn-outline-primary btn-sm" href="https://www.jkk.name/berkeley-coreference-analyser/" target="_blank" rel="noopener"><span
    class="fontawesome-inline-svg"
    style="display: inline-flex; align-self: center; height:1em; width:1em; top: .125em; position: relative;"
><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512"><path fill='currentColor' d="M414.8 40.79L286.8 488.8C281.9 505.8 264.2 515.6 247.2 510.8C230.2 505.9 220.4 488.2 225.2 471.2L353.2 23.21C358.1 6.216 375.8-3.624 392.8 1.232C409.8 6.087 419.6 23.8 414.8 40.79H414.8zM518.6 121.4L630.6 233.4C643.1 245.9 643.1 266.1 630.6 278.6L518.6 390.6C506.1 403.1 485.9 403.1 473.4 390.6C460.9 378.1 460.9 357.9 473.4 345.4L562.7 256L473.4 166.6C460.9 154.1 460.9 133.9 473.4 121.4C485.9 108.9 506.1 108.9 518.6 121.4V121.4zM166.6 166.6L77.25 256L166.6 345.4C179.1 357.9 179.1 378.1 166.6 390.6C154.1 403.1 133.9 403.1 121.4 390.6L9.372 278.6C-3.124 266.1-3.124 245.9 9.372 233.4L121.4 121.4C133.9 108.9 154.1 108.9 166.6 121.4C179.1 133.9 179.1 154.1 166.6 166.6V166.6z"/></svg>
</span>
 Software</a>
      
      
      
      <a class="btn btn-outline-primary btn-sm" href="https://www.jkk.name/pub/emnlp13analysis_keynote.key" target="_blank" rel="noopener">Slides</a>
      
      
    </div>
  </div>
  <div class="row" id="emnlp13analysis-abstract" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          Coreference resolution metrics quantify errors but do not analyze them. Here, we consider an automated method of categorizing errors in the output of a coreference system into intuitive underlying error types. Using this tool, we first compare the error distributions across a large set of systems, then analyze common errors across the top ten systems, empirically characterizing the major unsolved challenges of the coreference resolution task.
        </p>
    </div>
  </div>
  <div class="row" id="emnlp13analysis-cite" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          
        <pre>
        @InProceedings{emnlp13analysis,
  title     = {Error-Driven Analysis of Challenges in Coreference Resolution},
  author    = {Kummerfeld, Jonathan K. and Klein, Dan},
  booktitle = {Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing},
  month     = {October},
  year      = {2013},
  location  = {Seattle, Washington, USA},
  pages     = {265--277},
  software  = {https://www.jkk.name/berkeley-coreference-analyser/},
  url       = {https://aclanthology.org/D13-1027.pdf},
  slides    = {https://www.jkk.name/pub/emnlp13analysis_keynote.key},
  slidespdf = {https://www.jkk.name/pub/emnlp13analysis_slides.pdf},
}
        </pre>
        
        </p>
    </div>
  </div>
</div>


<div class="container pb-2">
  <div class="row">
    <div class="col-lg-6">
      <strong>An Empirical Examination of Challenges in Chinese Parsing</strong>
      <br />
      <span class="text-muted">Jonathan K. Kummerfeld, Daniel Tse, James R. Curran, Dan Klein</span>
      <br />
      ACL (short)<span class="text-muted">, 2013</span>
    </div>
    <div class="col-lg-6">
      <a class="btn btn-outline-primary btn-sm" href="https://aclanthology.org/P13-2018.pdf" target="_blank" rel="noopener"><span
    class="fontawesome-inline-svg"
    style="display: inline-flex; align-self: center; height:1em; width:1em; top: .125em; position: relative;"
><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path fill='currentColor' d="M256 0v128h128L256 0zM224 128L224 0H48C21.49 0 0 21.49 0 48v416C0 490.5 21.49 512 48 512h288c26.51 0 48-21.49 48-48V160h-127.1C238.3 160 224 145.7 224 128zM272 416h-160C103.2 416 96 408.8 96 400C96 391.2 103.2 384 112 384h160c8.836 0 16 7.162 16 16C288 408.8 280.8 416 272 416zM272 352h-160C103.2 352 96 344.8 96 336C96 327.2 103.2 320 112 320h160c8.836 0 16 7.162 16 16C288 344.8 280.8 352 272 352zM288 272C288 280.8 280.8 288 272 288h-160C103.2 288 96 280.8 96 272C96 263.2 103.2 256 112 256h160C280.8 256 288 263.2 288 272z"/></svg>
</span>
 PDF</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('acl13analysis-abstract').style.display == 'block') {
  document.getElementById('acl13analysis-abstract').style.display='none';
  } else {
  document.getElementById('acl13analysis-abstract').style.display='block';
  }
  ">Abstract</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('acl13analysis-cite').style.display == 'block') {
  document.getElementById('acl13analysis-cite').style.display='none';
  } else {
  document.getElementById('acl13analysis-cite').style.display='block';
  }
  ">BibTeX</a>
      
      
      
      
      <a class="btn btn-outline-primary btn-sm" href="https://www.jkk.name/berkeley-parser-analyser/" target="_blank" rel="noopener"><span
    class="fontawesome-inline-svg"
    style="display: inline-flex; align-self: center; height:1em; width:1em; top: .125em; position: relative;"
><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512"><path fill='currentColor' d="M414.8 40.79L286.8 488.8C281.9 505.8 264.2 515.6 247.2 510.8C230.2 505.9 220.4 488.2 225.2 471.2L353.2 23.21C358.1 6.216 375.8-3.624 392.8 1.232C409.8 6.087 419.6 23.8 414.8 40.79H414.8zM518.6 121.4L630.6 233.4C643.1 245.9 643.1 266.1 630.6 278.6L518.6 390.6C506.1 403.1 485.9 403.1 473.4 390.6C460.9 378.1 460.9 357.9 473.4 345.4L562.7 256L473.4 166.6C460.9 154.1 460.9 133.9 473.4 121.4C485.9 108.9 506.1 108.9 518.6 121.4V121.4zM166.6 166.6L77.25 256L166.6 345.4C179.1 357.9 179.1 378.1 166.6 390.6C154.1 403.1 133.9 403.1 121.4 390.6L9.372 278.6C-3.124 266.1-3.124 245.9 9.372 233.4L121.4 121.4C133.9 108.9 154.1 108.9 166.6 121.4C179.1 133.9 179.1 154.1 166.6 166.6V166.6z"/></svg>
</span>
 Software</a>
      
      
      
      <a class="btn btn-outline-primary btn-sm" href="https://www.jkk.name/pub/acl13analysis_keynote.key" target="_blank" rel="noopener">Slides</a>
      
      
    </div>
  </div>
  <div class="row" id="acl13analysis-abstract" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          Aspects of Chinese syntax result in a distinctive mix of parsing challenges. However, the contribution of individual sources of error to overall difficulty is not well understood. We conduct a comprehensive automatic analysis of error types made by Chinese parsers, covering a broad range of error types for large sets of sentences, enabling the first empirical ranking of Chinese error types by their performance impact. We also investigate which error types are resolved by using gold part-of-speech tags, showing that improving Chinese tagging only addresses certain error types, leaving substantial outstanding challenges.
        </p>
    </div>
  </div>
  <div class="row" id="acl13analysis-cite" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          
        <pre>
        @InProceedings{acl13analysis,
  title     = {An Empirical Examination of Challenges in Chinese Parsing},
  author    = {Kummerfeld, Jonathan K. and Tse, Daniel and Curran, James R. and Klein, Dan},
  booktitle = {Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)},
  location  = {Sofia, Bulgaria},
  pages     = {98--103},
  month     = {August},
  year      = {2013},
  software  = {https://www.jkk.name/berkeley-parser-analyser/},
  url       = {https://aclanthology.org/P13-2018.pdf},
  slides    = {https://www.jkk.name/pub/acl13analysis_keynote.key},
  slidespdf = {https://www.jkk.name/pub/acl13analysis_slides.pdf},
}
        </pre>
        
        </p>
    </div>
  </div>
</div>


<div class="container pb-2">
  <div class="row">
    <div class="col-lg-6">
      <strong>High-velocity Clouds in the Galactic All Sky Survey. I. Catalog</strong>
      <br />
      <span class="text-muted">Vanessa A. Moss, Naomi M. McClure-Griffiths, Tara Murphy, D. J. Pisano, Jonathan K. Kummerfeld, James R. Curran</span>
      <br />
      The Astrophysical Journal Supplement Series<span class="text-muted">, 2013</span>
    </div>
    <div class="col-lg-6">
      <a class="btn btn-outline-primary btn-sm" href="http://iopscience.iop.org/0067-0049/209/1/12" target="_blank" rel="noopener"><span
    class="fontawesome-inline-svg"
    style="display: inline-flex; align-self: center; height:1em; width:1em; top: .125em; position: relative;"
><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path fill='currentColor' d="M256 0v128h128L256 0zM224 128L224 0H48C21.49 0 0 21.49 0 48v416C0 490.5 21.49 512 48 512h288c26.51 0 48-21.49 48-48V160h-127.1C238.3 160 224 145.7 224 128zM272 416h-160C103.2 416 96 408.8 96 400C96 391.2 103.2 384 112 384h160c8.836 0 16 7.162 16 16C288 408.8 280.8 416 272 416zM272 352h-160C103.2 352 96 344.8 96 336C96 327.2 103.2 320 112 320h160c8.836 0 16 7.162 16 16C288 344.8 280.8 352 272 352zM288 272C288 280.8 280.8 288 272 288h-160C103.2 288 96 280.8 96 272C96 263.2 103.2 256 112 256h160C280.8 256 288 263.2 288 272z"/></svg>
</span>
 PDF</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('astro13clouds-abstract').style.display == 'block') {
  document.getElementById('astro13clouds-abstract').style.display='none';
  } else {
  document.getElementById('astro13clouds-abstract').style.display='block';
  }
  ">Abstract</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('astro13clouds-cite').style.display == 'block') {
  document.getElementById('astro13clouds-cite').style.display='none';
  } else {
  document.getElementById('astro13clouds-cite').style.display='block';
  }
  ">BibTeX</a>
      
      
      
      
      
      
      
    </div>
  </div>
  <div class="row" id="astro13clouds-abstract" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          We present a catalogue of high-velocity clouds (HVCs) from the Galactic All Sky Survey (GASS) of southern-sky neutral hydrogen, which has 57 mK sensitivity and 1 km/s velocity resolution and was obtained with the Parkes Telescope. Our catalogue has been derived from the stray-radiation corrected second release of GASS. We describe the data and our method of identifying HVCs and analyse the overall properties of the GASS population. We catalogue a total of 1693 HVCs at declinations &lt; 0 deg, including 1111 positive velocity HVCs and 582 negative velocity HVCs. Our catalogue also includes 295 anomalous velocity clouds (AVCs). The cloud line-widths of our HVC population have a median FWHM of ~19 km/s, which is lower than found in previous surveys. The completeness of our catalogue is above 95% based on comparison with the HIPASS catalogue of HVCs, upon which we improve with an order of magnitude in spectral resolution. We find 758 new HVCs and AVCs with no HIPASS counterpart. The GASS catalogue will shed an unprecedented light on the distribution and kinematic structure of southern-sky HVCs, as well as delve further into the cloud populations that make up the anomalous velocity gas of the Milky Way.
        </p>
    </div>
  </div>
  <div class="row" id="astro13clouds-cite" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          
        <pre>
        @Article{astro13clouds,
  title     = {High-velocity Clouds in the Galactic All Sky Survey. I. Catalog},
  author    = {Moss, Vanessa A. and McClure-Griffiths, Naomi M. and Murphy, Tara and Pisano, D. J. and Kummerfeld, Jonathan K. and Curran, James R.},
  volume    = {209},
  number    = {1},
  pages     = {12},
  publisher = {IOP Publishing},
  journal   = {The Astrophysical Journal Supplement Series},
  year      = {2013},
  url       = {http://iopscience.iop.org/0067-0049/209/1/12},
  arxiv     = {https://arxiv.org/abs/1309.4104},
}
        </pre>
        
        </p>
    </div>
  </div>
</div>


<h3 id="2012">2012</h3>
<div class="container pb-2">
  <div class="row">
    <div class="col-lg-6">
      <strong>Parser Showdown at the Wall Street Corral: An Empirical Investigation of Error Types in Parser Output</strong>
      <br />
      <span class="text-muted">Jonathan K. Kummerfeld, David Hall, James R. Curran, Dan Klein</span>
      <br />
      EMNLP<span class="text-muted">, 2012</span>
    </div>
    <div class="col-lg-6">
      <a class="btn btn-outline-primary btn-sm" href="https://aclanthology.org/D12-1096.pdf" target="_blank" rel="noopener"><span
    class="fontawesome-inline-svg"
    style="display: inline-flex; align-self: center; height:1em; width:1em; top: .125em; position: relative;"
><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path fill='currentColor' d="M256 0v128h128L256 0zM224 128L224 0H48C21.49 0 0 21.49 0 48v416C0 490.5 21.49 512 48 512h288c26.51 0 48-21.49 48-48V160h-127.1C238.3 160 224 145.7 224 128zM272 416h-160C103.2 416 96 408.8 96 400C96 391.2 103.2 384 112 384h160c8.836 0 16 7.162 16 16C288 408.8 280.8 416 272 416zM272 352h-160C103.2 352 96 344.8 96 336C96 327.2 103.2 320 112 320h160c8.836 0 16 7.162 16 16C288 344.8 280.8 352 272 352zM288 272C288 280.8 280.8 288 272 288h-160C103.2 288 96 280.8 96 272C96 263.2 103.2 256 112 256h160C280.8 256 288 263.2 288 272z"/></svg>
</span>
 PDF</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('emnlp12analysis-abstract').style.display == 'block') {
  document.getElementById('emnlp12analysis-abstract').style.display='none';
  } else {
  document.getElementById('emnlp12analysis-abstract').style.display='block';
  }
  ">Abstract</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('emnlp12analysis-cite').style.display == 'block') {
  document.getElementById('emnlp12analysis-cite').style.display='none';
  } else {
  document.getElementById('emnlp12analysis-cite').style.display='block';
  }
  ">BibTeX</a>
      
      
      
      
      <a class="btn btn-outline-primary btn-sm" href="https://www.jkk.name/berkeley-parser-analyser/" target="_blank" rel="noopener"><span
    class="fontawesome-inline-svg"
    style="display: inline-flex; align-self: center; height:1em; width:1em; top: .125em; position: relative;"
><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512"><path fill='currentColor' d="M414.8 40.79L286.8 488.8C281.9 505.8 264.2 515.6 247.2 510.8C230.2 505.9 220.4 488.2 225.2 471.2L353.2 23.21C358.1 6.216 375.8-3.624 392.8 1.232C409.8 6.087 419.6 23.8 414.8 40.79H414.8zM518.6 121.4L630.6 233.4C643.1 245.9 643.1 266.1 630.6 278.6L518.6 390.6C506.1 403.1 485.9 403.1 473.4 390.6C460.9 378.1 460.9 357.9 473.4 345.4L562.7 256L473.4 166.6C460.9 154.1 460.9 133.9 473.4 121.4C485.9 108.9 506.1 108.9 518.6 121.4V121.4zM166.6 166.6L77.25 256L166.6 345.4C179.1 357.9 179.1 378.1 166.6 390.6C154.1 403.1 133.9 403.1 121.4 390.6L9.372 278.6C-3.124 266.1-3.124 245.9 9.372 233.4L121.4 121.4C133.9 108.9 154.1 108.9 166.6 121.4C179.1 133.9 179.1 154.1 166.6 166.6V166.6z"/></svg>
</span>
 Software</a>
      
      
      
      <a class="btn btn-outline-primary btn-sm" href="https://www.jkk.name/pub/emnlp12analysis_keynote.key" target="_blank" rel="noopener">Slides</a>
      
      
    </div>
  </div>
  <div class="row" id="emnlp12analysis-abstract" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          Constituency parser performance is primarily interpreted through a single metric, F-score on WSJ section 23, that conveys no linguistic information regarding the remaining errors.  We classify errors within a set of linguistically meaningful types using tree transformations that repair groups of errors together. We use this analysis to answer a range of questions about parser behaviour, including what linguistic constructions are difficult for state-of-the-art parsers, what types of errors are being resolved by rerankers, and what types are introduced when parsing out-of-domain text.
        </p>
    </div>
  </div>
  <div class="row" id="emnlp12analysis-cite" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          
        <pre>
        @InProceedings{emnlp12analysis,
  title     = {Parser Showdown at the Wall Street Corral: An Empirical Investigation of Error Types in Parser Output},
  author    = {Kummerfeld, Jonathan K. and Hall, David and Curran, James R. and Klein, Dan},
  booktitle = {Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning},
  year      = {2012},
  pages     = {1048--1059},
  month     = {July},
  location  = {Jeju Island, South Korea},
  software  = {https://www.jkk.name/berkeley-parser-analyser/},
  url       = {https://aclanthology.org/D12-1096.pdf},
  slides    = {https://www.jkk.name/pub/emnlp12analysis_keynote.key},
  slidespdf = {https://www.jkk.name/pub/emnlp12analysis_slides.pdf},
}
        </pre>
        
        </p>
    </div>
  </div>
</div>


<div class="container pb-2">
  <div class="row">
    <div class="col-lg-6">
      <strong>Robust Conversion of CCG Derivations to Phrase Structure Trees</strong>
      <br />
      <span class="text-muted">Jonathan K. Kummerfeld, Dan Klein, James R. Curran</span>
      <br />
      ACL (short)<span class="text-muted">, 2012</span>
    </div>
    <div class="col-lg-6">
      <a class="btn btn-outline-primary btn-sm" href="https://aclanthology.org/P12-2021.pdf" target="_blank" rel="noopener"><span
    class="fontawesome-inline-svg"
    style="display: inline-flex; align-self: center; height:1em; width:1em; top: .125em; position: relative;"
><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path fill='currentColor' d="M256 0v128h128L256 0zM224 128L224 0H48C21.49 0 0 21.49 0 48v416C0 490.5 21.49 512 48 512h288c26.51 0 48-21.49 48-48V160h-127.1C238.3 160 224 145.7 224 128zM272 416h-160C103.2 416 96 408.8 96 400C96 391.2 103.2 384 112 384h160c8.836 0 16 7.162 16 16C288 408.8 280.8 416 272 416zM272 352h-160C103.2 352 96 344.8 96 336C96 327.2 103.2 320 112 320h160c8.836 0 16 7.162 16 16C288 344.8 280.8 352 272 352zM288 272C288 280.8 280.8 288 272 288h-160C103.2 288 96 280.8 96 272C96 263.2 103.2 256 112 256h160C280.8 256 288 263.2 288 272z"/></svg>
</span>
 PDF</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('acl12conversion-abstract').style.display == 'block') {
  document.getElementById('acl12conversion-abstract').style.display='none';
  } else {
  document.getElementById('acl12conversion-abstract').style.display='block';
  }
  ">Abstract</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('acl12conversion-cite').style.display == 'block') {
  document.getElementById('acl12conversion-cite').style.display='none';
  } else {
  document.getElementById('acl12conversion-cite').style.display='block';
  }
  ">BibTeX</a>
      
      
      
      
      <a class="btn btn-outline-primary btn-sm" href="https://www.jkk.name/berkeley-ccg2pst/" target="_blank" rel="noopener"><span
    class="fontawesome-inline-svg"
    style="display: inline-flex; align-self: center; height:1em; width:1em; top: .125em; position: relative;"
><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512"><path fill='currentColor' d="M414.8 40.79L286.8 488.8C281.9 505.8 264.2 515.6 247.2 510.8C230.2 505.9 220.4 488.2 225.2 471.2L353.2 23.21C358.1 6.216 375.8-3.624 392.8 1.232C409.8 6.087 419.6 23.8 414.8 40.79H414.8zM518.6 121.4L630.6 233.4C643.1 245.9 643.1 266.1 630.6 278.6L518.6 390.6C506.1 403.1 485.9 403.1 473.4 390.6C460.9 378.1 460.9 357.9 473.4 345.4L562.7 256L473.4 166.6C460.9 154.1 460.9 133.9 473.4 121.4C485.9 108.9 506.1 108.9 518.6 121.4V121.4zM166.6 166.6L77.25 256L166.6 345.4C179.1 357.9 179.1 378.1 166.6 390.6C154.1 403.1 133.9 403.1 121.4 390.6L9.372 278.6C-3.124 266.1-3.124 245.9 9.372 233.4L121.4 121.4C133.9 108.9 154.1 108.9 166.6 121.4C179.1 133.9 179.1 154.1 166.6 166.6V166.6z"/></svg>
</span>
 Software</a>
      
      
      
      <a class="btn btn-outline-primary btn-sm" href="https://www.jkk.name/pub/acl12conversion_keynote.key" target="_blank" rel="noopener">Slides</a>
      
      
    </div>
  </div>
  <div class="row" id="acl12conversion-abstract" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          We propose an improved, bottom-up method for converting CCG derivations into PTB-style phrase structure trees. In contrast with past work (Clark and Curran, 2009), which used simple transductions on category pairs, our approach uses richer transductions attached to single categories. Our conversion preserves more sentences under round-trip conversion (51.1% vs. 39.6%) and is more robust. In particular, unlike past methods, ours does not require ad-hoc rules over non-local features, and so can be easily integrated into a parser.
        </p>
    </div>
  </div>
  <div class="row" id="acl12conversion-cite" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          
        <pre>
        @InProceedings{acl12conversion,
  title     = {Robust Conversion of CCG Derivations to Phrase Structure Trees},
  author    = {Kummerfeld, Jonathan K. and Klein, Dan and Curran, James R.},
  booktitle = {Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)},
  year      = {2012},
  pages     = {105--109},
  month     = {July},
  location  = {Jeju Island, South Korea},
  software  = {https://www.jkk.name/berkeley-ccg2pst/},
  url       = {https://aclanthology.org/P12-2021.pdf},
  slides    = {https://www.jkk.name/pub/acl12conversion_keynote.key},
  slidespdf = {https://www.jkk.name/pub/acl12conversion_slides.pdf},
}
        </pre>
        
        </p>
    </div>
  </div>
</div>


<h3 id="2011">2011</h3>
<div class="container pb-2">
  <div class="row">
    <div class="col-lg-6">
      <strong>Mention Detection: Heuristics for the OntoNotes annotations</strong>
      <br />
      <span class="text-muted">Jonathan K. Kummerfeld, Mohit Bansal, David Burkett, Dan Klein</span>
      <br />
      CoNLL Shared Task<span class="text-muted">, 2011</span>
    </div>
    <div class="col-lg-6">
      <a class="btn btn-outline-primary btn-sm" href="https://aclanthology.org/W11-1916.pdf" target="_blank" rel="noopener"><span
    class="fontawesome-inline-svg"
    style="display: inline-flex; align-self: center; height:1em; width:1em; top: .125em; position: relative;"
><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path fill='currentColor' d="M256 0v128h128L256 0zM224 128L224 0H48C21.49 0 0 21.49 0 48v416C0 490.5 21.49 512 48 512h288c26.51 0 48-21.49 48-48V160h-127.1C238.3 160 224 145.7 224 128zM272 416h-160C103.2 416 96 408.8 96 400C96 391.2 103.2 384 112 384h160c8.836 0 16 7.162 16 16C288 408.8 280.8 416 272 416zM272 352h-160C103.2 352 96 344.8 96 336C96 327.2 103.2 320 112 320h160c8.836 0 16 7.162 16 16C288 344.8 280.8 352 272 352zM288 272C288 280.8 280.8 288 272 288h-160C103.2 288 96 280.8 96 272C96 263.2 103.2 256 112 256h160C280.8 256 288 263.2 288 272z"/></svg>
</span>
 PDF</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('conll11coreference-abstract').style.display == 'block') {
  document.getElementById('conll11coreference-abstract').style.display='none';
  } else {
  document.getElementById('conll11coreference-abstract').style.display='block';
  }
  ">Abstract</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('conll11coreference-cite').style.display == 'block') {
  document.getElementById('conll11coreference-cite').style.display='none';
  } else {
  document.getElementById('conll11coreference-cite').style.display='block';
  }
  ">BibTeX</a>
      
      
      
      
      
      <a class="btn btn-outline-primary btn-sm" href="https://www.jkk.name/pub/conll11coreference_poster.pdf" target="_blank" rel="noopener">Poster</a>
      
      
      
    </div>
  </div>
  <div class="row" id="conll11coreference-abstract" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          Our submission was a reduced version of the system described in Haghighi and Klein (2010), with extensions to improve mention detection to suit the OntoNotes annotation scheme. Including exact matching mention detection in this shared task added a new and challenging dimension to the problem, particularly for our system, which previously used a very permissive detection method. We improved this aspect of the system by adding filters based on the annotation scheme for OntoNotes and analysis of system behavior on the development set. These changes led to improvements in coreference F-score of 10.06, 5.71, 6.78, 6.63 and 3.09 on the MUC, B3 , Ceaf-e, Ceaf-m and Blanc, metrics, respectively, and a final task score of 47.10.
        </p>
    </div>
  </div>
  <div class="row" id="conll11coreference-cite" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          
        <pre>
        @InProceedings{conll11coreference,
  title     = {Mention Detection: Heuristics for the OntoNotes annotations},
  author    = {Kummerfeld, Jonathan K. and Bansal, Mohit and Burkett, David and Klein, Dan},
  booktitle = {Proceedings of the Fifteenth Conference on Computational Natural Language Learning: Shared Task},
  year      = {2011},
  pages     = {102--106},
  month     = {June},
  location  = {Portland, Oregon, USA},
  url       = {https://aclanthology.org/W11-1916.pdf},
  poster    = {https://www.jkk.name/pub/conll11coreference_poster.pdf},
}
        </pre>
        
        </p>
    </div>
  </div>
</div>


<h3 id="2010">2010</h3>
<div class="container pb-2">
  <div class="row">
    <div class="col-lg-6">
      <strong>Faster Parsing by Supertagger Adaptation</strong>
      <br />
      <span class="text-muted">Jonathan K. Kummerfeld, Jessika Roesner, Tim Dawborn, James Haggerty, James R. Curran, Stephen Clark</span>
      <br />
      ACL<span class="text-muted">, 2010</span>
    </div>
    <div class="col-lg-6">
      <a class="btn btn-outline-primary btn-sm" href="https://aclanthology.org/P10-1036.pdf" target="_blank" rel="noopener"><span
    class="fontawesome-inline-svg"
    style="display: inline-flex; align-self: center; height:1em; width:1em; top: .125em; position: relative;"
><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path fill='currentColor' d="M256 0v128h128L256 0zM224 128L224 0H48C21.49 0 0 21.49 0 48v416C0 490.5 21.49 512 48 512h288c26.51 0 48-21.49 48-48V160h-127.1C238.3 160 224 145.7 224 128zM272 416h-160C103.2 416 96 408.8 96 400C96 391.2 103.2 384 112 384h160c8.836 0 16 7.162 16 16C288 408.8 280.8 416 272 416zM272 352h-160C103.2 352 96 344.8 96 336C96 327.2 103.2 320 112 320h160c8.836 0 16 7.162 16 16C288 344.8 280.8 352 272 352zM288 272C288 280.8 280.8 288 272 288h-160C103.2 288 96 280.8 96 272C96 263.2 103.2 256 112 256h160C280.8 256 288 263.2 288 272z"/></svg>
</span>
 PDF</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('acl10adapt-abstract').style.display == 'block') {
  document.getElementById('acl10adapt-abstract').style.display='none';
  } else {
  document.getElementById('acl10adapt-abstract').style.display='block';
  }
  ">Abstract</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('acl10adapt-cite').style.display == 'block') {
  document.getElementById('acl10adapt-cite').style.display='none';
  } else {
  document.getElementById('acl10adapt-cite').style.display='block';
  }
  ">BibTeX</a>
      
      
      
      
      <a class="btn btn-outline-primary btn-sm" href="http://downloads.schwa.org/acl10adapt_fast_news_model.tar.bz2" target="_blank" rel="noopener"><span
    class="fontawesome-inline-svg"
    style="display: inline-flex; align-self: center; height:1em; width:1em; top: .125em; position: relative;"
><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512"><path fill='currentColor' d="M414.8 40.79L286.8 488.8C281.9 505.8 264.2 515.6 247.2 510.8C230.2 505.9 220.4 488.2 225.2 471.2L353.2 23.21C358.1 6.216 375.8-3.624 392.8 1.232C409.8 6.087 419.6 23.8 414.8 40.79H414.8zM518.6 121.4L630.6 233.4C643.1 245.9 643.1 266.1 630.6 278.6L518.6 390.6C506.1 403.1 485.9 403.1 473.4 390.6C460.9 378.1 460.9 357.9 473.4 345.4L562.7 256L473.4 166.6C460.9 154.1 460.9 133.9 473.4 121.4C485.9 108.9 506.1 108.9 518.6 121.4V121.4zM166.6 166.6L77.25 256L166.6 345.4C179.1 357.9 179.1 378.1 166.6 390.6C154.1 403.1 133.9 403.1 121.4 390.6L9.372 278.6C-3.124 266.1-3.124 245.9 9.372 233.4L121.4 121.4C133.9 108.9 154.1 108.9 166.6 121.4C179.1 133.9 179.1 154.1 166.6 166.6V166.6z"/></svg>
</span>
 Software</a>
      
      
      
      
    </div>
  </div>
  <div class="row" id="acl10adapt-abstract" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          We propose a novel self-training method for a parser which uses a lexicalised grammar and supertagger, focusing on increasing the speed of the parser rather than its accuracy. The idea is to train the supertagger on large amounts of parser output, so that the supertagger can learn to supply the supertags that the parser will eventually choose as part of the highest scoring derivation. Since the supertagger supplies fewer supertags overall, the parsing speed is increased. We demonstrate the effectiveness of the method using a CCG supertagger and parser, obtaining significant speed increases on newspaper text with no loss in accuracy. We also show that the method can be used to adapt the CCG parser to new domains, obtaining accuracy and speed improvements for Wikipedia and biomedical text.
        </p>
    </div>
  </div>
  <div class="row" id="acl10adapt-cite" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          
        <pre>
        @InProceedings{acl10adapt,
  title     = {Faster Parsing by Supertagger Adaptation},
  author    = {Kummerfeld, Jonathan K. and Roesner, Jessika and Dawborn, Tim and Haggerty, James and Curran, James R. and Clark, Stephen},
  booktitle = {Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics},
  month     = {July},
  year      = {2010},
  location  = {Uppsala, Sweden},
  pages     = {345--355},
  software  = {http://downloads.schwa.org/acl10adapt_fast_news_model.tar.bz2},
  slidespdf = {https://www.jkk.name/pub/acl10adapt_slides.pdf},
  url       = {https://aclanthology.org/P10-1036.pdf},
}
        </pre>
        
        </p>
    </div>
  </div>
</div>


<div class="container pb-2">
  <div class="row">
    <div class="col-lg-6">
      <strong>Spatiotemporal Hierarchy of Relaxation Events, Dynamical Heterogeneities, and Structural Reorganization in a Supercooled Liquid</strong>
      <br />
      <span class="text-muted">Raphael Candelier, Asaph Widmer-Cooper, Jonathan K. Kummerfeld, Olivier Dauchot, Giulio Biroli, Peter Harrowell, David R. Reichman</span>
      <br />
      Physical Review Letters<span class="text-muted">, 2010</span>
    </div>
    <div class="col-lg-6">
      <a class="btn btn-outline-primary btn-sm" href="http://prl.aps.org/abstract/PRL/v105/i13/e135702" target="_blank" rel="noopener"><span
    class="fontawesome-inline-svg"
    style="display: inline-flex; align-self: center; height:1em; width:1em; top: .125em; position: relative;"
><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path fill='currentColor' d="M256 0v128h128L256 0zM224 128L224 0H48C21.49 0 0 21.49 0 48v416C0 490.5 21.49 512 48 512h288c26.51 0 48-21.49 48-48V160h-127.1C238.3 160 224 145.7 224 128zM272 416h-160C103.2 416 96 408.8 96 400C96 391.2 103.2 384 112 384h160c8.836 0 16 7.162 16 16C288 408.8 280.8 416 272 416zM272 352h-160C103.2 352 96 344.8 96 336C96 327.2 103.2 320 112 320h160c8.836 0 16 7.162 16 16C288 344.8 280.8 352 272 352zM288 272C288 280.8 280.8 288 272 288h-160C103.2 288 96 280.8 96 272C96 263.2 103.2 256 112 256h160C280.8 256 288 263.2 288 272z"/></svg>
</span>
 PDF</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('prl10chemistry-abstract').style.display == 'block') {
  document.getElementById('prl10chemistry-abstract').style.display='none';
  } else {
  document.getElementById('prl10chemistry-abstract').style.display='block';
  }
  ">Abstract</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('prl10chemistry-cite').style.display == 'block') {
  document.getElementById('prl10chemistry-cite').style.display='none';
  } else {
  document.getElementById('prl10chemistry-cite').style.display='block';
  }
  ">BibTeX</a>
      
      
      
      
      
      
      
    </div>
  </div>
  <div class="row" id="prl10chemistry-abstract" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          We identify the pattern of microscopic dynamical relaxation for a two-dimensional glass-forming liquid. On short time scales, bursts of irreversible particle motion, called cage jumps, aggregate into clusters. On larger time scales, clusters aggregate both spatially and temporally into avalanches. This propagation of mobility takes place along the soft regions of the systems, which have been identified by computing isoconfigurational Debye-Waller maps. Our results characterize the way in which dynamical heterogeneity evolves in moderately supercooled liquids and reveal that it is astonishingly similar to the one found for dense glassy granular media.
        </p>
    </div>
  </div>
  <div class="row" id="prl10chemistry-cite" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          
        <pre>
        @Article{prl10chemistry,
  title     = {Spatiotemporal Hierarchy of Relaxation Events, Dynamical Heterogeneities, and Structural Reorganization in a Supercooled Liquid},
  author    = {Candelier, Raphael and Widmer-Cooper, Asaph and Kummerfeld, Jonathan K. and Dauchot, Olivier and Biroli, Giulio and Harrowell, Peter and Reichman, David R.},
  journal   = {Physical Review Letters},
  volume    = {105},
  number    = {13},
  pages     = {135702},
  doi       = {10.1103/PhysRevLett.105.135702},
  numpages  = {4},
  year      = {2010},
  month     = {September},
  publisher = {American Physical Society},
  url       = {http://prl.aps.org/abstract/PRL/v105/i13/e135702},
  arxiv     = {https://arxiv.org/abs/0912.0193},
}
        </pre>
        
        </p>
    </div>
  </div>
</div>


<div class="container pb-2">
  <div class="row">
    <div class="col-lg-6">
      <strong>Morphological Analysis Can Improve a CCG Parser for English</strong>
      <br />
      <span class="text-muted">Matthew Honnibal, Jonathan K. Kummerfeld, James R. Curran</span>
      <br />
      CoLing<span class="text-muted">, 2010</span>
    </div>
    <div class="col-lg-6">
      <a class="btn btn-outline-primary btn-sm" href="https://aclanthology.org/C10-2051.pdf" target="_blank" rel="noopener"><span
    class="fontawesome-inline-svg"
    style="display: inline-flex; align-self: center; height:1em; width:1em; top: .125em; position: relative;"
><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path fill='currentColor' d="M256 0v128h128L256 0zM224 128L224 0H48C21.49 0 0 21.49 0 48v416C0 490.5 21.49 512 48 512h288c26.51 0 48-21.49 48-48V160h-127.1C238.3 160 224 145.7 224 128zM272 416h-160C103.2 416 96 408.8 96 400C96 391.2 103.2 384 112 384h160c8.836 0 16 7.162 16 16C288 408.8 280.8 416 272 416zM272 352h-160C103.2 352 96 344.8 96 336C96 327.2 103.2 320 112 320h160c8.836 0 16 7.162 16 16C288 344.8 280.8 352 272 352zM288 272C288 280.8 280.8 288 272 288h-160C103.2 288 96 280.8 96 272C96 263.2 103.2 256 112 256h160C280.8 256 288 263.2 288 272z"/></svg>
</span>
 PDF</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('coling10morph-abstract').style.display == 'block') {
  document.getElementById('coling10morph-abstract').style.display='none';
  } else {
  document.getElementById('coling10morph-abstract').style.display='block';
  }
  ">Abstract</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('coling10morph-cite').style.display == 'block') {
  document.getElementById('coling10morph-cite').style.display='none';
  } else {
  document.getElementById('coling10morph-cite').style.display='block';
  }
  ">BibTeX</a>
      
      
      
      
      
      
      
    </div>
  </div>
  <div class="row" id="coling10morph-abstract" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          Because English is a low morphology language, current statistical parsers tend to ignore morphology and accept some level of redundancy. This paper investigates how costly such redundancy is for a lexicalised grammar such as CCG.\n\nWe use morphological analysis to split verb inflectional suffixes into separate tokens, so that they can receive their own lexical categories. We find that this improves accuracy when the splits are based on correct POS tags, but that errors in gold standard or automatically assigned POS tags are costly for the system. This shows that the parser can benefit from morphological analysis, so long as the analysis is correct.
        </p>
    </div>
  </div>
  <div class="row" id="coling10morph-cite" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          
        <pre>
        @InProceedings{coling10morph,
  title     = {Morphological Analysis Can Improve a CCG Parser for English},
  author    = {Honnibal, Matthew and Kummerfeld, Jonathan K. and Curran, James R.},
  booktitle = {Proceedings of the 23rd International Conference on Computational Linguistics},
  year      = {2010},
  pages     = {445--453},
  location  = {Beijing, China},
  month     = {August},
  url       = {https://aclanthology.org/C10-2051.pdf},

We use morphological analysis to split verb inflectional suffixes into separate tokens, so that they can receive their own lexical categories. We find that this improves accuracy when the splits are based on correct POS tags, but that errors in gold standard or automatically assigned POS tags are costly for the system. This shows that the parser can benefit from morphological analysis, so long as the analysis is correct.},
}
        </pre>
        
        </p>
    </div>
  </div>
</div>


<h3 id="2009">2009</h3>
<div class="container pb-2">
  <div class="row">
    <div class="col-lg-6">
      <strong>Adaptive Supertagging for Faster Parsing</strong>
      <br />
      <span class="text-muted">Jonathan K. Kummerfeld</span>
      <br />
      The University of Sydney<span class="text-muted">, 2009</span>
    </div>
    <div class="col-lg-6">
      <a class="btn btn-outline-primary btn-sm" href="https://www.jkk.name/pub/thesis09adapt_thesis.pdf" target="_blank" rel="noopener"><span
    class="fontawesome-inline-svg"
    style="display: inline-flex; align-self: center; height:1em; width:1em; top: .125em; position: relative;"
><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path fill='currentColor' d="M256 0v128h128L256 0zM224 128L224 0H48C21.49 0 0 21.49 0 48v416C0 490.5 21.49 512 48 512h288c26.51 0 48-21.49 48-48V160h-127.1C238.3 160 224 145.7 224 128zM272 416h-160C103.2 416 96 408.8 96 400C96 391.2 103.2 384 112 384h160c8.836 0 16 7.162 16 16C288 408.8 280.8 416 272 416zM272 352h-160C103.2 352 96 344.8 96 336C96 327.2 103.2 320 112 320h160c8.836 0 16 7.162 16 16C288 344.8 280.8 352 272 352zM288 272C288 280.8 280.8 288 272 288h-160C103.2 288 96 280.8 96 272C96 263.2 103.2 256 112 256h160C280.8 256 288 263.2 288 272z"/></svg>
</span>
 PDF</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('thesis09adapt-abstract').style.display == 'block') {
  document.getElementById('thesis09adapt-abstract').style.display='none';
  } else {
  document.getElementById('thesis09adapt-abstract').style.display='block';
  }
  ">Abstract</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('thesis09adapt-cite').style.display == 'block') {
  document.getElementById('thesis09adapt-cite').style.display='none';
  } else {
  document.getElementById('thesis09adapt-cite').style.display='block';
  }
  ">BibTeX</a>
      
      
      
      
      
      <a class="btn btn-outline-primary btn-sm" href="https://www.jkk.name/pub/thesis09adapt_poster.pdf" target="_blank" rel="noopener">Poster</a>
      
      
      
    </div>
  </div>
  <div class="row" id="thesis09adapt-abstract" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          Statistical parsers are crucial for tackling the grand challenges of Natural Language Processing. The most effective approaches to these tasks are data driven, but parsers are too slow to be effectively used on large data sets. State-of-the-art parsers generally cannot process more than one sentence a second, and the fastest cannot process more than fifty sentences a second. The situation is even worse when they are applied outside of the domain of their training data. The fastest systems have two components, a parser, which has time complexity O(n3) and a supertagger, which has linear time complexity. By shifting work from the parser to the supertagger we dramatically improve speed.\n\nThis work demonstrates several major novel ideas that improve parsing efficiency. The core idea is that the tags chosen by the parser are gold standard data for its supertagger. This leads to the second surprising conceptual development, that decreasing tagging accuracy can improve parsing performance. To demonstrate these ideas required extensive development of the C&amp;C supertagger, including imple- mentation of more efficient estimation algorithms and parallelisation of the training process. This was particularly challenging as the C&amp;C supertagger is a state-of-the-art high performance system designed with a focus on speed rather than flexibility.\n\nI was able to significantly improve performance on the standard evaluation corpus by using the parser to generate extremely large new resources for supertagger training. I have also shown that these methods provide significant benefits on another domain, Wikipedia text, without the cost of generating human annotated data sets. These parsing performance gains occur while supertagging accuracy decreases.\n\nDespite extensive use of supertaggers to improve parsing efficiency there has been no comprehensive study of the interaction between a supertagger and a parser. I present the first systematic exploration of the relationship, show the potential benefits of understanding it, and demonstrate a novel algorithm for optimising the parameters that define it.\n\nI have constructed models that process newspaper text 86% faster than previously, and Wikipedia text 30% faster, without any loss in accuracy and without the aid of extra gold standard resources in either domain. This work will lead directly to improvements in a range of Natural Language Processing tasks by enabling the use of far more parsed data.
        </p>
    </div>
  </div>
  <div class="row" id="thesis09adapt-cite" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          
        <pre>
        @PhDThesis{thesis09adapt,
  title     = {Adaptive Supertagging for Faster Parsing},
  author    = {Kummerfeld, Jonathan K.},
  school    = {The University of Sydney},
  year      = {2009},
  location  = {Sydney, Australia},
  url       = {https://www.jkk.name/pub/thesis09adapt_thesis.pdf},
  poster    = {https://www.jkk.name/pub/thesis09adapt_poster.pdf},
  slidespdf = {https://www.jkk.name/pub/thesis09adapt_slides.pdf},

  This work demonstrates several major novel ideas that improve parsing efficiency. The core idea is that the tags chosen by the parser are gold standard data for its supertagger. This leads to the second surprising conceptual development, that decreasing tagging accuracy can improve parsing performance. To demonstrate these ideas required extensive development of the C&C supertagger, including imple- mentation of more efficient estimation algorithms and parallelisation of the training process. This was particularly challenging as the C&C supertagger is a state-of-the-art high performance system designed with a focus on speed rather than flexibility.

  I was able to significantly improve performance on the standard evaluation corpus by using the parser to generate extremely large new resources for supertagger training. I have also shown that these methods provide significant benefits on another domain, Wikipedia text, without the cost of generating human annotated data sets. These parsing performance gains occur while supertagging accuracy decreases.

  Despite extensive use of supertaggers to improve parsing efficiency there has been no comprehensive study of the interaction between a supertagger and a parser. I present the first systematic exploration of the relationship, show the potential benefits of understanding it, and demonstrate a novel algorithm for optimising the parameters that define it.

  I have constructed models that process newspaper text 86% faster than previously, and Wikipedia text 30% faster, without any loss in accuracy and without the aid of extra gold standard resources in either domain. This work will lead directly to improvements in a range of Natural Language Processing tasks by enabling the use of far more parsed data.},
}
        </pre>
        
        </p>
    </div>
  </div>
</div>


<div class="container pb-2">
  <div class="row">
    <div class="col-lg-6">
      <strong>Faster parsing and supertagging model estimation</strong>
      <br />
      <span class="text-muted">Jonathan K. Kummerfeld, Jessika Roesner, James R. Curran</span>
      <br />
      ALTA<span class="text-muted">, 2009</span>
    </div>
    <div class="col-lg-6">
      <a class="btn btn-outline-primary btn-sm" href="https://aclanthology.org/U09-1009.pdf" target="_blank" rel="noopener"><span
    class="fontawesome-inline-svg"
    style="display: inline-flex; align-self: center; height:1em; width:1em; top: .125em; position: relative;"
><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path fill='currentColor' d="M256 0v128h128L256 0zM224 128L224 0H48C21.49 0 0 21.49 0 48v416C0 490.5 21.49 512 48 512h288c26.51 0 48-21.49 48-48V160h-127.1C238.3 160 224 145.7 224 128zM272 416h-160C103.2 416 96 408.8 96 400C96 391.2 103.2 384 112 384h160c8.836 0 16 7.162 16 16C288 408.8 280.8 416 272 416zM272 352h-160C103.2 352 96 344.8 96 336C96 327.2 103.2 320 112 320h160c8.836 0 16 7.162 16 16C288 344.8 280.8 352 272 352zM288 272C288 280.8 280.8 288 272 288h-160C103.2 288 96 280.8 96 272C96 263.2 103.2 256 112 256h160C280.8 256 288 263.2 288 272z"/></svg>
</span>
 PDF</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('alta09tagging-abstract').style.display == 'block') {
  document.getElementById('alta09tagging-abstract').style.display='none';
  } else {
  document.getElementById('alta09tagging-abstract').style.display='block';
  }
  ">Abstract</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('alta09tagging-cite').style.display == 'block') {
  document.getElementById('alta09tagging-cite').style.display='none';
  } else {
  document.getElementById('alta09tagging-cite').style.display='block';
  }
  ">BibTeX</a>
      
      
      
      
      
      
      
    </div>
  </div>
  <div class="row" id="alta09tagging-abstract" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          Parsers are often the bottleneck for data acquisition, processing text too slowly to be widely applied. One way to improve the efficiency of parsers is to construct more confident statistical models. More training data would enable the use of more sophisticated features and also provide more evidence for current features, but gold standard annotated data is limited and expensive to produce.\n\nWe demonstrate faster methods for training a supertagger using hundreds of millions of automatically annotated words, constructing statistical models that further constrain the number of derivations the parser must consider. By introducing new features and using an automatically annotated corpus we are able to double parsing speed on Wikipedia and the Wall Street Journal, and gain accuracy slightly when parsing Section 00 of the Wall Street Journal.
        </p>
    </div>
  </div>
  <div class="row" id="alta09tagging-cite" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          
        <pre>
        @InProceedings{alta09tagging,
  title     = {Faster parsing and supertagging model estimation},
  author    = {Kummerfeld, Jonathan K. and Roesner, Jessika and Curran, James R.},
  booktitle = {Proceedings of the Australasian Language Technology Association Workshop 2009},
  year      = {2009},
  pages     = {62--70},
  location  = {Sydney, Australia},
  month     = {December},
  url       = {https://aclanthology.org/U09-1009.pdf},
  slidespdf = {https://www.jkk.name/pub/alta09tagging_slides.pdf},

We demonstrate faster methods for training a supertagger using hundreds of millions of automatically annotated words, constructing statistical models that further constrain the number of derivations the parser must consider. By introducing new features and using an automatically annotated corpus we are able to double parsing speed on Wikipedia and the Wall Street Journal, and gain accuracy slightly when parsing Section 00 of the Wall Street Journal.},
}
        </pre>
        
        </p>
    </div>
  </div>
</div>


<h3 id="2008">2008</h3>
<div class="container pb-2">
  <div class="row">
    <div class="col-lg-6">
      <strong>The densest packing of AB binary hard-sphere homogeneous compounds across all size ratios</strong>
      <br />
      <span class="text-muted">Jonathan K. Kummerfeld, Toby S Hudson, Peter Harrowell</span>
      <br />
      The Journal of Physical Chemistry B<span class="text-muted">, 2008</span>
    </div>
    <div class="col-lg-6">
      <a class="btn btn-outline-primary btn-sm" href="http://pubs.acs.org/doi/abs/10.1021/jp804953r" target="_blank" rel="noopener"><span
    class="fontawesome-inline-svg"
    style="display: inline-flex; align-self: center; height:1em; width:1em; top: .125em; position: relative;"
><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path fill='currentColor' d="M256 0v128h128L256 0zM224 128L224 0H48C21.49 0 0 21.49 0 48v416C0 490.5 21.49 512 48 512h288c26.51 0 48-21.49 48-48V160h-127.1C238.3 160 224 145.7 224 128zM272 416h-160C103.2 416 96 408.8 96 400C96 391.2 103.2 384 112 384h160c8.836 0 16 7.162 16 16C288 408.8 280.8 416 272 416zM272 352h-160C103.2 352 96 344.8 96 336C96 327.2 103.2 320 112 320h160c8.836 0 16 7.162 16 16C288 344.8 280.8 352 272 352zM288 272C288 280.8 280.8 288 272 288h-160C103.2 288 96 280.8 96 272C96 263.2 103.2 256 112 256h160C280.8 256 288 263.2 288 272z"/></svg>
</span>
 PDF</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('chem08packing-abstract').style.display == 'block') {
  document.getElementById('chem08packing-abstract').style.display='none';
  } else {
  document.getElementById('chem08packing-abstract').style.display='block';
  }
  ">Abstract</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('chem08packing-cite').style.display == 'block') {
  document.getElementById('chem08packing-cite').style.display='none';
  } else {
  document.getElementById('chem08packing-cite').style.display='block';
  }
  ">BibTeX</a>
      
      
      
      
      
      
      
    </div>
  </div>
  <div class="row" id="chem08packing-abstract" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          This paper considers the homogeneous packing of binary hard spheres in an equimolar stoichiometry, and postulates the densest packing at each sphere size ratio. Monte Carlo simulated annealing optimizations are seeded with all known atomic inorganic crystal structures, and the search is performed within the degrees of freedom associated with each homogeneous AB structure type. Structures isopointal to the FeB structure type are found to have the highest packing fraction at all sphere size ratios. The optimized structures match or improve on the best previously demonstrated packings of this type, and show that compound structures can pack more densely than segregated close-packed structures at all radius ratios less than 0.62.
        </p>
    </div>
  </div>
  <div class="row" id="chem08packing-cite" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          
        <pre>
        @Article{chem08packing,
  title     = {The densest packing of AB binary hard-sphere homogeneous compounds across all size ratios},
  author    = {Kummerfeld, Jonathan K. and Hudson, Toby S and Harrowell, Peter},
  journal   = {The Journal of Physical Chemistry B},
  month     = {August},
  year      = {2008},
  volume    = {112},
  issue     = {35},
  pages     = {10773--10776},
  url       = {http://pubs.acs.org/doi/abs/10.1021/jp804953r},
}
        </pre>
        
        </p>
    </div>
  </div>
</div>


<div class="container pb-2">
  <div class="row">
    <div class="col-lg-6">
      <strong>Classification of Verb Particle Constructions with the Google Web1T Corpus</strong>
      <br />
      <span class="text-muted">Jonathan K. Kummerfeld, James R. Curran</span>
      <br />
      ALTA<span class="text-muted">, 2008</span>
    </div>
    <div class="col-lg-6">
      <a class="btn btn-outline-primary btn-sm" href="https://aclanthology.org/U08-1008.pdf" target="_blank" rel="noopener"><span
    class="fontawesome-inline-svg"
    style="display: inline-flex; align-self: center; height:1em; width:1em; top: .125em; position: relative;"
><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path fill='currentColor' d="M256 0v128h128L256 0zM224 128L224 0H48C21.49 0 0 21.49 0 48v416C0 490.5 21.49 512 48 512h288c26.51 0 48-21.49 48-48V160h-127.1C238.3 160 224 145.7 224 128zM272 416h-160C103.2 416 96 408.8 96 400C96 391.2 103.2 384 112 384h160c8.836 0 16 7.162 16 16C288 408.8 280.8 416 272 416zM272 352h-160C103.2 352 96 344.8 96 336C96 327.2 103.2 320 112 320h160c8.836 0 16 7.162 16 16C288 344.8 280.8 352 272 352zM288 272C288 280.8 280.8 288 272 288h-160C103.2 288 96 280.8 96 272C96 263.2 103.2 256 112 256h160C280.8 256 288 263.2 288 272z"/></svg>
</span>
 PDF</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('alta08vpc-abstract').style.display == 'block') {
  document.getElementById('alta08vpc-abstract').style.display='none';
  } else {
  document.getElementById('alta08vpc-abstract').style.display='block';
  }
  ">Abstract</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('alta08vpc-cite').style.display == 'block') {
  document.getElementById('alta08vpc-cite').style.display='none';
  } else {
  document.getElementById('alta08vpc-cite').style.display='block';
  }
  ">BibTeX</a>
      
      
      
      
      
      <a class="btn btn-outline-primary btn-sm" href="https://www.jkk.name/pub/alta08vpc_poster.eps" target="_blank" rel="noopener">Poster</a>
      
      
      
    </div>
  </div>
  <div class="row" id="alta08vpc-abstract" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          Manually maintaining comprehensive databases of multi-word expressions, for example Verb-Particle Constructions (VPCs), is infeasible. We describe a new classifier for potential VPCs, which uses information in the Google Web1T corpus to perform a simple linguistic constituency test. Specifically, we consider the fronting test, comparing the frequencies of the two possible orderings of the given verb and particle. Using only a small set of queries for each verb-particle pair, the system was able to achieve an F-score of 78.4% in our evaluation while processing thousands of queries a second.
        </p>
    </div>
  </div>
  <div class="row" id="alta08vpc-cite" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          
        <pre>
        @InProceedings{alta08vpc,
  title     = {Classification of Verb Particle Constructions with the Google Web1T Corpus},
  author    = {Kummerfeld, Jonathan K. and Curran, James R.},
  booktitle = {Proceedings of the Australasian Language Technology Association Workshop 2008},
  month     = {December},
  year      = {2008},
  location  = {Hobart, Australia},
  pages     = {55--63},
  volume    = {6},
  url       = {https://aclanthology.org/U08-1008.pdf},
  poster    = {https://www.jkk.name/pub/alta08vpc_poster.eps},
}
        </pre>
        
        </p>
    </div>
  </div>
</div>


<h2 id="non-archival">Non-Archival</h2>
<h3 id="2024-1">2024</h3>
<div class="container pb-2">
  <div class="row">
    <div class="col-lg-6">
      <strong>A Mechanistic Understanding of Alignment Algorithms: A Case Study on DPO and Toxicity</strong>
      <br />
      <span class="text-muted">Andrew Lee, Xiaoyan Bai, Itamar Pres, Martin Wattenberg, Jonathan K. Kummerfeld, Rada Mihalcea</span>
      <br />
      arXiv<span class="text-muted">, 2024</span>
    </div>
    <div class="col-lg-6">
      <a class="btn btn-outline-primary btn-sm" href="https://arxiv.org/abs/2401.01967" target="_blank" rel="noopener"><span
    class="fontawesome-inline-svg"
    style="display: inline-flex; align-self: center; height:1em; width:1em; top: .125em; position: relative;"
><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path fill='currentColor' d="M256 0v128h128L256 0zM224 128L224 0H48C21.49 0 0 21.49 0 48v416C0 490.5 21.49 512 48 512h288c26.51 0 48-21.49 48-48V160h-127.1C238.3 160 224 145.7 224 128zM272 416h-160C103.2 416 96 408.8 96 400C96 391.2 103.2 384 112 384h160c8.836 0 16 7.162 16 16C288 408.8 280.8 416 272 416zM272 352h-160C103.2 352 96 344.8 96 336C96 327.2 103.2 320 112 320h160c8.836 0 16 7.162 16 16C288 344.8 280.8 352 272 352zM288 272C288 280.8 280.8 288 272 288h-160C103.2 288 96 280.8 96 272C96 263.2 103.2 256 112 256h160C280.8 256 288 263.2 288 272z"/></svg>
</span>
 PDF</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('arxiv24mechanistic-abstract').style.display == 'block') {
  document.getElementById('arxiv24mechanistic-abstract').style.display='none';
  } else {
  document.getElementById('arxiv24mechanistic-abstract').style.display='block';
  }
  ">Abstract</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('arxiv24mechanistic-cite').style.display == 'block') {
  document.getElementById('arxiv24mechanistic-cite').style.display='none';
  } else {
  document.getElementById('arxiv24mechanistic-cite').style.display='block';
  }
  ">BibTeX</a>
      
      
      
      
      
      
      
    </div>
  </div>
  <div class="row" id="arxiv24mechanistic-abstract" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          While alignment algorithms are now commonly used to tune pre-trained language models towards a user&#39;s preferences, we lack explanations for the underlying mechanisms in which models become ``aligned&#39;&#39;, thus making it difficult to explain phenomena like jailbreaks. In this work we study a popular algorithm, direct preference optimization (DPO), and the mechanisms by which it reduces toxicity. Namely, we first study how toxicity is represented and elicited in a pre-trained language model, GPT2-medium. We then apply DPO with a carefully crafted pairwise dataset to reduce toxicity. We examine how the resulting model averts toxic outputs, and find that capabilities learned from pre-training are not removed, but rather bypassed. We use this insight to demonstrate a simple method to un-align the model, reverting it back to its toxic behavior.
        </p>
    </div>
  </div>
  <div class="row" id="arxiv24mechanistic-cite" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          
        <pre>
        @Article{arxiv24mechanistic,
  author    = {Andrew Lee and Xiaoyan Bai and Itamar Pres and Martin Wattenberg and Jonathan K. Kummerfeld and Rada Mihalcea},
  title     = {A Mechanistic Understanding of Alignment Algorithms: A Case Study on DPO and Toxicity},
  journal   = {arXiv},
  month     = {January},
  year      = {2024},
  arxiv     = {https://arxiv.org/abs/2401.01967},
  data      = {},
}
        </pre>
        
        </p>
    </div>
  </div>
</div>


<h3 id="2022-1">2022</h3>
<div class="container pb-2">
  <div class="row">
    <div class="col-lg-6">
      <strong>Sensemaking Interfaces for Human Evaluation of Language Model Outputs</strong>
      <br />
      <span class="text-muted">Katy Gero, Jonathan K. Kummerfeld, Elena Glassman</span>
      <br />
      NeurIPS Workshop: Human Evaluation of Generative Models<span class="text-muted">, 2022</span>
    </div>
    <div class="col-lg-6">
      <a class="btn btn-outline-primary btn-sm" href="https://www.jkk.name/pub/ws23sensemaking.pdf" target="_blank" rel="noopener"><span
    class="fontawesome-inline-svg"
    style="display: inline-flex; align-self: center; height:1em; width:1em; top: .125em; position: relative;"
><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path fill='currentColor' d="M256 0v128h128L256 0zM224 128L224 0H48C21.49 0 0 21.49 0 48v416C0 490.5 21.49 512 48 512h288c26.51 0 48-21.49 48-48V160h-127.1C238.3 160 224 145.7 224 128zM272 416h-160C103.2 416 96 408.8 96 400C96 391.2 103.2 384 112 384h160c8.836 0 16 7.162 16 16C288 408.8 280.8 416 272 416zM272 352h-160C103.2 352 96 344.8 96 336C96 327.2 103.2 320 112 320h160c8.836 0 16 7.162 16 16C288 344.8 280.8 352 272 352zM288 272C288 280.8 280.8 288 272 288h-160C103.2 288 96 280.8 96 272C96 263.2 103.2 256 112 256h160C280.8 256 288 263.2 288 272z"/></svg>
</span>
 PDF</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('ws-neurips-hegm22lm-abstract').style.display == 'block') {
  document.getElementById('ws-neurips-hegm22lm-abstract').style.display='none';
  } else {
  document.getElementById('ws-neurips-hegm22lm-abstract').style.display='block';
  }
  ">Abstract</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('ws-neurips-hegm22lm-cite').style.display == 'block') {
  document.getElementById('ws-neurips-hegm22lm-cite').style.display='none';
  } else {
  document.getElementById('ws-neurips-hegm22lm-cite').style.display='block';
  }
  ">BibTeX</a>
      
      
      
      
      
      
      
    </div>
  </div>
  <div class="row" id="ws-neurips-hegm22lm-abstract" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          Ensuring a language model doesn&#39;t generate problematic text is difficult. Traditional evaluation methods, like automatic measures or human annotation, can fail to detect all problems, whether because system designers were not aware of a kind of problem they should attempt to detect, or because an automatic measure fails to reliably detect certain kinds of problems. In this paper we propose sensemaking tools as a robust and open-ended method to evaluate the large number of linguistic outputs produced by a language model. We demonstrate one potential sensemaking interface based on concordance tables, showing that we are able to detect problematic outputs and distributional shifts in minutes, despite not knowing exactly what kind of problems to look for. 
        </p>
    </div>
  </div>
  <div class="row" id="ws-neurips-hegm22lm-cite" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          
        <pre>
        @InProceedings{ws-neurips-hegm22lm,
  title     = {Sensemaking Interfaces for Human Evaluation of Language Model Outputs},
  author    = {Katy Gero and Jonathan K. Kummerfeld and Elena Glassman},
  year      = {2022},
  booktitle = {NeurIPS Workshop: Human Evaluation of Generative Models},
  month     = {December},
  url       = {https://www.jkk.name/pub/ws23sensemaking.pdf},
}
        </pre>
        
        </p>
    </div>
  </div>
</div>


<h3 id="2020-1">2020</h3>
<div class="container pb-2">
  <div class="row">
    <div class="col-lg-6">
      <strong>NOESIS II: Predicting Responses, Identifying Success, and Managing Complexity in Task-Oriented Dialogue</strong>
      <br />
      <span class="text-muted">Chulaka Gunasekara, Jonathan K. Kummerfeld, Luis Lastras, Walter S. Lasecki</span>
      <br />
      AAAI Wokshop: Dialogue System Technology Challenges<span class="text-muted">, 2020</span>
    </div>
    <div class="col-lg-6">
      <a class="btn btn-outline-primary btn-sm" href="https://www.jkk.name/pub/dstc20task2.pdf" target="_blank" rel="noopener"><span
    class="fontawesome-inline-svg"
    style="display: inline-flex; align-self: center; height:1em; width:1em; top: .125em; position: relative;"
><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path fill='currentColor' d="M256 0v128h128L256 0zM224 128L224 0H48C21.49 0 0 21.49 0 48v416C0 490.5 21.49 512 48 512h288c26.51 0 48-21.49 48-48V160h-127.1C238.3 160 224 145.7 224 128zM272 416h-160C103.2 416 96 408.8 96 400C96 391.2 103.2 384 112 384h160c8.836 0 16 7.162 16 16C288 408.8 280.8 416 272 416zM272 352h-160C103.2 352 96 344.8 96 336C96 327.2 103.2 320 112 320h160c8.836 0 16 7.162 16 16C288 344.8 280.8 352 272 352zM288 272C288 280.8 280.8 288 272 288h-160C103.2 288 96 280.8 96 272C96 263.2 103.2 256 112 256h160C280.8 256 288 263.2 288 272z"/></svg>
</span>
 PDF</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('ws-aaai-dstc20task2-abstract').style.display == 'block') {
  document.getElementById('ws-aaai-dstc20task2-abstract').style.display='none';
  } else {
  document.getElementById('ws-aaai-dstc20task2-abstract').style.display='block';
  }
  ">Abstract</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('ws-aaai-dstc20task2-cite').style.display == 'block') {
  document.getElementById('ws-aaai-dstc20task2-cite').style.display='none';
  } else {
  document.getElementById('ws-aaai-dstc20task2-cite').style.display='block';
  }
  ">BibTeX</a>
      
      
      
      <a class="btn btn-outline-primary btn-sm" href="https://github.com/dstc8-track2/NOESIS-II/" target="_blank" rel="noopener"><span
    class="fontawesome-inline-svg"
    style="display: inline-flex; align-self: center; height:1em; width:1em; top: .125em; position: relative;"
><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill='currentColor' d="M448 80V128C448 172.2 347.7 208 224 208C100.3 208 0 172.2 0 128V80C0 35.82 100.3 0 224 0C347.7 0 448 35.82 448 80zM393.2 214.7C413.1 207.3 433.1 197.8 448 186.1V288C448 332.2 347.7 368 224 368C100.3 368 0 332.2 0 288V186.1C14.93 197.8 34.02 207.3 54.85 214.7C99.66 230.7 159.5 240 224 240C288.5 240 348.3 230.7 393.2 214.7V214.7zM54.85 374.7C99.66 390.7 159.5 400 224 400C288.5 400 348.3 390.7 393.2 374.7C413.1 367.3 433.1 357.8 448 346.1V432C448 476.2 347.7 512 224 512C100.3 512 0 476.2 0 432V346.1C14.93 357.8 34.02 367.3 54.85 374.7z"/></svg>
</span>
 Data</a>
      
      
      
      
      
    </div>
  </div>
  <div class="row" id="ws-aaai-dstc20task2-abstract" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          Real-world conversation often involves more than two participants and complex conversation structures, but most datasets for dialogue research simplify the task to make it more tractable. This shared task built on prior tasks for goal-oriented dialogue, moving towards more realistic settings. Seventeen teams participated in the primary task, predicting the next utterance in a multi-party conversation, and several teams participated in supplementary tasks. All of the datasets have been publicly released, providing a standard benchmark for future work in this space.
        </p>
    </div>
  </div>
  <div class="row" id="ws-aaai-dstc20task2-cite" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          
        <pre>
        @InProceedings{ws-aaai-dstc20task2,
  title     = {NOESIS II: Predicting Responses, Identifying Success, and Managing Complexity in Task-Oriented Dialogue},
  author    = {Gunasekara, Chulaka and Kummerfeld, Jonathan K. and Lastras, Luis and Lasecki, Walter S.},
  year      = {2020},
  booktitle = {8th Edition of the Dialog System Technology Challenges at AAAI 2019},
  month     = {January},
  url       = {https://www.jkk.name/pub/dstc20task2.pdf},
  data      = {https://github.com/dstc8-track2/NOESIS-II/},
}
        </pre>
        
        </p>
    </div>
  </div>
</div>


<div class="container pb-2">
  <div class="row">
    <div class="col-lg-6">
      <strong>Qualification Labour: A Fair Wage Isn&rsquo;t Enough if Workers Need to Do 5,000 Low Paid Tasks to Qualify for Your Task</strong>
      <br />
      <span class="text-muted">Jonathan K. Kummerfeld</span>
      <br />
      HComp (Work in Progress)<span class="text-muted">, 2020</span>
    </div>
    <div class="col-lg-6">
      <a class="btn btn-outline-primary btn-sm" href="https://www.jkk.name/pub/hcomp20fair.pdf" target="_blank" rel="noopener"><span
    class="fontawesome-inline-svg"
    style="display: inline-flex; align-self: center; height:1em; width:1em; top: .125em; position: relative;"
><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path fill='currentColor' d="M256 0v128h128L256 0zM224 128L224 0H48C21.49 0 0 21.49 0 48v416C0 490.5 21.49 512 48 512h288c26.51 0 48-21.49 48-48V160h-127.1C238.3 160 224 145.7 224 128zM272 416h-160C103.2 416 96 408.8 96 400C96 391.2 103.2 384 112 384h160c8.836 0 16 7.162 16 16C288 408.8 280.8 416 272 416zM272 352h-160C103.2 352 96 344.8 96 336C96 327.2 103.2 320 112 320h160c8.836 0 16 7.162 16 16C288 344.8 280.8 352 272 352zM288 272C288 280.8 280.8 288 272 288h-160C103.2 288 96 280.8 96 272C96 263.2 103.2 256 112 256h160C280.8 256 288 263.2 288 272z"/></svg>
</span>
 PDF</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('hcomp20fair-abstract').style.display == 'block') {
  document.getElementById('hcomp20fair-abstract').style.display='none';
  } else {
  document.getElementById('hcomp20fair-abstract').style.display='block';
  }
  ">Abstract</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('hcomp20fair-cite').style.display == 'block') {
  document.getElementById('hcomp20fair-cite').style.display='none';
  } else {
  document.getElementById('hcomp20fair-cite').style.display='block';
  }
  ">BibTeX</a>
      
      
      
      
      
      
      
    </div>
  </div>
  <div class="row" id="hcomp20fair-abstract" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          Extensive work has argued in favour of paying crowd workers a wage that is at least equivalent to the U.S.~federal minimum wage. Meanwhile, research on collecting high quality annotations (e.g.~for Natural Language Processing) suggests using qualifications such as a minimum number of previously completed tasks. If most requesters who pay fairly use this kind of minimum qualification, then workers may be forced to complete a substantial amount of poorly paid work for other requesters before they can earn a fair wage. This paper (1) explores current conventions for the threshold, (2) discusses possible alternatives, and (3) presents a study of correlation between approved work and work quality.
        </p>
    </div>
  </div>
  <div class="row" id="hcomp20fair-cite" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          
        <pre>
        @InProceedings{hcomp20fair,
  title     = {Qualification Labour: A Fair Wage Isn't Enough if Workers Need to Do 5,000 Low Paid Tasks to Qualify for Your Task},
  author    = {Kummerfeld, Jonathan K.},
  year      = {2020},
  month     = {October},
  booktitle = {The eighth AAAI Conference on Human Computation and Crowdsourcing},
  url       = {https://www.jkk.name/pub/hcomp20fair.pdf},
}
        </pre>
        
        </p>
    </div>
  </div>
</div>


<h3 id="2019-1">2019</h3>
<div class="container pb-2">
  <div class="row">
    <div class="col-lg-6">
      <strong>DSTC7 Task 1: Noetic End-to-End Response Selection</strong>
      <br />
      <span class="text-muted">Chulaka Gunasekara, Jonathan K. Kummerfeld, Lazaros Polymenakos, Walter S. Lasecki</span>
      <br />
      AAAI Wokshop: Dialogue System Technology Challenges<span class="text-muted">, 2019</span>
    </div>
    <div class="col-lg-6">
      <a class="btn btn-outline-primary btn-sm" href="https://www.jkk.name/pub/ws18dstc_task1.pdf" target="_blank" rel="noopener"><span
    class="fontawesome-inline-svg"
    style="display: inline-flex; align-self: center; height:1em; width:1em; top: .125em; position: relative;"
><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path fill='currentColor' d="M256 0v128h128L256 0zM224 128L224 0H48C21.49 0 0 21.49 0 48v416C0 490.5 21.49 512 48 512h288c26.51 0 48-21.49 48-48V160h-127.1C238.3 160 224 145.7 224 128zM272 416h-160C103.2 416 96 408.8 96 400C96 391.2 103.2 384 112 384h160c8.836 0 16 7.162 16 16C288 408.8 280.8 416 272 416zM272 352h-160C103.2 352 96 344.8 96 336C96 327.2 103.2 320 112 320h160c8.836 0 16 7.162 16 16C288 344.8 280.8 352 272 352zM288 272C288 280.8 280.8 288 272 288h-160C103.2 288 96 280.8 96 272C96 263.2 103.2 256 112 256h160C280.8 256 288 263.2 288 272z"/></svg>
</span>
 PDF</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('ws-aaai-dstc19task1-abstract').style.display == 'block') {
  document.getElementById('ws-aaai-dstc19task1-abstract').style.display='none';
  } else {
  document.getElementById('ws-aaai-dstc19task1-abstract').style.display='block';
  }
  ">Abstract</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('ws-aaai-dstc19task1-cite').style.display == 'block') {
  document.getElementById('ws-aaai-dstc19task1-cite').style.display='none';
  } else {
  document.getElementById('ws-aaai-dstc19task1-cite').style.display='block';
  }
  ">BibTeX</a>
      
      
      
      <a class="btn btn-outline-primary btn-sm" href="https://ibm.github.io/dstc-noesis/public/index.html" target="_blank" rel="noopener"><span
    class="fontawesome-inline-svg"
    style="display: inline-flex; align-self: center; height:1em; width:1em; top: .125em; position: relative;"
><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill='currentColor' d="M448 80V128C448 172.2 347.7 208 224 208C100.3 208 0 172.2 0 128V80C0 35.82 100.3 0 224 0C347.7 0 448 35.82 448 80zM393.2 214.7C413.1 207.3 433.1 197.8 448 186.1V288C448 332.2 347.7 368 224 368C100.3 368 0 332.2 0 288V186.1C14.93 197.8 34.02 207.3 54.85 214.7C99.66 230.7 159.5 240 224 240C288.5 240 348.3 230.7 393.2 214.7V214.7zM54.85 374.7C99.66 390.7 159.5 400 224 400C288.5 400 348.3 390.7 393.2 374.7C413.1 367.3 433.1 357.8 448 346.1V432C448 476.2 347.7 512 224 512C100.3 512 0 476.2 0 432V346.1C14.93 357.8 34.02 367.3 54.85 374.7z"/></svg>
</span>
 Data</a>
      
      
      
      
      
    </div>
  </div>
  <div class="row" id="ws-aaai-dstc19task1-abstract" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          Goal-oriented dialogue in complex domains is an extremely challenging problem and there are relatively few datasets. This task provided two new resources that presented different challenges: one was focused but small, while the other was large but diverse. We also considered several new variations on the next utterance selection problem: (1) increasing the number of candidates, (2) including paraphrases, and (3) not including a correct option in the candidate set. Twenty teams participated, developing a range of neural network models, including some that successfully incorporated external data to boost performance. Both datasets have been publicly released, enabling future work to build on these results, working towards robust goal-oriented dialogue systems.
        </p>
    </div>
  </div>
  <div class="row" id="ws-aaai-dstc19task1-cite" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          
        <pre>
        @InProceedings{ws-aaai-dstc19task1,
  title     = {DSTC7 Task 1: Noetic End-to-End Response Selection},
  author    = {Gunasekara, Chulaka and Kummerfeld, Jonathan K. and Polymenakos, Lazaros and Lasecki, Walter S.},
  year      = {2019},
  booktitle = {7th Edition of the Dialog System Technology Challenges at AAAI 2019},
  month     = {January},
  url       = {https://www.jkk.name/pub/ws18dstc_task1.pdf},
  alt-url   = {http://workshop.colips.org/dstc7/papers/dstc7_task1_final_report.pdf},
  data      = {https://ibm.github.io/dstc-noesis/public/index.html},
}
        </pre>
        
        </p>
    </div>
  </div>
</div>


<div class="container pb-2">
  <div class="row">
    <div class="col-lg-6">
      <strong>The Eighth Dialog System Technology Challenge</strong>
      <br />
      <span class="text-muted">Seokhwan Kim, Michel Galley, Chulaka Gunasekara, Sungjin Lee, Adam Atkinson, Baolin Peng, Hannes Schulz, Jianfeng Gao, Jinchao Li, Mahmoud Adada, Minlie Huang, Luis Lastras, Jonathan K. Kummerfeld, Walter S. Lasecki, Chiori Hori, Anoop Cherian, Tim K. Marks, Abhinav Rastogi, Xiaoxue Zang, Srinivas Sunkara, Raghav Gupta</span>
      <br />
      NeurIPS Workshop: Conversational AI: Today&#39;s Practice and Tomorrow&#39;s Potential<span class="text-muted">, 2019</span>
    </div>
    <div class="col-lg-6">
      <a class="btn btn-outline-primary btn-sm" href="https://arxiv.org/abs/1911.06394" target="_blank" rel="noopener"><span
    class="fontawesome-inline-svg"
    style="display: inline-flex; align-self: center; height:1em; width:1em; top: .125em; position: relative;"
><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path fill='currentColor' d="M256 0v128h128L256 0zM224 128L224 0H48C21.49 0 0 21.49 0 48v416C0 490.5 21.49 512 48 512h288c26.51 0 48-21.49 48-48V160h-127.1C238.3 160 224 145.7 224 128zM272 416h-160C103.2 416 96 408.8 96 400C96 391.2 103.2 384 112 384h160c8.836 0 16 7.162 16 16C288 408.8 280.8 416 272 416zM272 352h-160C103.2 352 96 344.8 96 336C96 327.2 103.2 320 112 320h160c8.836 0 16 7.162 16 16C288 344.8 280.8 352 272 352zM288 272C288 280.8 280.8 288 272 288h-160C103.2 288 96 280.8 96 272C96 263.2 103.2 256 112 256h160C280.8 256 288 263.2 288 272z"/></svg>
</span>
 PDF</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('ws-neurips-convai19dstc-abstract').style.display == 'block') {
  document.getElementById('ws-neurips-convai19dstc-abstract').style.display='none';
  } else {
  document.getElementById('ws-neurips-convai19dstc-abstract').style.display='block';
  }
  ">Abstract</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('ws-neurips-convai19dstc-cite').style.display == 'block') {
  document.getElementById('ws-neurips-convai19dstc-cite').style.display='none';
  } else {
  document.getElementById('ws-neurips-convai19dstc-cite').style.display='block';
  }
  ">BibTeX</a>
      
      
      
      <a class="btn btn-outline-primary btn-sm" href="https://github.com/dstc8-track2/NOESIS-II/" target="_blank" rel="noopener"><span
    class="fontawesome-inline-svg"
    style="display: inline-flex; align-self: center; height:1em; width:1em; top: .125em; position: relative;"
><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill='currentColor' d="M448 80V128C448 172.2 347.7 208 224 208C100.3 208 0 172.2 0 128V80C0 35.82 100.3 0 224 0C347.7 0 448 35.82 448 80zM393.2 214.7C413.1 207.3 433.1 197.8 448 186.1V288C448 332.2 347.7 368 224 368C100.3 368 0 332.2 0 288V186.1C14.93 197.8 34.02 207.3 54.85 214.7C99.66 230.7 159.5 240 224 240C288.5 240 348.3 230.7 393.2 214.7V214.7zM54.85 374.7C99.66 390.7 159.5 400 224 400C288.5 400 348.3 390.7 393.2 374.7C413.1 367.3 433.1 357.8 448 346.1V432C448 476.2 347.7 512 224 512C100.3 512 0 476.2 0 432V346.1C14.93 357.8 34.02 367.3 54.85 374.7z"/></svg>
</span>
 Data</a>
      
      
      
      
      
    </div>
  </div>
  <div class="row" id="ws-neurips-convai19dstc-abstract" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          This paper introduces the Eighth Dialog System Technology Challenge. In line with recent challenges, the eighth edition focuses on applying end-to-end dialog technologies in a pragmatic way for multi-domain task-completion, noetic response selection, audio visual scene-aware dialog, and schema-guided dialog state tracking tasks. This paper describes the task definition, provided datasets, and evaluation set-up for each track. We also summarize the results of the submitted systems to highlight the overall trends of the state-of-the-art technologies for the tasks.
        </p>
    </div>
  </div>
  <div class="row" id="ws-neurips-convai19dstc-cite" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          
        <pre>
        @InProceedings{ws-neurips-convai19dstc,
  title     = {The Eighth Dialog System Technology Challenge},
  author    = {Kim, Seokhwan and Galley, Michel and Gunasekara, Chulaka and Lee, Sungjin and Atkinson, Adam and Peng, Baolin and Schulz, Hannes and Gao, Jianfeng and Li, Jinchao and Adada, Mahmoud and Huang, Minlie and Lastras, Luis and Kummerfeld, Jonathan K. and Lasecki, Walter S. and Hori, Chiori and Cherian, Anoop and Marks, Tim K. and Rastogi, Abhinav and Zang, Xiaoxue and Sunkara, Srinivas and Gupta, Raghav},
  year      = {2019},
  booktitle = {NeurIPS Workshop: Conversational AI: Today's Practice and Tomorrow's Potential},
  url       = {https://arxiv.org/abs/1911.06394},
  location  = {Vancouver, Canada},
  month     = {December},
  arxiv     = {https://arxiv.org/abs/1911.06394},
  data      = {https://github.com/dstc8-track2/NOESIS-II/},
}
        </pre>
        
        </p>
    </div>
  </div>
</div>


<div class="container pb-2">
  <div class="row">
    <div class="col-lg-6">
      <strong>Training Data Voids: Novel Attacks Against NLP Content Moderation</strong>
      <br />
      <span class="text-muted">Jordan S. Huffaker, Jonathan K. Kummerfeld, Walter S. Lasecki, Mark S. Ackerman</span>
      <br />
      CSCW Workshop: Volunteer Work: Mapping the Future of Moderation Research<span class="text-muted">, 2019</span>
    </div>
    <div class="col-lg-6">
      <a class="btn btn-outline-primary btn-sm" href="https://www.jkk.name/pub/ws19voids.pdf" target="_blank" rel="noopener"><span
    class="fontawesome-inline-svg"
    style="display: inline-flex; align-self: center; height:1em; width:1em; top: .125em; position: relative;"
><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path fill='currentColor' d="M256 0v128h128L256 0zM224 128L224 0H48C21.49 0 0 21.49 0 48v416C0 490.5 21.49 512 48 512h288c26.51 0 48-21.49 48-48V160h-127.1C238.3 160 224 145.7 224 128zM272 416h-160C103.2 416 96 408.8 96 400C96 391.2 103.2 384 112 384h160c8.836 0 16 7.162 16 16C288 408.8 280.8 416 272 416zM272 352h-160C103.2 352 96 344.8 96 336C96 327.2 103.2 320 112 320h160c8.836 0 16 7.162 16 16C288 344.8 280.8 352 272 352zM288 272C288 280.8 280.8 288 272 288h-160C103.2 288 96 280.8 96 272C96 263.2 103.2 256 112 256h160C280.8 256 288 263.2 288 272z"/></svg>
</span>
 PDF</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('ws-cscw19voids-abstract').style.display == 'block') {
  document.getElementById('ws-cscw19voids-abstract').style.display='none';
  } else {
  document.getElementById('ws-cscw19voids-abstract').style.display='block';
  }
  ">Abstract</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('ws-cscw19voids-cite').style.display == 'block') {
  document.getElementById('ws-cscw19voids-cite').style.display='none';
  } else {
  document.getElementById('ws-cscw19voids-cite').style.display='block';
  }
  ">BibTeX</a>
      
      
      
      
      
      
      
    </div>
  </div>
  <div class="row" id="ws-cscw19voids-abstract" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          
        </p>
    </div>
  </div>
  <div class="row" id="ws-cscw19voids-cite" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          
        <pre>
        @InProceedings{ws-cscw19voids,
  title     = {Training Data Voids: Novel Attacks Against NLP Content Moderation},
  author    = {Huffaker, Jordan S. and Kummerfeld, Jonathan K. and Lasecki, Walter S. and Ackerman, Mark S.},
  year      = {2019},
  booktitle = {CSCW Workshop: Volunteer Work: Mapping the Future of Moderation Research},
  url       = {https://www.jkk.name/pub/ws19voids.pdf},
  location  = {Austin, TX},
  month     = {November},
}
        </pre>
        
        </p>
    </div>
  </div>
</div>


<div class="container pb-2">
  <div class="row">
    <div class="col-lg-6">
      <strong>DSTC7 Task 1: Noetic End-to-End Response Selection</strong>
      <br />
      <span class="text-muted">Chulaka Gunasekara, Jonathan K. Kummerfeld, Lazaros Polymenakos, Walter S. Lasecki</span>
      <br />
      ACL Workshop: NLP for Conversational AI<span class="text-muted">, 2019</span>
    </div>
    <div class="col-lg-6">
      <a class="btn btn-outline-primary btn-sm" href="https://www.aclweb.org/anthology/W19-4107" target="_blank" rel="noopener"><span
    class="fontawesome-inline-svg"
    style="display: inline-flex; align-self: center; height:1em; width:1em; top: .125em; position: relative;"
><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path fill='currentColor' d="M256 0v128h128L256 0zM224 128L224 0H48C21.49 0 0 21.49 0 48v416C0 490.5 21.49 512 48 512h288c26.51 0 48-21.49 48-48V160h-127.1C238.3 160 224 145.7 224 128zM272 416h-160C103.2 416 96 408.8 96 400C96 391.2 103.2 384 112 384h160c8.836 0 16 7.162 16 16C288 408.8 280.8 416 272 416zM272 352h-160C103.2 352 96 344.8 96 336C96 327.2 103.2 320 112 320h160c8.836 0 16 7.162 16 16C288 344.8 280.8 352 272 352zM288 272C288 280.8 280.8 288 272 288h-160C103.2 288 96 280.8 96 272C96 263.2 103.2 256 112 256h160C280.8 256 288 263.2 288 272z"/></svg>
</span>
 PDF</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('ws-acl-convai19dstc7-abstract').style.display == 'block') {
  document.getElementById('ws-acl-convai19dstc7-abstract').style.display='none';
  } else {
  document.getElementById('ws-acl-convai19dstc7-abstract').style.display='block';
  }
  ">Abstract</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('ws-acl-convai19dstc7-cite').style.display == 'block') {
  document.getElementById('ws-acl-convai19dstc7-cite').style.display='none';
  } else {
  document.getElementById('ws-acl-convai19dstc7-cite').style.display='block';
  }
  ">BibTeX</a>
      
      
      
      <a class="btn btn-outline-primary btn-sm" href="https://ibm.github.io/dstc-noesis/public/index.html" target="_blank" rel="noopener"><span
    class="fontawesome-inline-svg"
    style="display: inline-flex; align-self: center; height:1em; width:1em; top: .125em; position: relative;"
><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill='currentColor' d="M448 80V128C448 172.2 347.7 208 224 208C100.3 208 0 172.2 0 128V80C0 35.82 100.3 0 224 0C347.7 0 448 35.82 448 80zM393.2 214.7C413.1 207.3 433.1 197.8 448 186.1V288C448 332.2 347.7 368 224 368C100.3 368 0 332.2 0 288V186.1C14.93 197.8 34.02 207.3 54.85 214.7C99.66 230.7 159.5 240 224 240C288.5 240 348.3 230.7 393.2 214.7V214.7zM54.85 374.7C99.66 390.7 159.5 400 224 400C288.5 400 348.3 390.7 393.2 374.7C413.1 367.3 433.1 357.8 448 346.1V432C448 476.2 347.7 512 224 512C100.3 512 0 476.2 0 432V346.1C14.93 357.8 34.02 367.3 54.85 374.7z"/></svg>
</span>
 Data</a>
      
      
      
      
      
    </div>
  </div>
  <div class="row" id="ws-acl-convai19dstc7-abstract" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          
        </p>
    </div>
  </div>
  <div class="row" id="ws-acl-convai19dstc7-cite" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          
        <pre>
        @InProceedings{ws-acl-convai19dstc7,
  title     = {DSTC7 Task 1: Noetic End-to-End Response Selection},
  author    = {Gunasekara, Chulaka and Kummerfeld, Jonathan K. and Polymenakos, Lazaros and Lasecki, Walter S.},
  year      = {2019},
  booktitle = {Proceedings of the First Workshop on NLP for Conversational AI},
  pages     = {60--67},
  url       = {https://www.aclweb.org/anthology/W19-4107},
  location  = {Florence, Italy},
  month     = {August},
  doi       = {10.18653/v1/W19-4107},
  data      = {https://ibm.github.io/dstc-noesis/public/index.html},
}
        </pre>
        
        </p>
    </div>
  </div>
</div>


<h3 id="2018-1">2018</h3>
<div class="container pb-2">
  <div class="row">
    <div class="col-lg-6">
      <strong>Dialog System Technology Challenge 7</strong>
      <br />
      <span class="text-muted">Koichiro Yoshino, Chiori Hori, Julien Perez, Luis Fernando D&#39;Haro, Lazaros Polymenakos, Chulaka Gunasekara, Walter S. Lasecki, Jonathan K. Kummerfeld, Michel Galley, Chris Brockett, Jianfeng Gao, Bill Dolan, Xiang Gao, Huda Alamari, Tim K. Marks, Devi Parikh, Dhruv Batra</span>
      <br />
      NeurIPS Workshop: Conversational AI: Today&#39;s Practice and Tomorrow&#39;s Potential<span class="text-muted">, 2018</span>
    </div>
    <div class="col-lg-6">
      <a class="btn btn-outline-primary btn-sm" href="https://arxiv.org/abs/1901.03461" target="_blank" rel="noopener"><span
    class="fontawesome-inline-svg"
    style="display: inline-flex; align-self: center; height:1em; width:1em; top: .125em; position: relative;"
><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path fill='currentColor' d="M256 0v128h128L256 0zM224 128L224 0H48C21.49 0 0 21.49 0 48v416C0 490.5 21.49 512 48 512h288c26.51 0 48-21.49 48-48V160h-127.1C238.3 160 224 145.7 224 128zM272 416h-160C103.2 416 96 408.8 96 400C96 391.2 103.2 384 112 384h160c8.836 0 16 7.162 16 16C288 408.8 280.8 416 272 416zM272 352h-160C103.2 352 96 344.8 96 336C96 327.2 103.2 320 112 320h160c8.836 0 16 7.162 16 16C288 344.8 280.8 352 272 352zM288 272C288 280.8 280.8 288 272 288h-160C103.2 288 96 280.8 96 272C96 263.2 103.2 256 112 256h160C280.8 256 288 263.2 288 272z"/></svg>
</span>
 PDF</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('ws-neurips-convai18dstc-abstract').style.display == 'block') {
  document.getElementById('ws-neurips-convai18dstc-abstract').style.display='none';
  } else {
  document.getElementById('ws-neurips-convai18dstc-abstract').style.display='block';
  }
  ">Abstract</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('ws-neurips-convai18dstc-cite').style.display == 'block') {
  document.getElementById('ws-neurips-convai18dstc-cite').style.display='none';
  } else {
  document.getElementById('ws-neurips-convai18dstc-cite').style.display='block';
  }
  ">BibTeX</a>
      
      
      
      <a class="btn btn-outline-primary btn-sm" href="https://ibm.github.io/dstc-noesis/public/index.html" target="_blank" rel="noopener"><span
    class="fontawesome-inline-svg"
    style="display: inline-flex; align-self: center; height:1em; width:1em; top: .125em; position: relative;"
><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill='currentColor' d="M448 80V128C448 172.2 347.7 208 224 208C100.3 208 0 172.2 0 128V80C0 35.82 100.3 0 224 0C347.7 0 448 35.82 448 80zM393.2 214.7C413.1 207.3 433.1 197.8 448 186.1V288C448 332.2 347.7 368 224 368C100.3 368 0 332.2 0 288V186.1C14.93 197.8 34.02 207.3 54.85 214.7C99.66 230.7 159.5 240 224 240C288.5 240 348.3 230.7 393.2 214.7V214.7zM54.85 374.7C99.66 390.7 159.5 400 224 400C288.5 400 348.3 390.7 393.2 374.7C413.1 367.3 433.1 357.8 448 346.1V432C448 476.2 347.7 512 224 512C100.3 512 0 476.2 0 432V346.1C14.93 357.8 34.02 367.3 54.85 374.7z"/></svg>
</span>
 Data</a>
      
      
      
      
      
    </div>
  </div>
  <div class="row" id="ws-neurips-convai18dstc-abstract" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          This paper introduces the Seventh Dialog System Technology Challenges (DSTC), which use shared datasets to explore the problem of building dialog systems. Recently, end-to-end dialog modeling approaches have been applied to various dialog tasks. The seventh DSTC (DSTC7) focuses on developing technologies related to end-to-end dialog systems for (1) sentence selection, (2) sentence generation and (3) audio visual scene aware dialog. This paper summarizes the overall setup and results of DSTC7, including detailed descriptions of the different tracks and provided datasets. We also describe overall trends in the submitted systems and the key results. Each track introduced new datasets and participants achieved impressive results using state-of-the-art end-to-end technologies.
        </p>
    </div>
  </div>
  <div class="row" id="ws-neurips-convai18dstc-cite" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          
        <pre>
        @InProceedings{ws-neurips-convai18dstc,
  title     = {Dialog System Technology Challenge 7},
  author    = {Yoshino, Koichiro and Hori, Chiori and Perez, Julien and D'Haro, Luis Fernando and Polymenakos, Lazaros and Gunasekara, Chulaka and Lasecki, Walter S. and Kummerfeld, Jonathan K. and Galley, Michel and Brockett, Chris and Gao, Jianfeng and Dolan, Bill and Gao, Xiang and Alamari, Huda and Marks, Tim K. and Parikh, Devi and Batra, Dhruv},
  year      = {2018},
  booktitle = {NeurIPS Workshop: Conversational AI: Today's Practice and Tomorrow's Potential},
  url       = {https://arxiv.org/abs/1901.03461},
  location  = {Montreal, Quebec, Canada},
  month     = {December},
  arxiv     = {https://arxiv.org/abs/1901.03461},
  data      = {https://ibm.github.io/dstc-noesis/public/index.html},
}
        </pre>
        
        </p>
    </div>
  </div>
</div>


<h3 id="2009-1">2009</h3>
<div class="container pb-2">
  <div class="row">
    <div class="col-lg-6">
      <strong>Large-Scale Syntactic Processing: Parsing the Web</strong>
      <br />
      <span class="text-muted">Stephen Clark, Ann Copestake, James R. Curran, Yue Zhang, Aurelie Herbelot, James Haggerty, Byung-Gyu Ahn, Curt Van Wyk, Jessika Roesner, Jonathan K. Kummerfeld, Tim Dawborn</span>
      <br />
      Johns Hopkins University<span class="text-muted">, 2009</span>
    </div>
    <div class="col-lg-6">
      <a class="btn btn-outline-primary btn-sm" href="https://www.jkk.name/pub/report09jhu.pdf" target="_blank" rel="noopener"><span
    class="fontawesome-inline-svg"
    style="display: inline-flex; align-self: center; height:1em; width:1em; top: .125em; position: relative;"
><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path fill='currentColor' d="M256 0v128h128L256 0zM224 128L224 0H48C21.49 0 0 21.49 0 48v416C0 490.5 21.49 512 48 512h288c26.51 0 48-21.49 48-48V160h-127.1C238.3 160 224 145.7 224 128zM272 416h-160C103.2 416 96 408.8 96 400C96 391.2 103.2 384 112 384h160c8.836 0 16 7.162 16 16C288 408.8 280.8 416 272 416zM272 352h-160C103.2 352 96 344.8 96 336C96 327.2 103.2 320 112 320h160c8.836 0 16 7.162 16 16C288 344.8 280.8 352 272 352zM288 272C288 280.8 280.8 288 272 288h-160C103.2 288 96 280.8 96 272C96 263.2 103.2 256 112 256h160C280.8 256 288 263.2 288 272z"/></svg>
</span>
 PDF</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('report09jhu-abstract').style.display == 'block') {
  document.getElementById('report09jhu-abstract').style.display='none';
  } else {
  document.getElementById('report09jhu-abstract').style.display='block';
  }
  ">Abstract</a>
      <a class="btn btn-outline-primary btn-sm" href="javascript:;" onClick="
  if (document.getElementById('report09jhu-cite').style.display == 'block') {
  document.getElementById('report09jhu-cite').style.display='none';
  } else {
  document.getElementById('report09jhu-cite').style.display='block';
  }
  ">BibTeX</a>
      
      
      
      
      
      
      
    </div>
  </div>
  <div class="row" id="report09jhu-abstract" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          Scalable syntactic processing will underpin the sophisticated language technology needed for next generation information access. Companies are already using nlp tools to create web-scale question answering and &#39;semantic search&#39; engines. Massive amounts of parsed web data will also allow the automatic creation of semantic knowledge resources on an unprecedented scale. The web is a challenging arena for syntactic parsing, because of its scale and variety of styles, genres, and domains.\n\nThe goals of our workshop were to scale and adapt an existing wide-coverage parser to Wikipedia text; improve the efficiency of the parser through various methods of chart pruning; use self-training to improve the efficiency and accuracy of the parser; use the parsed wiki data for an innovative form of bootstrapping to make the parser both more efficient and more accurate; and finally use the parsed web data for improved disambiguation of coordination structures, using a variety of syntactic and semantic knowledge sources.\n\nThe focus of the research was the C&amp;C parser (Clark and Curran, 2007c), a state-of-the-art statistical parser based on Combinatory Categorial Grammar (ccg). The parser has been evaluated on a number of standard test sets achieving state-of-the-art accuracies. It has also recently been adapted successfully to the biomedical domain (Rimell and Clark, 2009). The parser is surprisingly efficient, given its detailed output, processing tens of sentences per second. For web-scale text processing, we aimed to make the parser an order of magnitude faster still. The C&amp;C parser is one of only very few parsers currently available which has the potential to produce detailed, accurate analyses at the scale we were considering.
        </p>
    </div>
  </div>
  <div class="row" id="report09jhu-cite" style="display: none;margin-left:20px;">
    <div class="col">
        <p>
          
        <pre>
        @TechReport{report09jhu,
  title     = {Large-Scale Syntactic Processing: Parsing the Web},
  author    = {Clark, Stephen and Copestake, Ann and Curran, James R. and Zhang, Yue and Herbelot, Aurelie and Haggerty, James and Ahn, Byung-Gyu and Wyk, Curt Van and Roesner, Jessika and Kummerfeld, Jonathan K. and Dawborn, Tim},
  year      = {2009},
  institution = {Johns Hopkins University},
  url       = {https://www.jkk.name/pub/report09jhu.pdf},

The goals of our workshop were to scale and adapt an existing wide-coverage parser to Wikipedia text; improve the efficiency of the parser through various methods of chart pruning; use self-training to improve the efficiency and accuracy of the parser; use the parsed wiki data for an innovative form of bootstrapping to make the parser both more efficient and more accurate; and finally use the parsed web data for improved disambiguation of coordination structures, using a variety of syntactic and semantic knowledge sources.

The focus of the research was the C&C parser (Clark and Curran, 2007c), a state-of-the-art statistical parser based on Combinatory Categorial Grammar (ccg). The parser has been evaluated on a number of standard test sets achieving state-of-the-art accuracies. It has also recently been adapted successfully to the biomedical domain (Rimell and Clark, 2009). The parser is surprisingly efficient, given its detailed output, processing tens of sentences per second. For web-scale text processing, we aimed to make the parser an order of magnitude faster still. The C&C parser is one of only very few parsers currently available which has the potential to produce detailed, accurate analyses at the scale we were considering.},
}
        </pre>
        
        </p>
    </div>
  </div>
</div>


<hr>

	
	
	
</div>

          </main>
        </div>
      </div>
      
<footer class="bg-dark py-5 row d-print-none">
  <div class="container-fluid mx-sm-5">
    <div class="row">
      <div class="col-6 col-sm-4 text-xs-center order-sm-2">
        
        
        
<ul class="list-inline mb-0">
  
  <li class="list-inline-item mx-2 h3" data-toggle="tooltip" data-placement="top" title="Email" aria-label="Email">
    <a class="text-white" target="_blank" rel="noopener" href="mailto:jonathan.kummerfeld@sydney.edu.au" aria-label="Email">
      <i class="fa fa-envelope"></i>
    </a>
  </li>
  
  <li class="list-inline-item mx-2 h3" data-toggle="tooltip" data-placement="top" title="Twitter" aria-label="Twitter">
    <a class="text-white" target="_blank" rel="noopener" href="https://twitter.com/jkkummerfeld" aria-label="Twitter">
      <i class="fab fa-twitter"></i>
    </a>
  </li>
  
  <li class="list-inline-item mx-2 h3" data-toggle="tooltip" data-placement="top" title="LinkedIn" aria-label="LinkedIn">
    <a class="text-white" target="_blank" rel="noopener" href="https://linkedin.com/in/jkkummerfeld/" aria-label="LinkedIn">
      <i class="fab fa-linkedin"></i>
    </a>
  </li>
  
  <li class="list-inline-item mx-2 h3" data-toggle="tooltip" data-placement="top" title="Mastodon" aria-label="Mastodon">
    <a class="text-white" target="_blank" rel="noopener" href="https://mastodon.social/@jkkummerfeld" aria-label="Mastodon">
      <i class="fa-brands fa-mastodon"></i>
    </a>
  </li>
  
</ul>

        
        
      </div>
      <div class="col-6 col-sm-4 text-right text-xs-center order-sm-3">
        
        
        
<ul class="list-inline mb-0">
  
  <li class="list-inline-item mx-2 h3" data-toggle="tooltip" data-placement="top" title="GitHub" aria-label="GitHub">
    <a class="text-white" target="_blank" rel="noopener" href="https://github.com/jkkummerfeld" aria-label="GitHub">
      <i class="fab fa-github"></i>
    </a>
  </li>
  
  <li class="list-inline-item mx-2 h3" data-toggle="tooltip" data-placement="top" title="ACL Anthology" aria-label="ACL Anthology">
    <a class="text-white" target="_blank" rel="noopener" href="https://aclanthology.org/people/j/jonathan-k-kummerfeld/" aria-label="ACL Anthology">
      <i class="icon icon-acl-logo"></i>
    </a>
  </li>
  
  <li class="list-inline-item mx-2 h3" data-toggle="tooltip" data-placement="top" title="Semantic Scholar" aria-label="Semantic Scholar">
    <a class="text-white" target="_blank" rel="noopener" href="https://semanticscholar.org/author/Jonathan-K.-Kummerfeld/1727211" aria-label="Semantic Scholar">
      <i class="ai ai-semantic-scholar"></i>
    </a>
  </li>
  
  <li class="list-inline-item mx-2 h3" data-toggle="tooltip" data-placement="top" title="Google Scholar" aria-label="Google Scholar">
    <a class="text-white" target="_blank" rel="noopener" href="https://scholar.google.com/citations?user=OsoNG9AAAAAJ" aria-label="Google Scholar">
      <i class="ai ai-google-scholar"></i>
    </a>
  </li>
  
  <li class="list-inline-item mx-2 h3" data-toggle="tooltip" data-placement="top" title="DBLP" aria-label="DBLP">
    <a class="text-white" target="_blank" rel="noopener" href="https://dblp.uni-trier.de/pers/hd/k/Kummerfeld:Jonathan_K=" aria-label="DBLP">
      <i class="ai ai-dblp"></i>
    </a>
  </li>
  
  <li class="list-inline-item mx-2 h3" data-toggle="tooltip" data-placement="top" title="ArXiv" aria-label="ArXiv">
    <a class="text-white" target="_blank" rel="noopener" href="https://arxiv.org/a/kummerfeld_j_1" aria-label="ArXiv">
      <i class="ai ai-arxiv"></i>
    </a>
  </li>
  
  <li class="list-inline-item mx-2 h3" data-toggle="tooltip" data-placement="top" title="OrcID" aria-label="OrcID">
    <a class="text-white" target="_blank" rel="noopener" href="https://orcid.org/0000-0001-5030-3016" aria-label="OrcID">
      <i class="ai ai-orcid"></i>
    </a>
  </li>
  
  <li class="list-inline-item mx-2 h3" data-toggle="tooltip" data-placement="top" title="USyd" aria-label="USyd">
    <a class="text-white" target="_blank" rel="noopener" href="https://www.sydney.edu.au/engineering/about/our-people/academic-staff/jonathan-kummerfeld.html" aria-label="USyd">
      <i class="icon icon-usyd-logo"></i>
    </a>
  </li>
  
</ul>

        
        
      </div>
      <div class="col-12 col-sm-4 text-center py-2 order-sm-2">
        <small class="text-white">&copy; 2024 Jonathan K. Kummerfeld All Rights Reserved</small>
        
	
		
	
      </div>
    </div>
  </div>
</footer>


    </div>
    <script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.1/dist/umd/popper.min.js"
    integrity="sha384-9/reFTGAW83EW2RDu2S0VKaIzap3H66lZH81PoYlFhbGU+6BZp6G7niu735Sk7lN"
    crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.min.js"
    integrity="sha512-UR25UO94eTnCVwjbXozyeVd6ZqpaAE9naiEUBK/A+QDbfSTQFhPGj5lOR6d8tsgbBk84Ggb5A3EkjsOgPRPcKA=="
    crossorigin="anonymous"></script>





<script src='/js/tabpane-persist.js'></script>






<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css"
    integrity="sha512-vJqxkZ+Sugf/6WRlpcxN01qVfX/29hF6qc33eHF1va3NgoV+U+wCi+uTAsQ10sDoGyBxHLdaHvGwDlV3yVYboA==" crossorigin="anonymous">

<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js"
    integrity="sha512-5ufNcHqOYgilGEHPfuRIQ5B/vDS1M8+UC+DESZ5CwVgGTg+b2Ol/15rYL/GiCWJ/Sx8oVo0FPFok1dPk8U9INQ=="
    crossorigin="anonymous"></script>



<script defer src='https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js'
    integrity='sha512-ZA/RPrAo88DlwRnnoNVqKINnQNcWERzRK03PDaA4GIJiVZvGFIWQbdWCsUebMZfkWohnfngsDjXzU6PokO4jGw==' crossorigin='anonymous' 
    onload='renderMathInElement(document.body, null);'></script>















<script src="/js/main.min.91798a335c881f1b6b805085ba4aa22d1dbd2b0b18d105d05189fa104ddae350.js" integrity="sha256-kXmKM1yIHxtrgFCFukqiLR29KwsY0QXQUYn6EE3a41A=" crossorigin="anonymous"></script>




  </body>
</html>
